{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Multilabel - Data Augumented - Universal sentense Encoder -  Keras Modelling ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Lambda, Layer, Concatenate, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "session  = tf.Session()\n",
    "K.set_session(session)\n",
    "# session.run(tf.global_variables_initializer())\n",
    "# session.run(tf.tables_initializer())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['label','text'])\n",
    "trainset = datasets.load_files(container_path = 'dataset_small_less_categories_v2',encoding = 'UTF-8')\n",
    "\n",
    "def get_dataframe(lines):\n",
    "#     lines = filename.splitlines()\n",
    "    data = []\n",
    "    for i in range(0, len(lines)):\n",
    "        label = lines[i][0]\n",
    "    #     label = label.split(\",\")[0]\n",
    "        text = ' '.join(lines[i][1:])\n",
    "        text = re.sub(',','', text)\n",
    "        data.append([label, text])\n",
    "    df = pd.DataFrame(data, columns=['label', 'text'])\n",
    "    df.label = df.label.astype('category')\n",
    "    return df\n",
    "\n",
    "for k in range(len(trainset.target)):\n",
    "    labelled_sent= trainset.data[k].strip().split('\\r\\n')\n",
    "    Label=[trainset.target[k]]*len(labelled_sent)\n",
    "    labelled_emb = list(zip([s for s in Label], [s for s in labelled_sent]))\n",
    "    df_train = get_dataframe(labelled_emb)\n",
    "    df=pd.concat([df,df_train])\n",
    "    df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I want to travel back to my native place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Want curfew pass for case of emergency travel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I had started towards my home 120 km away on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Firstline workers facing issues as no cabs are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Want to go back to my family place. Currently ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>4</td>\n",
       "      <td>Economic downfall will soon create job crises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>4</td>\n",
       "      <td>Employee are not happy with the relief funds p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4</td>\n",
       "      <td>emi should be reduced and less interest rate s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>4</td>\n",
       "      <td>tv news channel focus more on fake news.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>4</td>\n",
       "      <td>work from home should be manditory for all com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                               text\n",
       "0       5          I want to travel back to my native place.\n",
       "1       5     Want curfew pass for case of emergency travel.\n",
       "2       5  I had started towards my home 120 km away on m...\n",
       "3       5  Firstline workers facing issues as no cabs are...\n",
       "4       5  Want to go back to my family place. Currently ...\n",
       "..    ...                                                ...\n",
       "333     4     Economic downfall will soon create job crises.\n",
       "334     4  Employee are not happy with the relief funds p...\n",
       "335     4  emi should be reduced and less interest rate s...\n",
       "336     4           tv news channel focus more on fake news.\n",
       "337     4  work from home should be manditory for all com...\n",
       "\n",
       "[338 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset.data[0], trainset.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [\"I want to travel back to my native place.\\r\\nWant curfew pass for case of emergency travel.\\r\\nI had started towards my home 120 km away on my car.\\r\\nFirstline workers facing issues as no cabs are available\\r\\nWant to go back to my family place. Currently staying in the hotel.\\r\\nWant to travel from bangalore to delhi. Any means of transport available?\\r\\nI haven't seen my family for a long time and they need my support. I need to be there.\\r\\nResiding in green zone but not able to get travel permssion even for getting essential household items.\\r\\nFew days back my vehicle was seized by police, now don't have any means of transport.\\r\\nMy visa about to get expire. Want some travel arrangements to be done to fly back to Austria.\\r\\nFive construction workers started walking from kerela to bihar but are stranded in karnataka border.\\r\\nI live in pg where its difficult to get food. When are flights and trains getting started.\\r\\nYou are giving permission to celebrities like Rishi kapoors daughter to travel while normal people are not getting passes within the city. \\r\\nI cancelled my advance booking on irctc website but refund is not initiated yet.\\r\\nDue to lack in any means of transport horse cart owner is charging very high prices. Please give update when daily buses will resume.\\r\\nThe temporary bridge is broken due to heavy flow of river water, so we are not able to go to cities.\\r\\nDaily a truck of refugees breaks into the city via the south highway road. Travel ban should be imposed on the trucks too.\\r\\nI want to drive to my home town to attend a funeral and need paas. send me back.\\r\\nI came to Bangalore to work and have been stuck here for so long due to the lockdown, I need to get to my elderly parents who are in a small town in Maharashtra which is declared a red zone. \\r\\nMy son went to Delhi to prepare for competitive exams and now he is stuck there with some friends as their institution has closed down and he is unable to return. \\r\\nMe and family stranded on roadside on the way to mysore. Car is not working.\\r\\nI am a Canadian resident.. I am in Panama and the airport continue closed here and there aren't humanitarian flights to Canada neither. Please I need back to see my family, return to get my job!.  I've been waiting for a humanitarian flight since early April\\r\\nI appeal to central govt, please  take care of laboure's , provide transport facilities.\\r\\nIf they start to walk by themselves it's very different to find them and migrate them. and Central gov have already passed notice to all states to make sure they dont need to walk. Now states can arrange transport.\\r\\nU need to stop all this arrange means of transport for them n give them tickets at station.\\r\\n10 migrant labour from Bihar near my locality are stuck here they  want to go back to their native place by road. I have been trying to register them on below site but it is not working\\r\\n100,000 Crew Members Stranded on Cruise Ships as Cruise Lines Refuse to Agree to Pay for Repatriation Expenses\\r\\n70 workmen stuck in Tidong HE Project near Recongpeo to go back to their homes in Bihar. No help from any nodal officer for migrant workers yet.\\r\\nAdd more world class international outbound flights so stranded that NRIs can reunite with their families.\\r\\nAir Asia Support Since yesterday I already DM my booking code for some help. My flight to Thai cancelled due to covid-19, already request credit account thru AVA. However I can not request credit account for my flight back from Thailand a week later. Until now no response.\\r\\nall the employees who are stuck on the way roads and going to their home\\r\\nAll those who wish to travel from gujarat to jk by train have to register on gujarat govt portal. Anyone from jk who is stranded in Gujarat may do so immediately. Its only train scheduled from Gujarat.\\r\\nAnyone any idea when atleast domastic flights will resume?\\r\\nAs Phase 2 of Vande Bharat Mission to carry Indians from other countries is slated to commence from May 19. NRIs have urged the Ministry of Civil Aviation to resume connecting flights to New Delhi, from south India.\\r\\nBut, what about those STUDENTS  and WORKERS who stuck in WESTBENGAL and want to go back to their home.\\r\\nCan we go home with private 4 wheeler vehicles? Actually mother is stuck with me since Holi.\\r\\nDear sir request you please arrange Flights from Chennai to ahmedabad as I am here with family and kids want to travel back to ahmedabad. I am here since lockdown started. You have started many flights all over India. But no flights is there from chennai to Ahmedabad\\r\\nMy sister in law has applied for e pass to travel from Mumbai to Beed district in Maharashtra.\\r\\nEffort from Congress to mobilize all local units to arrange transport.\\r\\nEMPLOYERS use public transport because they live miles away and have no alternative. no one is using public transport.\\r\\nHello sir my father is very serious, he has to go to Patna for treatment and in Bihar during the covid19 it's very difficult to get any transportation to reach Patna , and I am in Delhi unfortunately I can't reach there so I request to Bihar police please help him.\\r\\nHi, unfortunately we have no update on when normal international flights will resume due to the unpredictability of COVID-19 and other countries immigration changes.\\r\\nHow can i get the e-pass to travel back from New Delhi to Prayagraj. My Brother's is Stuck in New Delhi.\\r\\nI am not able to understand that Why they are not resuming the domestic flights. If they can resume train why not flights. Every one wants to go to their families.\\r\\nI had been stuck in Kolkata because of lockdown. I want to travel back to my hometown Hyderabad address.\\r\\nI have applied for migrant pass for up before 20 days on jansunvai app. I have alone and  stuck in Mumbai. Please do needful so that I can reach my home.\\r\\nI have been issued travel pass but no further communication regarding travel options. I had opted for govt assistance in traveling back to Bengaluru from Ahmedabad.\\r\\nI m stuck in India with my 8 month old infant. I can't take the repartition flights as my visa isn't stamped.\\r\\nIf the lockdown gets extended beyond may 17, I kindly request you to consider air services within Tamilnadu for inter district travel.\\r\\nis therE anY actioN takeN bY jharkhanD govT. foR migranT workeR tO brinG bacK tO hiS homE? iF yeS thaN whY mY eldeR brotheR iS stilL stucK iN mehsanA,gujraT? registatioN waS donE nearlY 20 dayS agO buT stilL nO responsE. pleasE trY tO brinG hiM bacK immedietelY.\\r\\nNothing is benefiting air travellers for now. People are stranded in different places and requesting you everyday to resume domestic flights.\\r\\nhow can i reach you from salanpur, WB Local police said bring your personal vehicle only that pass we can issue.\\r\\nMany travelers are still waiting to get back to their homes, jobs and daily routine.\\r\\nme and my 4 colleagues are stranded in india due to lockdown and want to travel to uganda as our company needs us urgently. We all have valid work permit and other required documents.\",\n",
       "  \"I need daily rations in Attur\\r\\nprovide dry rations for 6 people for 10 days\\r\\nNeed prepared food for 20 people in slum\\r\\nNeed groceries for a family in quarantine\\r\\nmy sugar, eggs and milk are over. I have small chidren. \\r\\nNeed food packets for 20 people\\r\\nI want bread and rice for my home\\r\\nFive construction workers started walking from kerela to bihar but are stranded in karnataka border. Get them food and help them go to their home.\\r\\nThe temporary bridge is broken due to heavy flow of river water, so we are not able to go to cities to buy groceries and medicines. Help us.\\r\\nI cannot cook food at my home as I do not have groceries and cooking oil.\\r\\nDry ration provided is of bad quality. People are getting sick after consuming them.\\r\\n5 kg Rice, 10 kg Wheat, 2 litre mustard oil etc.\\r\\nPeople are starving due to COVID19 crises.\\r\\nMy maid complaint that she has money but was unable to buy groceries as nearby shops are closed and police is not allowing them to go to far places. Please make sure essential services are working properly and Help my maid.Her No. is 7625472689\\r\\nNo one is taking care of roadside animals. They are starving.Plase do something to help them instantly\\r\\nAs my young daughter is still a toddler, I need some cereals or Cerelac and milk urgently.\\r\\nEven though the local auhtorities have arranged for raw vegetables for us to have, please provide us with cooking oil and spices to cook them, which we have been asking for so long.\\r\\nI am unable to find fruits or vegetables\\r\\nWhere can I get bread and butter.\\r\\nEdible supplies are not available in my area, i need bread and groceries\\r\\nWe are 6 people in my family and we are out of food. Anything you can give, please do\\r\\nI need food supplies for my family. Require lunch, dinner, meals everyday. \\r\\nI am starving and hence require daily meals. please supply meals for me.\\r\\nInternet facility provided at railway station is so bad that i am not even able to buy groceries online.\\r\\n10lbs down in quarantine  No Food \\r\\nAlthough COVID-19 has highlighted fragility of our food systems, it is still an opportunity to change, both in production & consumption patterns and in private & public actions. Time 4 an ecological conversion\\r\\nchildren  stuck  lockdown hungry\\r\\nFor those of you that missed yesterday's Food Drop, check out The City of Baltimore's Grocery Boxes pick up locations and times.\\r\\nGovernments must work together to avert disruptions to food supply chains. Food protectionism must be avoided\\r\\nHard to plan out a menu when you don't know what the grocery situation will look like in a few months.\\r\\nhe has run out of all the savings and is dependent on NGO to get dry ration during this lockdown..Request you to Please help..Thanks \\r\\nHigh End Kosher Milk and Yougurt from upstate small farmers to Feed The Needy at Masbia during the current Food Crisis and Hunger Wave\\r\\nHow is your moms pizza??\\r\\nI hate when I go to the kitchen looking for food, and I find is ingredients.  food  no food  hungry\\r\\nI urge to help me in getting food to 20 migrant workers stuck in Regonda P/S Sundhrala Tehsil Husnabad District Siddipet . This is their contact: Asif Hussain 9541028380. Thank you for your kind cooperation!\\r\\nI was so hangry just now every little thing my kids and the dogs did threw me into a rage. I have no idea how people skip breakfast or fast for any length of time.\\r\\nI'm hungry and cant decided what I want.\\r\\nI'm raising money for Help me buy Urgent Food for People in Colombia.\\r\\nIn addition to food for people isolated at home during special periods, medical personnel in the frontline also need food supplies, and packaging of large amounts of food requires a large number of food boxes and ration kits\\r\\nLiterally all I've even today is some toast with Nutella and a protein shake.  needfood\\r\\nlockdown  no food  no shelter   \\r\\nMan Could Soon Be Eating Rice For Breakfast, Dinner And Tea. \\r\\nNeed Food Hungry\\r\\nNew survey finds food waste on the rise as takeout and delivery increases.\\r\\nplease see migrants and others staying in sant Nagar/ garhi/ prakash mohalla east of Kailash need help. There are many without food ration medicines in the area. Request you to please ask NGO/people to help them with basic. \\r\\nfood crisis with lots of food.Soaring Prices, Rotting Crops: Coronavirus Triggers Global FoodCrisis.\\r\\nRequest to CM - people are dying with starvation who don't have ration cards, kindly help us to get ration cards, MORE people DYING with starvation RATHER THAN COVID 19.\\r\\nso on top of  rent being late  no food and rationing \\r\\nSoaring Prices, Rotting Crops Coronavirus Triggers Global Food Crisis Processing and transportation breakdowns, panic buying threaten vulnerable nations; a food crisis with lots of food\\r\\nSomebody help me out with some food  HELP  COVID19\\r\\nSteersSA is really proving itself to be a substandard take away joint during this Lockdown.  I ordered  food at 11:30, more than Four and a half  hours later no delivery.  Still sitting hungry. \\r\\nStop Covid19 crisis morphing into a Food Crisis: Support to Africa rice sector. To avoid food crisis in Africa, urgent measures for sustained agricultural growth need to be in place now\\r\\nTackling Food Waste in the time of Food Insecurity and making progress .\\r\\nThe crisis has snarled supply chains, stoked fears of food shortages, and sparked warnings of a potential spike in global hunger\\r\\nThe current food crisis situation we are facing is not because we do not have food produced, but because there is a challenge in moving food across regions\\r\\nThe team have been out this week to our families in Bulacan delivery food packs.\\r\\nThe WHO has warned of hunger famines and indications are for food shortages as governments push their bogus agenda.  THAT means start preparing! AND keep preparing!\\r\\nThere are many women lives in aarey colony (unit no 22) hve no option for food such as wheat , rice, oil etc.\\r\\nThis startup is looking to empower people to grow more food for themselves.\\r\\nThose affected or at high risk of developing COVID19 must have access to food.\\r\\nToday we organized a virtual event on food security and nutrition looking at responses & early results to avert a global crisis.\\r\\nWay more global deaths from starvation than coronavirus.Loss in agriculture sector.\\r\\nwe got a request from weavers families total 55 families in need of groceries poor families please help\\r\\nZomato done big mistake ordering food during lockdown since food packaging and handling was worst no hygiene and delivery guys looks in bad condition, now I am worrying why we ordered online food, packing were half open. Not sure how long I need to stay hungry.\\r\\nFruits & Vegetables Rice , wheat , flour , other cereals and pulses Sugar and salt, spices , masalas , Bakery and dairy (milk, milk products) , Tea and coffee Eggs, meat and fish , Food grains, and food ingredients , Packaged food and beverages Health supplements, nutraceuticals, food for special dietary use and food for special medical purpose Infant/baby food.\",\n",
       "  \"Much needed essential supplies not available in nearby store.\\r\\ndont have money to buy essential items \\r\\nrun out of gas . Unable to get gas cylinders\\r\\nGas cannisters are empty please refill it.\\r\\nrequesting supplies of kerosene\\r\\nToo frequent power cuts in our locality. Need supply of kerosine to run the generator\\r\\nPlease donate coal for burning of stove.\\r\\nCitySafe Durham is now operating delivery service where volunteers will deliver essential items, drop off prescriptions to vulnerable people.\\r\\nproducts such as cookware, innerwear\\r\\nmultifunction scissors, automatic mops, hair trimmers topped customers shopping cart.\\r\\nThe list of essentials needs to be broadened to include kitchen essentials, stationery, computers, IT accessories\\r\\nwe wanted to deliver Coconut Oil and Desiccated Coconut.\\r\\nNeed to ship pet essential supplies for dogs and cats\\r\\nshipping newborn Clothes and other essentials like nappies, blankets during the lockdown\\r\\npeople want to ship home products like floor cleaner, dishwash gel, handwash.\\r\\nCan someone deliver toiletry bag and other bathroom utlilities.\\r\\nlist of essential items includes Sanitary napkins , Diapers , Soaps and detergents Surface cleaners and disinfectants.\\r\\nTissue papers , toothpaste, tooth brush and other oral care products are also part of essential commodities.\\r\\nBaby Products, Baby milk formula should be considered as important things to be supplied.\\r\\nFace wash, Shampoo, Oral hygiene products.\\r\\nLaptops, mobile phones, and accessories, computer hardware, webcams, all these things should be allowed to be part of essential goods.\\r\\nBattery, dish washer , fabric care , paper tissues , towel , clothes , shoes , slippers\\r\\nlubricants, greases and engine oils, mining, fuel and petroleum\\r\\nlivestock transporters, farmerâ€™s markets, feed stores, agricultural equipment, gas, diesel and petroleum suppliers \\r\\nchemicals including pesticides, herbicides and fertilizer producers and distributors.\\r\\nTrying to include items like water, snacks, bandages, etc.\\r\\nDistribution of essential items like dry packets,  mosquito nets, cloths, lamps, sanitary  napkins,by a team of Forum for People's.\\r\\ntoilet paper, bar soap, liquid soap, toothpaste, facial tissue, shampoo\\r\\nA number of essential items: bandaids, gauze, inhalers, white sheets required for 50 people.\\r\\n#COVID19 relief packages should include essential reproductive health commodities like menstrual health items, oral contraceptives, condoms, spermicide, and lubrication.\\r\\nbabies are receiving diapers and essential baby items.\\r\\nlet us know that if there is a stop in the supplies of necessity like water, electricity, milk.\\r\\nThe key challenges to menstrual hygiene management (MHM) are unavailabity of sanitary napkins.\\r\\nDuring the initial phase of the lockdown, sanitary napkins were not included in the list of the daily usage necessity. \\r\\nunless for the provision of essential goods and services. She clearly needs to get money. \\r\\nLet me know if anyone needs essential supplies ( water / protein bars )\\r\\nI want fertilizers and seeds to grow crops in my farm.\\r\\nwater storage container, bulbs, tubelights , Battery, charger , plug required.\\r\\nI have no utensils, gas cylinder in my kitchen.\",\n",
       "  \"Two people suffering from fever and cold\\r\\nI need to take my father to hospital for dialysis.\\r\\nNeed an ambulance urgently\\r\\naccident in the area and arm broken, need to go to hospital\\r\\nMy blood pressure is low.\\r\\nI need tablets for my head ache.\\r\\nParacetamol tablets used to cure fever must be distributed.\\r\\nfood poisoning by eating old distributed items\\r\\nI am hungry from last three days. My glucose level is very low and bp is very high. Need help urgently.\\r\\nI was travelling from karnataka to tamil nadu and met with an accident. I need medical assistance for my fractured leg.\\r\\nmy daughter ate expired medicine. I am unable to call any hospital.\\r\\nmy aunt is feeling uneasiness since morning. This can be a symptom of corona. Send check up team immediately.\\r\\nI read a news article and I suspect I have cancer. As a precautionary measure I want my body checkup\\r\\nThere was sparking in my electric generator due to fuel leakage and I got a third degree burn.\\r\\nDry ration provided is of bad quality. People are getting sick after consuming them.\\r\\nMy father is sick.\\r\\nMy son is ill due to bad weather.\\r\\nI have been coughing for several days now, but recently I am also feeling a blockage on my throat, weaknesss and fever. \\r\\nMy wife is a construction worker and since we don't have enough meals now due to shortage of money, she is weak and unable to get up\\r\\nneed medical assistance\\r\\nI am running out of my insulin injections.\\r\\nMe and my parents are stuck alone in our house with severe health issues. My father has heart problems and my mother is bedridden. I need medical assistance.\\r\\nHello sir my father is very serious, he has to go to Patna for treatment and in Bihar during the covid19 it's very difficult.\\r\\n17 people died in accident no medical help\\r\\nExxon donates ambulances, vehicles, medical supplies for COVID-19\\r\\nfaye dsouza please see migrants and others staying in sant Nagar/ garhi/ prakash mohalla east of Kailash need help. There are many without medicines in the area. Request you to please ask NGO/people to help them with basic. \\r\\nGovt sends medical supplies to various States\\r\\nI had the same issue with my medical aid at first but they need a written letter from your psychiatrist stating that your diagnosis is chronic. I don't know how it's determined, but mine was considered genetic.\\r\\nIf anyone is in need, call me okay! I'll use my first aid kit.\\r\\nIndianEmbRiyadh Sir, submitted online request to travel India on Medical Emergency, I am suffering from Severe Head abnormality and heart problems. In this lockdown did many tests; MRI, CT Scan etc, unable to trace real cause of illness\\r\\nMy hometown WuxiCity not only dispatched medical workers to Hubei Province badly-hit by COVID19, but also donated medical supplies to its sister sities in 16 countries. Highly appreciated\\r\\nOur Biomedical team has an ongoing partnership with Project CURE, an organization that donates much needed medical supplies to hospitals.\\r\\nOur high school just sent out a request for help for our local hospital in the suburbs. They want us to make surgical caps! They are short supplied. \\r\\nSir, i would like to inform you that, my mother admitted in Nehru Homoeopathic Medical College and Hospital defence colony due to covid 19, she is suffering from sleeping issues and she is crying frequently , i request you kindly help on this.\\r\\nThere have never been adequate stockpiles of necessary medical supplies for this type of contingency, even though it's been known for generations that these situations arise. Capitalism does not safeguard public health.\\r\\ntoday morning team of Doctors will come and take the testing sample. Its noon already and there is no one here to take sample. Also the Aarogya Setu app says I am safe.\\r\\nTrump mulls executive order that would limit any federal contracts for essential drugs and medical treatments to manufacturers in the U.S.\\r\\nWe are manufacturers of best quality ppe kits for health care workers and our doctors.\\r\\nWhere's the medic car when you need one, or were these days when you would need your own first aid kit\\r\\nwe need to ship Ayurveda medicine to patients. i am ayurvedic Doctor shipping products from my clinic.\\r\\ndiabetes is a progressive disease. Will you require insulin? \\r\\nweight, exercise, genetics, hormones and beta-cells, those cells that produce insulin in your pancreas.\\r\\nthyroiditis is a type of autoimmune thyroid disease in which the immune system attacks and changes the texture of the thyroid gland.\\r\\nReviewing health problems and outbreaks; this includes chronic diseases, injuries, and social factors that influence health status \\r\\nasthama, spinal pain, headache, malaria, hepatitis C, dengue, tuberculosis, injuries, chronic lower respiratory disease.\\r\\nAlzheimer's disease, diabetes, influenza and pneumonia, cough, common cold, stroke and cerebrovascular diseases.\\r\\nInfluenza (The Flu), Bronchitis, gastroenteritis (Stomach Flu), ear Infections\\r\\nMy mother has fallen very sick recently and she has been admitted to the hospital. The doctors have diagnosed that she might have typhoid and they will have to keep her at the hospital under observation.\\r\\nGovt hospitals to check on hygiene due to reports of diseases.\\r\\nMy father was admitted during the Covid19 pandemic. No obvious symptoms of corona virus. They suspected he might have covid19. Discharged next day. Sent to Civil hospital. Test results came negative.\\r\\nMy Mom suffered from Kidney Stone and due to which there was a urine blockage at ureter and caused infection within body. And because of this, she had lung infection and breathlessness.\\r\\nI took Acupuncture treatment for my sciatica and 17 yrs migraine headache, now i am relieved of sciatica and migraine without medicine\\r\\nI got invisalign treatment while my mother got her dental implants treatment.\\r\\nThere is a cavity in my premolar, i need to get it filled.\\r\\ni have tooth ache since a week. I need to see a dentist.\\r\\nHospital is in need of more ventilators as number of patients is increasing.\\r\\nThere is a faulty ventilator that needs to be replaced.\\r\\nThe delivery workers of essential items should always wear masks as they come in contact with hundreds of people. Government should provide n95 masks for them.\\r\\nEquipment required at hospital. patients need mask and sanitizers\\r\\nMy inhaler isnt working and I need a new one asap.\\r\\n20,000 surgical masks in stock now.\\r\\nB737-700 Cargo operation stripping out passenger cabin seats to load cartons of medical supplies of personal protective equipment (PPE)\\r\\n1,000,000 Nitrile gloves just arrived in stock. Severe worldwide shortage.\\r\\nChina's Ministry of Defense donated to Brunei medical supplies including masks, goggles, protective clothing, waterproof isolation suits, etc.\\r\\nCovid - medical supplies ecommerce shop website template is for selling first aid items, PPE or any other essential medical supplies. \\r\\nFor anyone looking for PPE Supplies, my company has made it more accessible to the public.\\r\\nHand Sanitizer, it don't need to wash with water and quick dry. \\r\\nPlace an order for our anti-bacterial hand-wipes!\\r\\nSanitizers 8 ounce available at Neptunes\\r\\nFor $50 you can sponsor 25 masks including shipping and materials for our sewists. Any amount will be greatly appreciated.\\r\\nFace masks, Sanitizer, Gloves,Thermometers.\\r\\nHealthcare operations including hospitals/clinics, research and laboratory operations, nursing homes, residential health care facilities, congregate care facilities, assisted living facilities\\r\\nelder care, medical wholesale and distribution, home health workers and aides, medical supply and medical waste disposal, hazardous waste disposal, other ancillary healthcare services\",\n",
       "  '5 people trapped with no internet in my locality\\r\\nrequesting mobile recharge for 2 phones\\r\\nnetwork coverage is weak in my house\\r\\nno connectivity in wifi router due to some wiring problem.\\r\\nI am not able to call helplines\\r\\nis it possible to deliver a phone in kormangla as mine is not working\\r\\ndue to sim card issue I was unable to create hotspot\\r\\nthe network tower broken down in Whitefield\\r\\ncalls are not connecting from airtel\\r\\nI was trying to connect to my family. someone please guide me.\\r\\nWhy governement is not spending money to improve the communication services in India?\\r\\nWhy call center/customer care of COVID19-HelpCare do not respond on time.\\r\\nHelplines numbers are not working properly. Please update them.\\r\\nTower in my area has sparking issues.\\r\\nNo helpline is responding but we need to get this heard to the authorities as soon as possible.\\r\\nWhenever i try to reach some authorities from governement they just hang the call and don\\'t respond. I am really irritated by this behaviour.\\r\\nTelecom companies have raised the prices of net pack so much that they are not affordable.\\r\\nInternet facility provided at railway station is so bad that i am not even able to buy groceries online.\\r\\nThere has been transformer fault in our area and none of our devices are working and all our phones are discharged and we failed to contact anyone to request for repair for many days now.\\r\\nAll electricity is down in my society due to which all electronic devices are off. Phone, wifi laptop all shut\\r\\nDue to poor network in remote area we are unable to attend class regularly\\r\\nAfrica races to fill telecoms \"not spots\": Resourceful medical services use 3G and 2G signals to overcome poor network coverage.\\r\\nam I the only one that has poor network ?\\r\\nAmazing bundles are good unfortunately the free WhatsApp part doesn\\'t work when the bundles is depleted. Secondly in my current place the Airtel network is very poor\\r\\nAtleast they should not set time limit as in remote cities , network connections are poor and all students cant afford latest  laptops smartphones and scanners andeven it is  not feasible to get it repaired during this covid 19 crisis,future of students  is at stake due to technology\\r\\nCan you up your game in network? Very slow and poor network. Don\\'t lure us yet when we buy the bundles, it takes decates to load\"\\r\\nCommunication is key, more so during this pandemic. If your charity needs help making sure your comms is up to scratch, head over to Media Trust\\'s Volunteer Platform and post an opportunity request to be matched with an expert comms volunteer.\\r\\ndd national and dd retro the network is very poor, regularly goes off. DDNational should upgrade the system while launching new channel\\r\\ndo we do this?  Communication.  People need to find information from the CDC or Fauci and make sure it is tweeted several times until it is picked up and retweeted several times.  Tweet to the news and request they help us get the info.\\r\\nfacing poor network and slow speed issue.\\r\\nGuys my net connection since morning isn\\'t working and all modes of communication to reach out to you aren\\'t working.\\r\\nHello team I am using airtel number but network is very poor. Kindly rectify as soon as possible. U give lot advertising from forest airtel give good network but u r not able to proved in city.\\r\\nHi I have Airtel Prepaid, since today morning there is  no  network showing on my mobile also tried with different handset still not showing seems there is an issue with my number only I am struggling to get support. Kindly help asap.\\r\\nHi my name is Rasmi Ranjan Sahoo  and my mob no is 7788914484 and I am a Airtel user. From last 2months I had face lots of network issue and I also try to connect with your customercare but unable to connect with them your team always say due to COVID-19 situation \\r\\nHope you consider this request, infact online delivery of these essential goods will also not create crowd and chaos and it will help efficient work from home as many are struggling with these items like charger, headphones, etc.\\r\\nHow much time do you cheat people like this. This is the screenshot of result which I got for data speed test in NetVelocity. Providing poor data speed and showing no speed in result. Better I will port my Network from reliancejio to idea_cares \\r\\nI am still experiencing a very poor connection! No one has contacted me. This network is pathetic! How are you still charging people when you can\\'t deliver on your service?\\r\\nI have placed request for new BHARAT Broadband connection, no any communication feom sangli office, even unable to contact them to know the status.\\r\\nI have tried to request help by all means of communication to airte lindia but all in vain.\\r\\nI thank for adding 3 more helpline numbers to ease communication of the stranded migrants with our state level help desk.\\r\\nI want to ask i have pending two month electricity bill..fir to covid and fund issue not able to pay bill... Please let me know if I do not make payment than will u disconnect line?.also request you to please wevied off inetrest charges....please help\"\\r\\nI was trying to Livestream it but Etisalat network is really poor.\\r\\nIdea very poor network. They said i will be getting 4g speed but in reality i am not even getting 2g . And in the app if we chat about the same with chat boot it says that the data limit is over. very bad n worst experience.\\r\\nInstead of telecasting more news about Corona pls start an initiative by conducting webinar sessions for 10th and PUC students ( any subject) This will help the ppl in greater way. Thanks\\r\\nIts been a week with no Vodacom network in Palma, Cabo Delgado, the ballons went dead\\r\\nIve called an average of 400+ times every day for over 3.5 weeks/have never spoken to a human being/Had issues with communication and missed my payment request date/over 3 weeks/what do I do? I need help/It won\\'t let me request payment for 1.5 months now.\\r\\nlast Sunday I paid for the renewal of my broadband. After receiving the service request, there no further communication! Personal not taking my calls / not responding to WhatsApp... Pls help\\r\\nlight off, network poor , mobile battery  low .see u again .follow me i will give u fb. Thank you every one.\\r\\nMy postpaid Airtel sim stopped working  this afternoon . No network coverage available as it says insert sim. Got a call from airtel rep saying Airtel stores are closed.what to do next? Pls help\\r\\nNetwork is very poor even not talk more than 8 sec in a single call. Every time we connect call disconnect within 5-8 sec. Location is Bihar, Dist- West Champaran, PS- Chanpatia, Vill-Pokharia Rai\\r\\nPhone communication may help clarify the request and whether or not we can \"designate\" an account in accordance with VA regulations.\\r\\nPlease do something about your network tower at Candolim Goa. The signal strength is so poor that the internet won\\'t work at all.\\r\\nPoor Network Airtel at Assam, Silchar, Nagatila. airtelindia I am recharged huge amount but doesn\\'t good network and I couldn\\'t open any apps, browser. I don\\'t like. please improve whatever I can.\\r\\npoor Network Airtel India. I couldn\\'t open any browse and apps. I didn\\'t play any game esily. only connection error.\\r\\nPoor network service from Airtel since last 1 years. Poor calling due to call drop issues and poor internet\\r\\nPossible to send email/txt confirmation on connection request ? In current situation, manpower shortage is understandable. But some communication on collected email+ph no. is fair ask. \\r\\nSo fed up with virginmedia Whenever I\\'m watching a movie on demand it suddenly stops with a network availability error. I pay so much for a service that is so poor. Am seriously considering giving up on them. Can\\'t stand the constant price increases with decreases in service.\\r\\nToo much bad network in my area a lot of tower available but the facility is very poor all network facility is very poor and everyone is not getting speed\\r\\ntoo much poor network in my area from past one week. a 3 mb file taking cou0le of minutes to download. cant surf youtube, insta\\r\\nVodacom SMS we do receive and can send but it\\'s not easy, it is difficult to make or receive phone calls, we always get voice mail notifications. We hardly surf the net due to poor network coverage. 1 minute you have access the other minute dololo.\\r\\nWhat kind of poor internet airtel provides now I understand why JIO is better network than Airtel.\\r\\nWhat we want is a constant and reliable network.not a network which disappoints you at the middle of a conversation.develop your network. it is so poor\\r\\nwhen will u call me?? who will compensate for my 1 day data loss? Moreover, your network is so poor that sometimes i feel like changing the network.\\r\\nWhy why poor connection network daily Airtel. I am recharge regularly but I couldn\\'t browse and open any apps, I don\\'t play pubg, any game\\r\\nwriting on behalf of my brother in Bengaluru. The Airtel network connection in his area ( Thala Kaveri layout) is poor and inconsistent. He has registered a complaint and no response yet. Can you please look into it and suggest solutions? Kindly help.',\n",
       "  \"there are drums of flammable oil stored in our locality. Is it possible to store them elsewhere\\r\\nthere has ben a leakage in gas pipeline for the past few days. Cant find professionals to fix it.\\r\\nReduce oil prices immidiately\\r\\nFrequent power cut in the area \\r\\nFuel is precious. Please use it wisely.\\r\\nIn upcoming days CNG usage will rise to more than petrol and diesel.\\r\\nThere was sparking in my electric generator due to fuel leakage.\\r\\nI can hear voices of crying children from my neighbor. I think they are being abused.\\r\\nYesterday i saw few people bullying a person from my locality.\\r\\nWas passing by the vathur bus stop and a group of boys teased me.\\r\\nI feel that someone is going to break in and kill me.\\r\\nThe only shop in my area is charging very high prices for items.\\r\\nAn old man is getting abused by his family\\r\\nSomeone is continuously following me. Feeling scared.\\r\\nI saw bruises on my maid face. I think she is a victim of domestic violence.\\r\\nDue to lack in any means of transport horse cart owner is charging very high prices.\\r\\nMy father is ill treated.\\r\\nI recently came to know that my brother is adopted and that's why he is ill treated by my parents.\\r\\nNearby shops are charging way beyond the MRP prices.\\r\\nDevesh was beating Aabhas with rod stick.\\r\\nThese days students are learning to bully from school itself.\\r\\nPolice assaulted senior citizen for not having proper documents.\\r\\nMedia houses have to much of liberty and they harass people a lot.\\r\\nMy neighbor, Mr. Rao is a salesman who is frustrated due to no income and he fights with his wife, shouts horribly and breaks things almost everyday\\r\\nAn elderly man in our locality is hateful of the entire family and even the shopkeepers harass them by refusing to sell items to them.\\r\\n3 people have crashed in my neighbors house for some money matter.\\r\\nSoon, the local social media fills with xenophobia and hate, along with demands that the foreigners go back to where they came from.\\r\\nAll of you are missing the point. One wrong does not justify another wrong. If you say that  Muslims are spreading  hate , so are you by citing selected verses from  Quran. How can you condemn something while doing exactly the same yourselves. It is  hypocrisy \\r\\nCrazy white woman terrorizing brown people racism\\r\\nIn this webinar, ryanmauro speaks to former jihadist JesseMorton and former neo-nazi  SchoepJeff to discuss how extremists are using the current  pandemic to justify  Antisemitism and how they find a common focus of their hate-filled ideologies.\\r\\nOur children are traumatized on so many levels by this quarantine from Covid-19.\\r\\nrape by parents and relatives is now common; where then will the generation of  girls find refuge. One who is supposed to be protecting you from  sexual  physical and  emotional  abuse victimizes you; where is  social protection Who then shall we trust? \\r\\nShe is an absolute  arrogant  disgrace -  shameful and no respect for the gentleman she was interviewing. She planned to gang up on him and hit him hard - lack of  rational sense was from her. Pure  hate from her.  she is a disgrace.\\r\\nThink there's a minority who have an issue with  NHS staff as I got verbally abused in a store - a woman shouted in my face as she pushed me to go in a queue. When I brought my ID out to get discount she shouted oh clap for the NHS hero amongst other things\\r\\nTook me years to realise. It isn't ok! If the Warning signs show, get out from abuse!\\r\\nThey lost their jobs due to COVID-19. Request you to pls help them.\\r\\nI lost my job due to this sudden covid outbreak.\\r\\nEconomic downfall will soon create job crises.\\r\\nEmployee are not happy with the relief funds provided.\\r\\nemi should be reduced and less interest rate should be charged on loans and other policies.\\r\\ntv news channel focus more on fake news.\\r\\nwork from home should be manditory for all companies\"],\n",
       " 'filenames': array(['dataset_small_less_categories_v2\\\\travel\\\\travel.txt',\n",
       "        'dataset_small_less_categories_v2\\\\food\\\\food.txt',\n",
       "        'dataset_small_less_categories_v2\\\\essential_items\\\\essential_items.txt',\n",
       "        'dataset_small_less_categories_v2\\\\healthcare\\\\healthcare.txt',\n",
       "        'dataset_small_less_categories_v2\\\\communication\\\\communication.txt',\n",
       "        'dataset_small_less_categories_v2\\\\others\\\\others.txt'],\n",
       "       dtype='<U68'),\n",
       " 'target_names': ['communication',\n",
       "  'essential_items',\n",
       "  'food',\n",
       "  'healthcare',\n",
       "  'others',\n",
       "  'travel'],\n",
       " 'target': array([5, 2, 1, 3, 0, 4]),\n",
       " 'DESCR': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I want to travel back to my native place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Want curfew pass for case of emergency travel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I had started towards my home 120 km away on my car.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Firstline workers facing issues as no cabs are available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Want to go back to my family place. Currently staying in the hotel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>4</td>\n",
       "      <td>Economic downfall will soon create job crises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>4</td>\n",
       "      <td>Employee are not happy with the relief funds provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4</td>\n",
       "      <td>emi should be reduced and less interest rate should be charged on loans and other policies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>4</td>\n",
       "      <td>tv news channel focus more on fake news.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>4</td>\n",
       "      <td>work from home should be manditory for all companies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  \\\n",
       "0       5   \n",
       "1       5   \n",
       "2       5   \n",
       "3       5   \n",
       "4       5   \n",
       "..    ...   \n",
       "333     4   \n",
       "334     4   \n",
       "335     4   \n",
       "336     4   \n",
       "337     4   \n",
       "\n",
       "                                                                                            text  \n",
       "0                                                      I want to travel back to my native place.  \n",
       "1                                                 Want curfew pass for case of emergency travel.  \n",
       "2                                           I had started towards my home 120 km away on my car.  \n",
       "3                                       Firstline workers facing issues as no cabs are available  \n",
       "4                            Want to go back to my family place. Currently staying in the hotel.  \n",
       "..                                                                                           ...  \n",
       "333                                               Economic downfall will soon create job crises.  \n",
       "334                                       Employee are not happy with the relief funds provided.  \n",
       "335  emi should be reduced and less interest rate should be charged on loans and other policies.  \n",
       "336                                                     tv news channel focus more on fake news.  \n",
       "337                                         work from home should be manditory for all companies  \n",
       "\n",
       "[338 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "data=[]\n",
    "length=len(df)\n",
    "\n",
    "for i in range(length * 10):\n",
    "    num1 = i % length\n",
    "    num2 = num1\n",
    "    while (num1 == num2):\n",
    "        num2=random.randrange(length)\n",
    "    data.append([df.label[num1],df.label[num2],df.text[num1] + ' ' + df.text[num2]])\n",
    "    \n",
    "for i in range(length):\n",
    "    data.append([df['label'][i], df['label'][i], df['text'][i]])     \n",
    "df2 = pd.DataFrame(data, columns=['label1','label2', 'text'])\n",
    "#df2.append(pd.DataFrame([df['label'], df['label'], df['text']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    815\n",
       "0    750\n",
       "2    676\n",
       "5    646\n",
       "4    436\n",
       "1    395\n",
       "Name: label2, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['label2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['communication', 'essential_items', 'food', 'healthcare', 'others', 'travel']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>She is an absolute  arrogant  disgrace -  shameful and no respect for the gentleman she was interviewing. She planned to gang up on him and hit him hard - lack of  rational sense was from her. Pur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Think there's a minority who have an issue with  NHS staff as I got verbally abused in a store - a woman shouted in my face as she pushed me to go in a queue. When I brought my ID out to get disco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Took me years to realise. It isn't ok! If the Warning signs show get out from abuse!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>They lost their jobs due to COVID-19. Request you to pls help them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>I lost my job due to this sudden covid outbreak.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Economic downfall will soon create job crises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Employee are not happy with the relief funds provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>emi should be reduced and less interest rate should be charged on loans and other policies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>tv news channel focus more on fake news.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>work from home should be manditory for all companies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label1  label2  \\\n",
       "3708       4       4   \n",
       "3709       4       4   \n",
       "3710       4       4   \n",
       "3711       4       4   \n",
       "3712       4       4   \n",
       "3713       4       4   \n",
       "3714       4       4   \n",
       "3715       4       4   \n",
       "3716       4       4   \n",
       "3717       4       4   \n",
       "\n",
       "                                                                                                                                                                                                         text  \n",
       "3708  She is an absolute  arrogant  disgrace -  shameful and no respect for the gentleman she was interviewing. She planned to gang up on him and hit him hard - lack of  rational sense was from her. Pur...  \n",
       "3709  Think there's a minority who have an issue with  NHS staff as I got verbally abused in a store - a woman shouted in my face as she pushed me to go in a queue. When I brought my ID out to get disco...  \n",
       "3710                                                                                                                     Took me years to realise. It isn't ok! If the Warning signs show get out from abuse!  \n",
       "3711                                                                                                                                      They lost their jobs due to COVID-19. Request you to pls help them.  \n",
       "3712                                                                                                                                                         I lost my job due to this sudden covid outbreak.  \n",
       "3713                                                                                                                                                           Economic downfall will soon create job crises.  \n",
       "3714                                                                                                                                                   Employee are not happy with the relief funds provided.  \n",
       "3715                                                                                                              emi should be reduced and less interest rate should be charged on loans and other policies.  \n",
       "3716                                                                                                                                                                 tv news channel focus more on fake news.  \n",
       "3717                                                                                                                                                     work from home should be manditory for all companies  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_csv('dataset_multi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "filter_POS = set(['NOUN', 'NUM', 'ADJ', 'VERB', 'PART'])\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# ADV, NOUN, ADP, PRON, SCONJ, PROPN, DET, SYM, INTJ\n",
    "# PUNCT, NUM, AUX, X, CONJ, ADJ, VERB, PART, SPACE, CCONJ\n",
    "# def filter_query(query):\n",
    "#     query = query.lower()\n",
    "#     doc = nlp(query)\n",
    "#     tokens = [t.text for t in doc if t.pos_ in filter_POS]\n",
    "#     return ' '.join(tokens)\n",
    "gc = 0\n",
    "def filter_query(query):\n",
    "    query = query.lower()\n",
    "    query = re.sub(r'[\\t\\n\\r\\f ]+', ' ', re.sub(r'\\.', '. ', query))\n",
    "    # print (query)\n",
    "    doc = nlp(query)\n",
    "    if len(doc) > 6:\n",
    "        tokens = [t.text for t in doc if t.pos_ in filter_POS]\n",
    "    else:\n",
    "        tokens = [t.text for t in doc]\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    filt_q = ' '.join(tokens)\n",
    "    filt_q = re.sub(r'\\b(n\\'t|nt)\\b', 'not', filt_q)\n",
    "    filt_q = re.sub(r'\\'ll\\b', 'will', filt_q)\n",
    "    return filt_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3718,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text_'] = df2['text']\n",
    "df2['text'] = df2['text'].apply(filter_query)\n",
    "\n",
    "# df['text_'] = df['text']\n",
    "# df['text'] = df['text'].apply(filter_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_ = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>want to travel native place toilet paper bar soap liquid soap toothpaste facial tissue shampoo</td>\n",
       "      <td>I want to travel back to my native place. toilet paper bar soap liquid soap toothpaste facial tissue shampoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>want curfew pas case emergency travel want to ask pending two month electricity bill fir fund issue not able to pay bill let know not make payment will disconnect line request to please wevied ine...</td>\n",
       "      <td>Want curfew pass for case of emergency travel. I want to ask i have pending two month electricity bill..fir to covid and fund issue not able to pay bill... Please let me know if I do not make paym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>started home 120 km car adequate stockpile necessary medical supply type contingency known generation situation arise capitalism not safeguard public health</td>\n",
       "      <td>I had started towards my home 120 km away on my car. There have never been adequate stockpiles of necessary medical supplies for this type of contingency even though it's been known for generation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>firstline worker facing issue cab available reduce oil price</td>\n",
       "      <td>Firstline workers facing issues as no cabs are available Reduce oil prices immidiately</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>want to go family place staying hotel food poisoning eating old distributed item</td>\n",
       "      <td>Want to go back to my family place. Currently staying in the hotel. food poisoning by eating old distributed items</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>economic downfall will create job crisis</td>\n",
       "      <td>Economic downfall will soon create job crises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>employee not happy relief fund provided</td>\n",
       "      <td>Employee are not happy with the relief funds provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>should reduced le interest rate should charged loan other policy</td>\n",
       "      <td>emi should be reduced and less interest rate should be charged on loans and other policies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>focus fake news</td>\n",
       "      <td>tv news channel focus more on fake news.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>work home should manditory company</td>\n",
       "      <td>work from home should be manditory for all companies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3718 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label1  label2  \\\n",
       "0          5       1   \n",
       "1          5       0   \n",
       "2          5       3   \n",
       "3          5       4   \n",
       "4          5       3   \n",
       "...      ...     ...   \n",
       "3713       4       4   \n",
       "3714       4       4   \n",
       "3715       4       4   \n",
       "3716       4       4   \n",
       "3717       4       4   \n",
       "\n",
       "                                                                                                                                                                                                         text  \\\n",
       "0                                                                                                              want to travel native place toilet paper bar soap liquid soap toothpaste facial tissue shampoo   \n",
       "1     want curfew pas case emergency travel want to ask pending two month electricity bill fir fund issue not able to pay bill let know not make payment will disconnect line request to please wevied ine...   \n",
       "2                                                started home 120 km car adequate stockpile necessary medical supply type contingency known generation situation arise capitalism not safeguard public health   \n",
       "3                                                                                                                                                firstline worker facing issue cab available reduce oil price   \n",
       "4                                                                                                                            want to go family place staying hotel food poisoning eating old distributed item   \n",
       "...                                                                                                                                                                                                       ...   \n",
       "3713                                                                                                                                                                 economic downfall will create job crisis   \n",
       "3714                                                                                                                                                                  employee not happy relief fund provided   \n",
       "3715                                                                                                                                         should reduced le interest rate should charged loan other policy   \n",
       "3716                                                                                                                                                                                          focus fake news   \n",
       "3717                                                                                                                                                                       work home should manditory company   \n",
       "\n",
       "                                                                                                                                                                                                        text_  \n",
       "0                                                                                                I want to travel back to my native place. toilet paper bar soap liquid soap toothpaste facial tissue shampoo  \n",
       "1     Want curfew pass for case of emergency travel. I want to ask i have pending two month electricity bill..fir to covid and fund issue not able to pay bill... Please let me know if I do not make paym...  \n",
       "2     I had started towards my home 120 km away on my car. There have never been adequate stockpiles of necessary medical supplies for this type of contingency even though it's been known for generation...  \n",
       "3                                                                                                                      Firstline workers facing issues as no cabs are available Reduce oil prices immidiately  \n",
       "4                                                                                          Want to go back to my family place. Currently staying in the hotel. food poisoning by eating old distributed items  \n",
       "...                                                                                                                                                                                                       ...  \n",
       "3713                                                                                                                                                           Economic downfall will soon create job crises.  \n",
       "3714                                                                                                                                                   Employee are not happy with the relief funds provided.  \n",
       "3715                                                                                                              emi should be reduced and less interest rate should be charged on loans and other policies.  \n",
       "3716                                                                                                                                                                 tv news channel focus more on fake news.  \n",
       "3717                                                                                                                                                     work from home should be manditory for all companies  \n",
       "\n",
       "[3718 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2, df2['label2'], test_size=0.2)\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# X_train.reset_index(drop=True)\n",
    "# X_test.reset_index(drop=True)\n",
    "# y_train.reset_index(drop=True)\n",
    "# y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "main=[]\n",
    "for i in range(len(X_train)):\n",
    "    arr=np.array([X_train['label1'][i],X_train['label2'][i]])\n",
    "    main.append(arr)\n",
    "    \n",
    "# main=[]\n",
    "# for i in range(len(X_train)):\n",
    "#     arr=np.array([X_train['label'][i]])\n",
    "#     main.append(arr)\n",
    "    \n",
    "# # Create MultiLabelBinarizer object\n",
    "# one_hot = MultiLabelBinarizer()\n",
    "\n",
    "# One-hot encode data\n",
    "train_text = np.array(X_train, dtype=object)[:,2][:,np.newaxis]\n",
    "# train_label =np.asarray(one_hot.fit_transform(main), dtype = np.int8)\n",
    "\n",
    "train_label = np.zeros((X_train.shape[0], len(trainset.target)))\n",
    "for i in range(X_train.shape[0]):\n",
    "    train_label[i][main[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 1., 1., 0., 0.]),\n",
       " label1                                                                                                                                                                                                          3\n",
       " label2                                                                                                                                                                                                          2\n",
       " text                                     travelling met accident need medical assistance fractured leg today organized virtual event food security nutrition looking response early result to avert global crisis\n",
       " text_     I was travelling from karnataka to tamil nadu and met with an accident. I need medical assistance for my fractured leg. Today we organized a virtual event on food security and nutrition looking at...\n",
       " Name: 9, dtype: object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[9], X_train.loc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1], dtype=int64),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array(['number essential item bandaids gauze inhaler white sheet required 50 people'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main[10],train_label[10], train_text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "main=[]\n",
    "for i in range(len(X_test)):\n",
    "    arr=np.array([X_test['label1'][i],X_test['label2'][i]])\n",
    "    main.append(arr)\n",
    "    \n",
    "# main=[]\n",
    "# for i in range(len(X_test)):\n",
    "#     arr=np.array([X_test['label'][i]])\n",
    "#     main.append(arr)\n",
    "    \n",
    "# # Create MultiLabelBinarizer object\n",
    "# one_hot = MultiLabelBinarizer()\n",
    "\n",
    "test_text = np.array(X_test, dtype=object)[:,2][:,np.newaxis]\n",
    "# test_label = np.asarray(one_hot.fit_transform(main), dtype = np.int8)\n",
    "\n",
    "test_label = np.zeros((X_test.shape[0], len(trainset.target)))\n",
    "for i in range(X_test.shape[0]):\n",
    "    test_label[i][main[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['week network ballons went dead thyroiditis type autoimmune thyroid disease immune system attack change texture thyroid gland'\n",
      " 'edible supply not available area need bread grocery day student learning to bully school'\n",
      " 'need to take father hospital dialysis sparking electric generator fuel leakage got third degree burn'\n",
      " ... '5 people trapped internet locality'\n",
      " '6 people family food can give want to go family place staying hotel'\n",
      " 'wife construction worker not enough meal due shortage money weak unable to water storage container bulb tubelights battery charger plug required']\n"
     ]
    }
   ],
   "source": [
    "train_text_use = train_text[:, 0]\n",
    "test_text_use = test_text[:, 0]\n",
    "print (train_text_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = len(np.unique(df.label))\n",
    "module_url = \"../tf_sent_encoder_2\" \n",
    "embed = hub.Module(module_url, trainable=True)\n",
    "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-175-e8cecebc9479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "categories = trainset.target_names\n",
    "categories\n",
    "\n",
    "# from keras.layers import Concatenate\n",
    "\n",
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)),signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "# def sentence_encoder(input_text):\n",
    "#     return embed(tf.squeeze(input_text))\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(UniversalEmbedding,output_shape=(embed_size,))(input_text)\n",
    "dense1 = Dense(1024, activation='relu')(embedding)\n",
    "dense2 = Dense(128, activation='relu')(dense1)\n",
    "pred = []\n",
    "for c in categories:\n",
    "    pred.append(Dense(1, activation='sigmoid')(dense2))\n",
    "out = Concatenate()(pred)\n",
    "model = Model(inputs=[input_text], outputs=out)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "optimizer = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "0.0005\n"
     ]
    }
   ],
   "source": [
    "# def create_model(vocab_size, max_length):\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Embedding(vocab_size, 128,\n",
    "#             input_length = max_length,  trainable = False))\n",
    "#     model.add(Bidirectional(GRU(128)))\n",
    "#     model.add(Dense(64, activation = \"relu\"))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(64, activation = \"relu\"))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(21, activation = \"softmax\"))\n",
    "\n",
    "#     return model\n",
    "print (K.eval(model.optimizer.lr))\n",
    "K.set_value(model.optimizer.lr, 0.0005)\n",
    "print (K.eval(model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.0'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.initialize_all_variables().run(session=tf.keras.backend.get_session())\n",
    "hub.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2974 samples, validate on 744 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "[_Derived_]{{function_node __inference_pruned_9755}} {{function_node __inference_pruned_9755}} Attempting to use uninitialized value Embeddings_en/sharded_1\n\t [[{{node Embeddings_en/sharded_1/read}}]]\n\t [[keras_layer/StatefulPartitionedCall]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-0110ec4640fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m           callbacks=[es_callback, lr_tracker, reduce_lr])\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model20.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: [_Derived_]{{function_node __inference_pruned_9755}} {{function_node __inference_pruned_9755}} Attempting to use uninitialized value Embeddings_en/sharded_1\n\t [[{{node Embeddings_en/sharded_1/read}}]]\n\t [[keras_layer/StatefulPartitionedCall]]"
     ]
    }
   ],
   "source": [
    "K.set_session(session)\n",
    "class LearningRateTracker(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\" - lr: {}\".format(K.eval(self.model.optimizer.lr))) \n",
    "# session.run(tf.global_variables_initializer())\n",
    "# session.run(tf.tables_initializer())\n",
    "\n",
    "LR_PATIENCE = 10\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=LR_PATIENCE, min_lr=1e-8, verbose=1, mode=\"min\")\n",
    "es_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "lr_tracker = LearningRateTracker()\n",
    "\n",
    "history = model.fit(train_text_use, \n",
    "          train_label,\n",
    "          validation_data=(test_text_use, test_label),\n",
    "          epochs=1000,\n",
    "          batch_size=256,\n",
    "          callbacks=[es_callback, lr_tracker, reduce_lr])\n",
    "model.save_weights('./model20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 657,286\n",
      "Trainable params: 657,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ElmoEmbeddingLayer(x):\n",
    "# #     print(x.shape)\n",
    "#     module = hub.Module(\"../nnlm-en-dim128_1\", trainable=True)\n",
    "#     embeddings = module(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "#     return embeddings\n",
    "nnlm_dim=128\n",
    "nnlm_input = Input(shape=(), dtype=tf.string)\n",
    "# nnlm_embedding = Lambda(ElmoEmbeddingLayer, output_shape=(nnlm_dim,))(nnlm_input)\n",
    "nnlm_embedding = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\", output_shape=[128], input_shape=[], dtype=tf.string, trainable=False)(nnlm_input)\n",
    "x = Dense(512, activation='relu')(nnlm_embedding)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "out = Dense(len(categories), activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[nnlm_input], outputs=out)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "# model.fit(x_train, y_train, epochs=1,validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "optimizer = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "keras_layer_6 (KerasLayer)   (None, 128)               124642688 \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 124,974,470\n",
      "Trainable params: 331,782\n",
      "Non-trainable params: 124,642,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2974 samples, validate on 744 samples\n",
      "Epoch 1/1000\n",
      "2974/2974 [==============================] - 7s 2ms/step - loss: 0.5890 - acc: 0.6899 - val_loss: 0.5127 - val_acc: 0.7507\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 2/1000\n",
      "2974/2974 [==============================] - 1s 206us/step - loss: 0.4466 - acc: 0.8121 - val_loss: 0.3823 - val_acc: 0.8434\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 3/1000\n",
      "2974/2974 [==============================] - 1s 181us/step - loss: 0.3299 - acc: 0.8677 - val_loss: 0.3035 - val_acc: 0.8853\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 4/1000\n",
      "2974/2974 [==============================] - 1s 174us/step - loss: 0.2647 - acc: 0.8976 - val_loss: 0.2601 - val_acc: 0.8985\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 5/1000\n",
      "2974/2974 [==============================] - 0s 163us/step - loss: 0.2278 - acc: 0.9110 - val_loss: 0.2360 - val_acc: 0.9140\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 6/1000\n",
      "2974/2974 [==============================] - 1s 182us/step - loss: 0.2045 - acc: 0.9206 - val_loss: 0.2184 - val_acc: 0.9191\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 7/1000\n",
      "2974/2974 [==============================] - 0s 167us/step - loss: 0.1869 - acc: 0.9276 - val_loss: 0.2044 - val_acc: 0.9245\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 8/1000\n",
      "2974/2974 [==============================] - 1s 178us/step - loss: 0.1727 - acc: 0.9333 - val_loss: 0.1960 - val_acc: 0.9301\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 9/1000\n",
      "2974/2974 [==============================] - 0s 161us/step - loss: 0.1593 - acc: 0.9400 - val_loss: 0.1858 - val_acc: 0.9323\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 10/1000\n",
      "2974/2974 [==============================] - 1s 180us/step - loss: 0.1503 - acc: 0.9430 - val_loss: 0.1768 - val_acc: 0.9335\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 11/1000\n",
      "2974/2974 [==============================] - 1s 186us/step - loss: 0.1411 - acc: 0.9469 - val_loss: 0.1714 - val_acc: 0.9373\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 12/1000\n",
      "2974/2974 [==============================] - 1s 192us/step - loss: 0.1328 - acc: 0.9500 - val_loss: 0.1665 - val_acc: 0.9386\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 13/1000\n",
      "2974/2974 [==============================] - 1s 223us/step - loss: 0.1232 - acc: 0.9553 - val_loss: 0.1582 - val_acc: 0.9442\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 14/1000\n",
      "2974/2974 [==============================] - 1s 199us/step - loss: 0.1161 - acc: 0.9585 - val_loss: 0.1527 - val_acc: 0.9453\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 15/1000\n",
      "2974/2974 [==============================] - 1s 278us/step - loss: 0.1113 - acc: 0.9602 - val_loss: 0.1569 - val_acc: 0.9420\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 16/1000\n",
      "2974/2974 [==============================] - 1s 186us/step - loss: 0.1040 - acc: 0.9625 - val_loss: 0.1449 - val_acc: 0.9483\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 17/1000\n",
      "2974/2974 [==============================] - 1s 170us/step - loss: 0.0984 - acc: 0.9662 - val_loss: 0.1433 - val_acc: 0.9494\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 18/1000\n",
      "2974/2974 [==============================] - 1s 210us/step - loss: 0.0907 - acc: 0.9686 - val_loss: 0.1369 - val_acc: 0.9527\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 19/1000\n",
      "2974/2974 [==============================] - 1s 215us/step - loss: 0.0857 - acc: 0.9707 - val_loss: 0.1355 - val_acc: 0.9527\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 20/1000\n",
      "2974/2974 [==============================] - 1s 210us/step - loss: 0.0842 - acc: 0.9723 - val_loss: 0.1319 - val_acc: 0.9539\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 21/1000\n",
      "2974/2974 [==============================] - 1s 219us/step - loss: 0.0757 - acc: 0.9762 - val_loss: 0.1245 - val_acc: 0.9574\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 22/1000\n",
      "2974/2974 [==============================] - 1s 189us/step - loss: 0.0703 - acc: 0.9788 - val_loss: 0.1221 - val_acc: 0.9590\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 23/1000\n",
      "2974/2974 [==============================] - 1s 224us/step - loss: 0.0656 - acc: 0.9800 - val_loss: 0.1189 - val_acc: 0.9579\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 24/1000\n",
      "2974/2974 [==============================] - 1s 227us/step - loss: 0.0614 - acc: 0.9823 - val_loss: 0.1167 - val_acc: 0.9610\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 25/1000\n",
      "2974/2974 [==============================] - 1s 205us/step - loss: 0.0570 - acc: 0.9839 - val_loss: 0.1144 - val_acc: 0.9621\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 26/1000\n",
      "2974/2974 [==============================] - 1s 212us/step - loss: 0.0524 - acc: 0.9854 - val_loss: 0.1099 - val_acc: 0.9637\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 27/1000\n",
      "2974/2974 [==============================] - 1s 219us/step - loss: 0.0505 - acc: 0.9880 - val_loss: 0.1071 - val_acc: 0.9624\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 28/1000\n",
      "2974/2974 [==============================] - 1s 196us/step - loss: 0.0473 - acc: 0.9883 - val_loss: 0.1034 - val_acc: 0.9633\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 29/1000\n",
      "2974/2974 [==============================] - 1s 192us/step - loss: 0.0431 - acc: 0.9890 - val_loss: 0.1009 - val_acc: 0.9646\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 30/1000\n",
      "2974/2974 [==============================] - 1s 219us/step - loss: 0.0400 - acc: 0.9911 - val_loss: 0.1000 - val_acc: 0.9657\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 31/1000\n",
      "2974/2974 [==============================] - 1s 254us/step - loss: 0.0379 - acc: 0.9908 - val_loss: 0.0956 - val_acc: 0.9673\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 32/1000\n",
      "2974/2974 [==============================] - 1s 201us/step - loss: 0.0343 - acc: 0.9931 - val_loss: 0.0956 - val_acc: 0.9673\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 33/1000\n",
      "2974/2974 [==============================] - 1s 206us/step - loss: 0.0327 - acc: 0.9935 - val_loss: 0.0928 - val_acc: 0.9686\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 34/1000\n",
      "2974/2974 [==============================] - 1s 223us/step - loss: 0.0303 - acc: 0.9939 - val_loss: 0.0902 - val_acc: 0.9673\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 35/1000\n",
      "2974/2974 [==============================] - 1s 186us/step - loss: 0.0284 - acc: 0.9948 - val_loss: 0.0897 - val_acc: 0.9686\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 36/1000\n",
      "2974/2974 [==============================] - 1s 178us/step - loss: 0.0274 - acc: 0.9950 - val_loss: 0.0908 - val_acc: 0.9691\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 37/1000\n",
      "2974/2974 [==============================] - 1s 176us/step - loss: 0.0241 - acc: 0.9955 - val_loss: 0.0849 - val_acc: 0.9700\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 38/1000\n",
      "2974/2974 [==============================] - 1s 171us/step - loss: 0.0237 - acc: 0.9957 - val_loss: 0.0852 - val_acc: 0.9713\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 39/1000\n",
      "2974/2974 [==============================] - 1s 174us/step - loss: 0.0218 - acc: 0.9962 - val_loss: 0.0836 - val_acc: 0.9709\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 40/1000\n",
      "2974/2974 [==============================] - 1s 169us/step - loss: 0.0200 - acc: 0.9973 - val_loss: 0.0816 - val_acc: 0.9720\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 41/1000\n",
      "2974/2974 [==============================] - 1s 196us/step - loss: 0.0184 - acc: 0.9971 - val_loss: 0.0818 - val_acc: 0.9727\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 42/1000\n",
      "2974/2974 [==============================] - 1s 199us/step - loss: 0.0168 - acc: 0.9979 - val_loss: 0.0798 - val_acc: 0.9709\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 43/1000\n",
      "2974/2974 [==============================] - 1s 217us/step - loss: 0.0160 - acc: 0.9978 - val_loss: 0.0795 - val_acc: 0.9733\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 44/1000\n",
      "2974/2974 [==============================] - 1s 220us/step - loss: 0.0147 - acc: 0.9986 - val_loss: 0.0804 - val_acc: 0.9731\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 45/1000\n",
      "2974/2974 [==============================] - 1s 197us/step - loss: 0.0144 - acc: 0.9984 - val_loss: 0.0772 - val_acc: 0.9729\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 46/1000\n",
      "2974/2974 [==============================] - 1s 183us/step - loss: 0.0130 - acc: 0.9987 - val_loss: 0.0762 - val_acc: 0.9738\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 47/1000\n",
      "2974/2974 [==============================] - 1s 258us/step - loss: 0.0126 - acc: 0.9990 - val_loss: 0.0740 - val_acc: 0.9738\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 48/1000\n",
      "2974/2974 [==============================] - 1s 242us/step - loss: 0.0118 - acc: 0.9990 - val_loss: 0.0753 - val_acc: 0.9738\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2974/2974 [==============================] - 1s 302us/step - loss: 0.0111 - acc: 0.9992 - val_loss: 0.0762 - val_acc: 0.9738\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 50/1000\n",
      "2974/2974 [==============================] - 1s 270us/step - loss: 0.0108 - acc: 0.9991 - val_loss: 0.0737 - val_acc: 0.9747\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 51/1000\n",
      "2974/2974 [==============================] - 1s 266us/step - loss: 0.0104 - acc: 0.9993 - val_loss: 0.0738 - val_acc: 0.9749\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 52/1000\n",
      "2974/2974 [==============================] - 1s 264us/step - loss: 0.0096 - acc: 0.9992 - val_loss: 0.0740 - val_acc: 0.9760\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 53/1000\n",
      "2974/2974 [==============================] - 1s 252us/step - loss: 0.0093 - acc: 0.9991 - val_loss: 0.0745 - val_acc: 0.9747\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 54/1000\n",
      "2974/2974 [==============================] - 1s 258us/step - loss: 0.0088 - acc: 0.9993 - val_loss: 0.0729 - val_acc: 0.9751\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 55/1000\n",
      "2974/2974 [==============================] - 1s 201us/step - loss: 0.0086 - acc: 0.9993 - val_loss: 0.0707 - val_acc: 0.9767\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 56/1000\n",
      "2974/2974 [==============================] - 1s 196us/step - loss: 0.0079 - acc: 0.9993 - val_loss: 0.0711 - val_acc: 0.9751\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 57/1000\n",
      "2974/2974 [==============================] - 1s 195us/step - loss: 0.0073 - acc: 0.9993 - val_loss: 0.0709 - val_acc: 0.9758\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 58/1000\n",
      "2974/2974 [==============================] - 1s 197us/step - loss: 0.0073 - acc: 0.9992 - val_loss: 0.0718 - val_acc: 0.9756\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 59/1000\n",
      "2974/2974 [==============================] - 1s 209us/step - loss: 0.0070 - acc: 0.9993 - val_loss: 0.0716 - val_acc: 0.9758\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 60/1000\n",
      "2974/2974 [==============================] - 1s 215us/step - loss: 0.0068 - acc: 0.9993 - val_loss: 0.0722 - val_acc: 0.9756\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 61/1000\n",
      "2974/2974 [==============================] - 1s 233us/step - loss: 0.0067 - acc: 0.9993 - val_loss: 0.0729 - val_acc: 0.9749\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 62/1000\n",
      "2974/2974 [==============================] - 1s 205us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0716 - val_acc: 0.9758\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 63/1000\n",
      "2974/2974 [==============================] - 1s 201us/step - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0698 - val_acc: 0.9763\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 64/1000\n",
      "2974/2974 [==============================] - 1s 204us/step - loss: 0.0055 - acc: 0.9994 - val_loss: 0.0716 - val_acc: 0.9756\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 65/1000\n",
      "2974/2974 [==============================] - 1s 209us/step - loss: 0.0052 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9765\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 66/1000\n",
      "2974/2974 [==============================] - 1s 212us/step - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0695 - val_acc: 0.9767\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 67/1000\n",
      "2974/2974 [==============================] - 1s 196us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0704 - val_acc: 0.9760\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 68/1000\n",
      "2974/2974 [==============================] - 1s 170us/step - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0728 - val_acc: 0.9772\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 69/1000\n",
      "2974/2974 [==============================] - 1s 175us/step - loss: 0.0048 - acc: 0.9994 - val_loss: 0.0696 - val_acc: 0.9769\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 70/1000\n",
      "2974/2974 [==============================] - 0s 166us/step - loss: 0.0046 - acc: 0.9993 - val_loss: 0.0700 - val_acc: 0.9776\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 71/1000\n",
      "2974/2974 [==============================] - 1s 187us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0723 - val_acc: 0.9763\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 72/1000\n",
      "2974/2974 [==============================] - 1s 195us/step - loss: 0.0045 - acc: 0.9993 - val_loss: 0.0707 - val_acc: 0.9769\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 73/1000\n",
      "2974/2974 [==============================] - 1s 199us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0726 - val_acc: 0.9765\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 74/1000\n",
      "2974/2974 [==============================] - ETA: 0s - loss: 0.0039 - acc: 0.999 - 1s 188us/step - loss: 0.0040 - acc: 0.9994 - val_loss: 0.0699 - val_acc: 0.9778\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 75/1000\n",
      "2974/2974 [==============================] - 1s 201us/step - loss: 0.0041 - acc: 0.9993 - val_loss: 0.0708 - val_acc: 0.9774\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 76/1000\n",
      "2974/2974 [==============================] - 1s 217us/step - loss: 0.0044 - acc: 0.9993 - val_loss: 0.0701 - val_acc: 0.9772\n",
      " - lr: 0.0010000000474974513\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 77/1000\n",
      "2974/2974 [==============================] - 0s 162us/step - loss: 0.0037 - acc: 0.9994 - val_loss: 0.0692 - val_acc: 0.9772\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 78/1000\n",
      "2974/2974 [==============================] - 1s 176us/step - loss: 0.0033 - acc: 0.9995 - val_loss: 0.0689 - val_acc: 0.9785\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 79/1000\n",
      "2974/2974 [==============================] - 1s 195us/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.0698 - val_acc: 0.9783\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 80/1000\n",
      "2974/2974 [==============================] - 1s 177us/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.0702 - val_acc: 0.9778\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 81/1000\n",
      "2974/2974 [==============================] - 1s 178us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0694 - val_acc: 0.9774\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 82/1000\n",
      "2974/2974 [==============================] - 1s 221us/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0691 - val_acc: 0.9776\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 83/1000\n",
      "2974/2974 [==============================] - 1s 211us/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0697 - val_acc: 0.9783\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 84/1000\n",
      "2974/2974 [==============================] - 1s 226us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0691 - val_acc: 0.9792\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 85/1000\n",
      "2974/2974 [==============================] - ETA: 0s - loss: 0.0031 - acc: 0.999 - 1s 215us/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0704 - val_acc: 0.9783\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 86/1000\n",
      "2974/2974 [==============================] - 1s 217us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 0.0695 - val_acc: 0.9769\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 87/1000\n",
      "2974/2974 [==============================] - 1s 222us/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0694 - val_acc: 0.9792\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 88/1000\n",
      "2974/2974 [==============================] - 1s 172us/step - loss: 0.0033 - acc: 0.9994 - val_loss: 0.0719 - val_acc: 0.9772\n",
      " - lr: 0.0005000000237487257\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 89/1000\n",
      "2974/2974 [==============================] - 1s 189us/step - loss: 0.0029 - acc: 0.9996 - val_loss: 0.0690 - val_acc: 0.9789\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 90/1000\n",
      "2974/2974 [==============================] - 1s 181us/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0696 - val_acc: 0.9780\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 91/1000\n",
      "2974/2974 [==============================] - 1s 184us/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0693 - val_acc: 0.9783\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 92/1000\n",
      "2974/2974 [==============================] - 1s 203us/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0694 - val_acc: 0.9776\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 93/1000\n",
      "2974/2974 [==============================] - 1s 204us/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0694 - val_acc: 0.9780\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 94/1000\n",
      "2974/2974 [==============================] - 1s 226us/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0694 - val_acc: 0.9778\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 95/1000\n",
      "2974/2974 [==============================] - 1s 244us/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0696 - val_acc: 0.9780\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 96/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2974/2974 [==============================] - 1s 275us/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0693 - val_acc: 0.9778\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 97/1000\n",
      "2974/2974 [==============================] - 1s 262us/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0695 - val_acc: 0.9776\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 98/1000\n",
      "2974/2974 [==============================] - 1s 267us/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0693 - val_acc: 0.9785\n",
      " - lr: 0.0002500000118743628\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 99/1000\n",
      "2974/2974 [==============================] - 1s 254us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0696 - val_acc: 0.9787\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 100/1000\n",
      "2974/2974 [==============================] - 1s 261us/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0696 - val_acc: 0.9787\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 101/1000\n",
      "2974/2974 [==============================] - 1s 255us/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0693 - val_acc: 0.9776\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 102/1000\n",
      "2974/2974 [==============================] - 1s 244us/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0695 - val_acc: 0.9776\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 103/1000\n",
      "2974/2974 [==============================] - 1s 249us/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0695 - val_acc: 0.9776\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 104/1000\n",
      "2974/2974 [==============================] - 1s 209us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0696 - val_acc: 0.9780\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 105/1000\n",
      "2974/2974 [==============================] - 1s 242us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0695 - val_acc: 0.9776\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 106/1000\n",
      "2974/2974 [==============================] - 1s 230us/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0694 - val_acc: 0.9780\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 107/1000\n",
      "2974/2974 [==============================] - 1s 262us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0694 - val_acc: 0.9783\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 108/1000\n",
      "2974/2974 [==============================] - ETA: 0s - loss: 0.0025 - acc: 0.999 - 1s 271us/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0696 - val_acc: 0.9778\n",
      " - lr: 0.0001250000059371814\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 109/1000\n",
      "2974/2974 [==============================] - 1s 217us/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0695 - val_acc: 0.9776\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 110/1000\n",
      "2974/2974 [==============================] - 1s 256us/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0695 - val_acc: 0.9776\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 111/1000\n",
      "2974/2974 [==============================] - 1s 257us/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0695 - val_acc: 0.9778\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 112/1000\n",
      "2974/2974 [==============================] - 1s 173us/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0696 - val_acc: 0.9783\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 113/1000\n",
      "2974/2974 [==============================] - 1s 190us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0696 - val_acc: 0.9776\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 114/1000\n",
      "2974/2974 [==============================] - 1s 199us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0697 - val_acc: 0.9776\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 115/1000\n",
      "2974/2974 [==============================] - 1s 217us/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0696 - val_acc: 0.9776\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 116/1000\n",
      "2974/2974 [==============================] - 1s 244us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0695 - val_acc: 0.9778\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 117/1000\n",
      "2974/2974 [==============================] - 1s 242us/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0695 - val_acc: 0.9774\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 118/1000\n",
      "2974/2974 [==============================] - 1s 207us/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0695 - val_acc: 0.9785\n",
      " - lr: 6.25000029685907e-05\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 119/1000\n",
      "2974/2974 [==============================] - 1s 226us/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0695 - val_acc: 0.9778\n",
      " - lr: 3.125000148429535e-05\n",
      "Epoch 120/1000\n",
      "2974/2974 [==============================] - 1s 225us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0696 - val_acc: 0.9776\n",
      " - lr: 3.125000148429535e-05\n",
      "Epoch 121/1000\n",
      "2974/2974 [==============================] - 1s 233us/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0696 - val_acc: 0.9778\n",
      " - lr: 3.125000148429535e-05\n",
      "Epoch 122/1000\n",
      "2974/2974 [==============================] - 1s 216us/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0696 - val_acc: 0.9778\n",
      " - lr: 3.125000148429535e-05\n",
      "Epoch 123/1000\n",
      "2974/2974 [==============================] - 1s 251us/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0695 - val_acc: 0.9778\n",
      " - lr: 3.125000148429535e-05\n",
      "Epoch 124/1000\n",
      "2974/2974 [==============================] - 1s 211us/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0695 - val_acc: 0.9778\n",
      " - lr: 3.125000148429535e-05\n",
      "Epoch 125/1000\n",
      "2974/2974 [==============================] - 1s 215us/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0695 - val_acc: 0.9778\n",
      " - lr: 3.125000148429535e-05\n",
      "Epoch 126/1000\n",
      "2974/2974 [==============================] - 1s 229us/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0696 - val_acc: 0.9780\n",
      " - lr: 3.125000148429535e-05\n",
      "Epoch 127/1000\n",
      "2974/2974 [==============================] - 1s 230us/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0695 - val_acc: 0.9778\n",
      " - lr: 3.125000148429535e-05\n",
      "Epoch 128/1000\n",
      "2974/2974 [==============================] - 1s 239us/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0696 - val_acc: 0.9778\n",
      " - lr: 3.125000148429535e-05\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 00128: early stopping\n"
     ]
    }
   ],
   "source": [
    "# K.set_session(session)\n",
    "class LearningRateTracker(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\" - lr: {}\".format(K.eval(self.model.optimizer.lr))) \n",
    "# session.run(tf.global_variables_initializer())\n",
    "# session.run(tf.tables_initializer())\n",
    "\n",
    "LR_PATIENCE = 10\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=LR_PATIENCE, min_lr=1e-8, verbose=1, mode=\"min\")\n",
    "es_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "lr_tracker = LearningRateTracker()\n",
    "\n",
    "history = model.fit(train_text_use, \n",
    "          train_label,\n",
    "          validation_data=(test_text_use, test_label),\n",
    "          epochs=1000,\n",
    "          batch_size=256,\n",
    "          callbacks=[es_callback, lr_tracker, reduce_lr])\n",
    "model.save_weights('./model20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_nnlm128_512_512.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "queries_list = []\n",
    "with open('COVID-TEXT.csv', 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        queries_list.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Labourers without food',\n",
       " 'Migrant Workers from UP and BIHAR',\n",
       " 'People need cooked food',\n",
       " 'people stuck in bangalore',\n",
       " 'People Stuck without Food',\n",
       " 'People without ration',\n",
       " 'Residence of rama swamy palya facing water scarcity',\n",
       " 'Stranded migrants from various states',\n",
       " '5o Migrant workers from West Bengal',\n",
       " 'Alemari samudaya with food and ration',\n",
       " 'Elder people need urgent ration',\n",
       " 'Familiy without ration',\n",
       " '10 members need Ration , Daily Wage workers',\n",
       " '10 people Need information on how to go back to bihar ',\n",
       " '10 person from Bihar are struck in Dharwad. They need Ration , Kindly deliver, they have no money and food to survive .\\nThanks',\n",
       " '14 Workers need ration',\n",
       " '150 people Wants to go home from mangalore to Giridih Jarkhand',\n",
       " '17 families are not having ration card not received any ration from anywhere. They need to be helped for the basic food and sanitaries',\n",
       " '25 people who are living in Venkateshwar Nagar, (Vaddargalli) not ration card and not benefiting from PDS. These people need to be helped provision kit',\n",
       " '3 members Need ration and GAS ',\n",
       " '3 Migrants labourers from Bihar need ration \\n',\n",
       " '300 family in poor people please help them',\n",
       " '300 Migrants labourers from Bihar need ration ',\n",
       " '310 families need families',\n",
       " '32 family need ration, daily wage workers',\n",
       " '6 members need ration (garment workers)',\n",
       " '6 members need ration wage workers\\nDaily wage workers\\n ',\n",
       " 'Enquiry about travelling from Bangalore to Dakshina kannada.\\n ',\n",
       " 'Glycomety GP - 1 ( 2 strips)\\nDolowin Plus (2 strips)',\n",
       " \"I've got request for ration to be delivered for 70-75 labour class people in OPH road, shivaginagar. \\nThese people are from different states (UP, Bihar, Assam) \\nEssentials were provided to them by their owners and now itÃ¢â‚¬â„¢s become hard for the owners also to provide further. \\nRequesting you to revert at the earliest.\",\n",
       " 'karmikarige 112 resan kit',\n",
       " 'Lakshmi Yadav and 7 migrant workers need ration urgently.',\n",
       " 'Need information on how to go back to bihar ',\n",
       " 'Need ration for 12 dialy wage workers',\n",
       " 'Need ration for 13 migrant laborers from Kolkata.',\n",
       " 'Need ration for 3 members Daily wage workers\\nRecieved through phone by Manohar\\n',\n",
       " 'Need ration for 5 members ,person working in garments ',\n",
       " 'Need Ration for 6 members Daily wage workers ',\n",
       " 'Need to go to Agra ',\n",
       " 'Need to travel from Bangalore to Bihar \\n ',\n",
       " 'Panchanan and 9 migrant workers need ration and gas immediately.',\n",
       " 'Phagu Ram Mahato and 2 migrants need dry ration immediately',\n",
       " 'Pradip and 8 workers need dry ration and gas refill immediately. They are painters from North Indian states.',\n",
       " 'Prakash and 4 migrant workers need ration urgently.',\n",
       " 'Ranjith and fifty workers from North Indian states need dry ration urgently. \\n',\n",
       " 'Ration kits for slum',\n",
       " 'Request for ration kits and packed food for underprivileged families in and around JC nagar. \\nWe have been active in this area and have been providing both ration and packed food to the needy and are running out of resources and funds to meet the list of people here. \\n\\nPlease get in touch with us and help us deliver essential food and ration for the needy here. \\nThank you',\n",
       " 'Request for ration kits to be provided in agalkote village, after magadi town. \\n36 families all from labour class are expecting aid.\\nTransport will be provided by our volunteers if necessary. Please reach out to them at the earliest.',\n",
       " 'Request Ration Kits for Daily Wage and Migrant labourers near Kannur Village Quarry, Near Nelamanagal, Sagarhalli and Mariampet-Muthakapalli Panchayat, in Srinivaspur, Kolar',\n",
       " 'Required ration for poor and needy for 30 plus families',\n",
       " 'Santosh Kumar and 4 migrants need ration urgently.',\n",
       " \"Sir/Madam,My name is Lakshminarayana BN,I am requesting fr ration supply behalf of distress lady named sharadamma,aged 80yrs,she is almost blind,She's helpless,As of now I am taking care of her,Hence I request u to kindly help her by providing ration supplies,Thanking you,yours faithfully,,,\",\n",
       " 'Sonaram Munda and 5 migrants need ration and gas refilling immediately',\n",
       " 'Stuck in Bangalore. From WEst Bengal. No jobs. Shop owner left them without paying. Need ration, gas and house rent. Want to return back to West Bengal.',\n",
       " 'Sukhram Kumar and 15 migrant workers need ration urgently.',\n",
       " 'There are 17 families without the Ration Card and they are not able to access the Ration shop for the basic necessities. they need to be helped for food and sanitary ietems',\n",
       " 'There are 45 families at the slum near Aland Naka, Kalaburagi. These people are requesting for the basic necessities.',\n",
       " 'They are in need of ration and gas. \\nThe secondary contact name: Pravat Bardhan contact number is 7991098775',\n",
       " 'They are in need of Ration and Gas. There are 5 peoples in group. The secondary contact person is Santosh Sethy, contact number : 7992993324.',\n",
       " 'They are in need of Ration and Gas. They are 5 members living together in one room.\\nThe secondary contact person name :Pravat Bardhan and the contact no: 7991098775',\n",
       " 'They are in need of Ration. There are 16 peoples in group. The secondary contact person is Baskar Mahato, contact number : 6362301525',\n",
       " 'They are in need of Ration. There are 20 peoples.\\nThe secondary contact person name: Pankaj Kumar, contact no: 9611001767.',\n",
       " 'They are in need of Ration. There are 5 peoples in group. The secondary contact person is Ranjeet Kumar Sharma, contact no. 6203404995.',\n",
       " 'They are in need of Ration. There are 7 peoples in group.',\n",
       " 'Thirteen families are not having ration card and they are struggling for food.',\n",
       " 'We are around 5 migrant workers stranded in Kolar, we require help IÃ¢â‚¬â„¢m going back to Tripura. We did not have groceries this till yesterday. We received relief today (2 May 2020) from localities. Kindly let us know how we can use the transport facility provided by the Government to go back home.',\n",
       " 'We have helping to alemari people and beggers senior citizens families issued vegetables fruits and water bottle needfully issued and then future help to single oldage families forest hills poorest people s',\n",
       " 'Women in need of medical assistance',\n",
       " 'Tribals from Tamil Nadu wants to travel back',\n",
       " 'To Provide Ration for people',\n",
       " 'Stranded migrants from various states',\n",
       " 'Stranded labourers without food or ration',\n",
       " 'Residence of rama swamy palya facing water scarcity',\n",
       " \"Require pass to travel from bangalore to Tirchy due to father's death\",\n",
       " 'people without food and need assistance to travel',\n",
       " 'people stuck in bangalore',\n",
       " 'People need cooked food',\n",
       " 'People in need of medical assistance',\n",
       " 'Patient in request of urgent medicine',\n",
       " 'Need pass to travel from Assam to Karnataka due to daughters health condition',\n",
       " 'need food for 50 people',\n",
       " 'need dry ration',\n",
       " 'Migrant Family from Jharkhand need help',\n",
       " 'Migrant construction workers request for travel',\n",
       " 'Labourers without food who travelled to Chitradurga',\n",
       " 'Labourers (Jharkhand ) who worked for Gopalan group . Have not been paid since lockdown.',\n",
       " 'Familoes pressurized for rent',\n",
       " '8 adults 2 child stuck without food',\n",
       " '73 families surveyed by a volunteer - most dont have ration card.',\n",
       " '10 person from Bihar are struck in Dharwad. They need Ration , Kindly deliver, they have no money and food to survive .',\n",
       " '17 families are not having ration card not received any ration from anywhere. They need to be helped for the basic food and sanitaries',\n",
       " '25 people who are living in Venkateshwar Nagar, (Vaddargalli) not ration card and not benefiting from PDS. These people need to be helped provision kit',\n",
       " 'Request for ration kits to be provided in agalkote village, after magadi town. \\n36 families all from labour class are expecting aid.\\nTransport will be provided by our volunteers if necessary. Please reach out to them at the earliest.',\n",
       " 'Request Ration Kits for Daily Wage and Migrant labourers near Kannur Village Quarry, Near Nelamanagal, Sagarhalli and Mariampet-Muthakapalli Panchayat, in Srinivaspur, Kolar',\n",
       " 'Required ration for poor and needy for 30 plus families',\n",
       " 'Settled population needing help with ration, money',\n",
       " 'There are 17 families without the Ration Card and they are not able to access the Ration shop for the basic necessities. they need to be helped for food and sanitary ietems',\n",
       " 'There are 45 families at the slum near Aland Naka, Kalaburagi. These people are requesting for the basic necessities.',\n",
       " 'Thirteen families are not having ration card and they are struggling for food.',\n",
       " 'food need for construction workers from Raichur',\n",
       " 'Stranded migrants from various states',\n",
       " 'There is a request for ration for above address. Since it is a Red zone, we are not able to reach.']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = Con\n",
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(query_list):\n",
    "    filt_query = [filter_query(q) for q in query_list]\n",
    "    print (filt_query)\n",
    "    # filt_query = query_list\n",
    "    # query_arr = np.array(filt_query, dtype=object)[:, np.newaxis]\n",
    "    query_arr = np.array(filt_query)\n",
    "    predicts = model.predict(query_arr)\n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['network connectivity area ordering grocery need ration', 'need gas cylinder mobile broke', 'father sick want daily ration', 'yesterday saw few people bullying person locality think need help need cab to go hospital', 'unable to find fruit vegetable', 'need food travel 50 family contact number 8134981349', 'parent stuck house severe health issue father heart problem mother bedridden need urgent medical assistance']\n",
      "QUERY 0-> No network connectivity in my area for ordering groceries. Need ration urgently\n",
      "\n",
      "\n",
      "\tcommunication:100.0\n",
      "\tessential_items:0.1\n",
      "\tfood:100.0\n",
      "\thealthcare:0.0\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 1-> Need gas cylinder as my mobile broke down.\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:100.0\n",
      "\tfood:0.0\n",
      "\thealthcare:0.3\n",
      "\tothers:0.3\n",
      "\ttravel:0.2\n",
      "\n",
      "\n",
      "QUERY 2-> My father is sick. i want daily ration\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.0\n",
      "\tfood:100.0\n",
      "\thealthcare:90.7\n",
      "\tothers:0.0\n",
      "\ttravel:43.6\n",
      "\n",
      "\n",
      "QUERY 3-> Yesterday i saw few people bullying a person from my locality. I think he needs help.i need cab to go to hospital.\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.0\n",
      "\tfood:45.6\n",
      "\thealthcare:60.3\n",
      "\tothers:100.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 4-> I am unable to find fruits and vegetables\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.0\n",
      "\tfood:100.0\n",
      "\thealthcare:0.0\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 5-> need food and travel for 50 families. contact number 8134981349\n",
      "\n",
      "\n",
      "\tcommunication:39.2\n",
      "\tessential_items:0.0\n",
      "\tfood:100.0\n",
      "\thealthcare:0.0\n",
      "\tothers:0.0\n",
      "\ttravel:89.9\n",
      "\n",
      "\n",
      "QUERY 6-> Me and my parents are stuck alone in our house with severe health issues. My father has heart problems and my mother is bedridden. I need urgent medical assistance\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.0\n",
      "\tfood:0.1\n",
      "\thealthcare:100.0\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"No network connectivity in my area for ordering groceries. Need ration urgently\",\n",
    "\"Need gas cylinder as my mobile broke down.\",\n",
    "\"My father is sick. i want daily ration\",\n",
    "\"Yesterday i saw few people bullying a person from my locality. I think he needs help.i need cab to go to hospital.\",\n",
    "'I am unable to find fruits and vegetables',\n",
    "'need food and travel for 50 families. contact number 8134981349',\n",
    "'Me and my parents are stuck alone in our house with severe health issues. My father has heart problems and my mother is bedridden. I need urgent medical assistance']\n",
    "\n",
    "\n",
    "# new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "# #new_text = np.array(queries_list, dtype=object)[:, np.newaxis]\n",
    "\n",
    "# predicts = model.predict(new_text)\n",
    "predicts = run_prediction(new_text)\n",
    "\n",
    "dictt=trainset.target_names\n",
    "\n",
    "for j in range(len(new_text)):\n",
    "    print(\"QUERY \"+str(j) +'-> ' + new_text[j])\n",
    "    print('\\n')\n",
    "    for i in range(len(dictt)):\n",
    "        print('\\t'+dictt[i]+\":\"+str(np.around(predicts*100,decimals=1)[j][i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['network connectivity area order grocery need ration', 'try to contact airport authority not responding', 'yesterday saw few people bullying person locality think need help need cab car broke to go hospital', 'give toilet cleaner pet food', 'travel lockdown not able to find soap', 'i want ventilator', 'need to go home urgently .', 'parent stuck house severe health issue father heart problem mother bedridden need urgent medical assistance']\n",
      "QUERY 0-> No network connectivity in my area for order grocery . Need ration urgently\n",
      "\n",
      "\n",
      "\tcommunication:100.0\n",
      "\tessential_items:0.0\n",
      "\tfood:100.0\n",
      "\thealthcare:0.0\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 1-> i am try to contact airport authorities but they are not responding\n",
      "\n",
      "\n",
      "\tcommunication:100.0\n",
      "\tessential_items:0.2\n",
      "\tfood:0.1\n",
      "\thealthcare:0.0\n",
      "\tothers:0.0\n",
      "\ttravel:12.3\n",
      "\n",
      "\n",
      "QUERY 2-> Yesterday i saw few people bullying a person from my locality. I think he needs help.i need cab as my car broke down to go to hospital.\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.0\n",
      "\tfood:0.3\n",
      "\thealthcare:34.6\n",
      "\tothers:100.0\n",
      "\ttravel:9.5\n",
      "\n",
      "\n",
      "QUERY 3-> give me toilet cleaner and pet food\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:99.9\n",
      "\tfood:100.0\n",
      "\thealthcare:0.0\n",
      "\tothers:0.1\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 4-> ijust travel back to bangalore due to lockdown i am not able to find soap\n",
      "\n",
      "\n",
      "\tcommunication:5.8\n",
      "\tessential_items:0.0\n",
      "\tfood:99.6\n",
      "\thealthcare:0.0\n",
      "\tothers:0.0\n",
      "\ttravel:100.0\n",
      "\n",
      "\n",
      "QUERY 5-> i want ventilators\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:9.4\n",
      "\tfood:0.9\n",
      "\thealthcare:100.0\n",
      "\tothers:0.9\n",
      "\ttravel:0.9\n",
      "\n",
      "\n",
      "QUERY 6-> need to go home urgently.\n",
      "\n",
      "\n",
      "\tcommunication:0.9\n",
      "\tessential_items:0.7\n",
      "\tfood:68.6\n",
      "\thealthcare:100.0\n",
      "\tothers:0.0\n",
      "\ttravel:19.8\n",
      "\n",
      "\n",
      "QUERY 7-> Me and my parents are stuck alone in our house with severe health issues. My father has heart problems and my mother is bedridden. I need urgent medical assistance\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.0\n",
      "\tfood:0.1\n",
      "\thealthcare:100.0\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"No network connectivity in my area for order grocery . Need ration urgently\",\n",
    "\n",
    " \"i am try to contact airport authorities but they are not responding\",\n",
    "\n",
    " \"Yesterday i saw few people bullying a person from my locality. I think he needs help.i need cab as my car broke down to go to hospital.\",\n",
    "\n",
    " 'give me toilet cleaner and pet food',\n",
    "\n",
    " 'ijust travel back to bangalore due to lockdown i am not able to find soap',\n",
    "\n",
    " 'i want ventilators',\n",
    "\n",
    " 'need to go home urgently.',\n",
    "\n",
    " 'Me and my parents are stuck alone in our house with severe health issues. My father has heart problems and my mother is bedridden. I need urgent medical assistance']\n",
    "predicts = run_prediction(new_text)\n",
    "\n",
    "dictt=trainset.target_names\n",
    "\n",
    "for j in range(len(new_text)):\n",
    "    print(\"QUERY \"+str(j) +'-> ' + new_text[j])\n",
    "    print('\\n')\n",
    "    for i in range(len(dictt)):\n",
    "        print('\\t'+dictt[i]+\":\"+str(np.around(predicts*100,decimals=1)[j][i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.0719925e-05, 5.1792540e-02, 3.0541523e-05, 3.5929384e-05,\n",
       "        7.5689690e-07, 3.2593703e-01],\n",
       "       [8.1119651e-05, 9.8318785e-01, 2.1166863e-06, 1.6125040e-02,\n",
       "        6.0552239e-02, 5.8824737e-03]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(['need to go home', ''], dtype=object)[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 'PRON'), ('want', 'VERB'), ('roti', 'NOUN'), (',', 'PUNCT'), ('egg', 'NOUN'), (',', 'PUNCT'), ('dal', 'PROPN'), (',', 'PUNCT'), ('chawal', 'PROPN'), (',', 'PUNCT'), ('anda', 'PROPN'), ('.', 'PUNCT')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'want roti egg'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_query(\"i want roti ,  egg , dal , chawal , anda .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 0 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-71616dfdd5f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqueries_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueries_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'query'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdictt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-71616dfdd5f9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqueries_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueries_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'query'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdictt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 7 is out of bounds for axis 0 with size 7"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame([[queries_list[i]] + list(np.around(predicts*100,decimals=1)[i]) for i in range(len(queries_list))], columns=['query'] + dictt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>communication</th>\n",
       "      <th>food</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>others</th>\n",
       "      <th>travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Labourers without food</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Migrant Workers from UP and BIHAR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>48.900002</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>99.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People need cooked food</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>64.699997</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people stuck in bangalore</td>\n",
       "      <td>98.099998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People Stuck without Food</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               query  communication   food  healthcare  \\\n",
       "0             Labourers without food       0.000000  100.0    0.000000   \n",
       "1  Migrant Workers from UP and BIHAR       0.000000    0.6   48.900002   \n",
       "2            People need cooked food       0.300000  100.0    0.200000   \n",
       "3          people stuck in bangalore      98.099998    0.0    0.000000   \n",
       "4          People Stuck without Food      14.600000  100.0    0.000000   \n",
       "\n",
       "       others     travel  \n",
       "0    0.800000   0.000000  \n",
       "1    0.100000  99.099998  \n",
       "2   64.699997   0.000000  \n",
       "3  100.000000   0.000000  \n",
       "4    8.600000   0.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2256071e-07, 1.9670317e-04, 2.2590014e-03, 4.9715425e-04,\n",
       "        9.9989069e-01],\n",
       "       [3.3535997e-03, 5.9001707e-03, 6.5540969e-01, 1.1426200e-02,\n",
       "        2.5253209e-01]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_arr = np.array(['need to visit home', ''], dtype=object)[:, np.newaxis]\n",
    "model.predict(query_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plea sunkadkatte ration request urgent help receive food not child would prefer ration', 'dalit village 150 family not receiving support received 10 kg rice wheat family start lockdown can help', 'request help 10 people two child tribals working coffee pepper plantation 3 spoke say 150 such labourer belt paid contractor money not given ration met tasildar yesterday going can not happen help state decision migrant worker moving place origin thank', 'r working carpenter helper builder contractor r providing grocery other food requirement worker enquiry told problem food sir', '250 fisherman struck not access food last few day depression say help', 'dear friend 08 member check post critical situation present requesting food other help organization working border request attend cae help construction migrant worker contact 6282662916 hope one will reach provide ration', 'contact detail group 50 migrant worker stuck kr market only intermittent access food say large group unable to food distribution point food run request to help', 'small village outskirt not good cell reception isolated news coronavirus availability supply', 'three construction worker hungry last two day jumped building provide ambulance', 'friend fell terrace searching network network problem area government mistake medical expense should bourne', 'daily ration kit distributed not cooking oil supposed to cook', 'trying to start small kitchen to feed hungry poor kid locality unable to not received big 19 kg gas cannister applied 20 day', 'doctor car brokedown want to repaired']\n",
      "QUERY 0-> We have a plea from Sunkadkatte for rations. Request your urgent help .They receive food sometimes but not regularly. They have children and would prefer ration.\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:7.3\n",
      "\tfood:100.0\n",
      "\thealthcare:0.0\n",
      "\tothers:0.2\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 1-> There is a Dalit village with 150 families in Kanakapura district who are not receiving any support. They received 10 kg rice and some wheat per family at the start of the lockdown.Anyone can help ?\n",
      "\n",
      "\n",
      "\tcommunication:0.7\n",
      "\tessential_items:0.0\n",
      "\tfood:100.0\n",
      "\thealthcare:7.7\n",
      "\tothers:0.0\n",
      "\ttravel:92.5\n",
      "\n",
      "\n",
      "QUERY 2-> Dear Ma'am Suchitra here again with another request for help. About 10 people and two children, tribals from Javadhi hills, Tamil Nadu working in coffee n pepper plantation in Chikmagalur. 3 of them spoke to me. They say over 150+ such labourers are there in this belt. They were paid by the contractor in March n have no money now. They have not been given any ration either. They met the Tasildar yesterday about going back. But that cannot happen now.  Ma'am how do we help them out? What is the state decision on migrant workers moving back to place of origin? Thank you.\n",
      "\n",
      "\n",
      "\tcommunication:3.7\n",
      "\tessential_items:0.2\n",
      "\tfood:99.8\n",
      "\thealthcare:0.2\n",
      "\tothers:27.4\n",
      "\ttravel:58.2\n",
      "\n",
      "\n",
      "QUERY 3-> Sir these wkrs r working as carpenters, helpers at Arabhikothanur Kolar,the builder and contractors r providing groceries and other food requirements to these workers.on enquiry the wkrs told there is no problem with resp to food sir\n",
      "\n",
      "\n",
      "\tcommunication:45.7\n",
      "\tessential_items:6.2\n",
      "\tfood:100.0\n",
      "\thealthcare:0.1\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 4-> 250 Fishermen From Andhra Pradesh struck in Udupi, Karnataka.They didn't have access to food from last few days. They are in depression.And at last he says, agar Kuch ni mila toh zehar kha lenge isse aacha .Please help.\n",
      "\n",
      "\n",
      "\tcommunication:15.0\n",
      "\tessential_items:0.0\n",
      "\tfood:84.2\n",
      "\thealthcare:99.5\n",
      "\tothers:10.1\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 5-> Dear friends,  08 members from Uttar Pradesh are  in Mangalore near Kannanuru check post, they are in critical situation present they Requesting food and other help, any organizations working in Mangalore and border of Kerala request you pls attend this cae and help them, all are construction migrant workers,  their contact No: 6282662916, I hope some one will reach them. Please provide ration for all of us.\n",
      "\n",
      "\n",
      "\tcommunication:99.9\n",
      "\tessential_items:6.1\n",
      "\tfood:100.0\n",
      "\thealthcare:0.3\n",
      "\tothers:0.0\n",
      "\ttravel:0.2\n",
      "\n",
      "\n",
      "QUERY 6-> These are the contact details of a group of 50 plus migrant workers stuck in KR market with only intermittent access to food. They say they are a large group and all of them are unable to get food even at distribution points as food runs out. Request you to help\n",
      "\n",
      "\n",
      "\tcommunication:99.1\n",
      "\tessential_items:0.1\n",
      "\tfood:100.0\n",
      "\thealthcare:0.0\n",
      "\tothers:0.0\n",
      "\ttravel:86.6\n",
      "\n",
      "\n",
      "QUERY 7-> We are a small village on the outskirts of Bangalore and we do not have good cell reception here and hence we are isolated here with no news about coronavirus or availability of supplies.\n",
      "\n",
      "\n",
      "\tcommunication:99.9\n",
      "\tessential_items:0.0\n",
      "\tfood:82.0\n",
      "\thealthcare:2.9\n",
      "\tothers:0.0\n",
      "\ttravel:13.2\n",
      "\n",
      "\n",
      "QUERY 8-> Three construction workers from jharkhand are hungry from last two days and jumped off the building. Please provide ambulance\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.0\n",
      "\tfood:0.0\n",
      "\thealthcare:100.0\n",
      "\tothers:8.3\n",
      "\ttravel:1.8\n",
      "\n",
      "\n",
      "QUERY 9-> my friend fell from terrace while searching for network. There is network problem in this area. This is all government mistake and the medical expenses should be bourne by them.\n",
      "\n",
      "\n",
      "\tcommunication:100.0\n",
      "\tessential_items:0.0\n",
      "\tfood:2.0\n",
      "\thealthcare:30.6\n",
      "\tothers:100.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 10-> The daily ration kit distributed to us do not have cooking oil in them. How are we supposed to cook.\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.3\n",
      "\tfood:100.0\n",
      "\thealthcare:2.3\n",
      "\tothers:0.1\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 11-> I am trying to start a small kitchen to feed the hungry poor kids in my locality but I am unable to do so as I haven't received the big 19 kg gas cannister which I applied for almost 20 days ago.\n",
      "\n",
      "\n",
      "\tcommunication:1.2\n",
      "\tessential_items:21.8\n",
      "\tfood:100.0\n",
      "\thealthcare:2.4\n",
      "\tothers:2.3\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 12-> I am a doctor, my car brokedown and want it to get repaired urgently.\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.0\n",
      "\tfood:0.0\n",
      "\thealthcare:99.9\n",
      "\tothers:0.7\n",
      "\ttravel:4.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"We have a plea from Sunkadkatte for rations. Request your urgent help .They receive food sometimes but not regularly. They have children and would prefer ration.\",\n",
    "\"There is a Dalit village with 150 families in Kanakapura district who are not receiving any support. They received 10 kg rice and some wheat per family at the start of the lockdown.Anyone can help ?\",\n",
    "\"Dear Ma'am Suchitra here again with another request for help. About 10 people and two children, tribals from Javadhi hills, Tamil Nadu working in coffee n pepper plantation in Chikmagalur. 3 of them spoke to me. They say over 150+ such labourers are there in this belt. They were paid by the contractor in March n have no money now. They have not been given any ration either. They met the Tasildar yesterday about going back. But that cannot happen now.  Ma'am how do we help them out? What is the state decision on migrant workers moving back to place of origin? Thank you.\",\n",
    "\"Sir these wkrs r working as carpenters, helpers at Arabhikothanur Kolar,the builder and contractors r providing groceries and other food requirements to these workers.on enquiry the wkrs told there is no problem with resp to food sir\",\n",
    "\"250 Fishermen From Andhra Pradesh struck in Udupi, Karnataka.They didn't have access to food from last few days. They are in depression.And at last he says, \"\"agar Kuch ni mila toh zehar kha lenge isse aacha .Please help.\",\n",
    "\"Dear friends,  08 members from Uttar Pradesh are  in Mangalore near Kannanuru check post, they are in critical situation present they Requesting food and other help, any organizations working in Mangalore and border of Kerala request you pls attend this cae and help them, all are construction migrant workers,  their contact No: 6282662916, I hope some one will reach them. Please provide ration for all of us.\",\n",
    "\"These are the contact details of a group of 50 plus migrant workers stuck in KR market with only intermittent access to food. They say they are a large group and all of them are unable to get food even at distribution points as food runs out. Request you to help\",\n",
    "'We are a small village on the outskirts of Bangalore and we do not have good cell reception here and hence we are isolated here with no news about coronavirus or availability of supplies.',\n",
    "'Three construction workers from jharkhand are hungry from last two days and jumped off the building. Please provide ambulance',\n",
    "'my friend fell from terrace while searching for network. There is network problem in this area. This is all government mistake and the medical expenses should be bourne by them.',\n",
    "'The daily ration kit distributed to us do not have cooking oil in them. How are we supposed to cook.',\n",
    "\"I am trying to start a small kitchen to feed the hungry poor kids in my locality but I am unable to do so as I haven't received the big 19 kg gas cannister which I applied for almost 20 days ago.\",\n",
    "'I am a doctor, my car brokedown and want it to get repaired urgently.']\n",
    "# new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "\n",
    "# predicts = model.predict(new_text)\n",
    "\n",
    "\n",
    "# categories = np.unique(df.label)\n",
    "# predict_logits = predicts.argmax(axis=1)\n",
    "# predict_labels = [categories[logit] for logit in predict_logits]\n",
    "predicts = run_prediction(new_text)\n",
    "\n",
    "dictt=trainset.target_names\n",
    "# ANS=[dict[s] for s in predict_labels]\n",
    "\n",
    "for j in range(len(new_text)):\n",
    "    print(\"QUERY \"+str(j) +'-> ' + new_text[j])\n",
    "    print('\\n')\n",
    "    for i in range(len(dictt)):\n",
    "        print('\\t'+dictt[i]+\":\"+str(np.around(predicts*100,decimals=1)[j][i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brush toothpaste soap 2 people 50 unit mask', 'brush toothpaste soap 50 unit mask', 'rice wheat daal 2 people 50 unit mask syrup', 'second layout 350 workers- construction recycling domestic help need urgent dry ration', '350 workers- construction recycling domestic help need urgent dry ration', 'ration govt distribution sunkadkatte not give saying not request help case not local', 'respected help required ration yesterday need food family including 2 child 1 worked sale 2 worked beauty salon 3 daughter 4 daughter 5 6 7 8 address 12 19 cross 560008 contact number 8884356927 1 working beauty salon 2 year old sister contact 9108396170 address 3 cross', 'intrested in donating used blanket', 'intrested in used blanket']\n",
      "QUERY 0-> brush toothpaste and soap for 2 people and 50 units of n95 mask\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:99.3\n",
      "\tfood:0.9\n",
      "\thealthcare:84.6\n",
      "\tothers:2.5\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 1-> brush toothpaste and soap and 50 units of n95 mask\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:99.9\n",
      "\tfood:0.0\n",
      "\thealthcare:81.9\n",
      "\tothers:0.1\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 2-> rice, wheat and daal for 2 people and 50 units of n95 mask and syrup\n",
      "\n",
      "\n",
      "\tcommunication:43.1\n",
      "\tessential_items:0.0\n",
      "\tfood:100.0\n",
      "\thealthcare:5.0\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 3-> And the second is: Sri Venkateswara Layout, Chinappa Layout, Mahadevapura. There are 350 workers- construction, recycling, domestic help. WB, UP, Bihar. need urgent dry ration\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:97.9\n",
      "\tfood:22.3\n",
      "\thealthcare:92.1\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 4-> There are 350 workers- construction, recycling, domestic help. WB, UP, Bihar. need urgent dry ration\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:99.9\n",
      "\tfood:87.1\n",
      "\thealthcare:7.9\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 5-> et rations from a govt distribution in Sunkadkatte they didn't give him saying he is not from here. So request help here in this case too since they are not locals\n",
      "\n",
      "\n",
      "\tcommunication:100.0\n",
      "\tessential_items:0.0\n",
      "\tfood:79.5\n",
      "\thealthcare:0.0\n",
      "\tothers:2.1\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 6-> Respected Ma'am,\n",
      "Help Required.\n",
      "No ration since yesterday who are in really need of food .\n",
      "Pa Shehgin & family including 2 children.\n",
      "1. Pa. Shehgin kipgen( worked in sales )\n",
      "2. Nu. Hoineng kipgen( worked beauty salon )\n",
      "3. Chingnu( daughter )\n",
      "4. Dedai( daughter )\n",
      "5. Gugun( son)\n",
      "6. Hekham\n",
      "7. Hoineo\n",
      "8. Chinkho\n",
      "Address:\n",
      "#12, 19 A cross Lakshmipuram, Halasuru, Bengaluru 560008.\n",
      "Contact number : 8884356927\n",
      "1.Mrs.hahat doungel ( working in beauty salon) 2.boichung doungel ( son,7 year old )\n",
      "3.jenny.doungel ( sister ).\n",
      "Contact no : 9108396170.\n",
      "Address: Kothanur, Anjinapalia, 3 cross\n",
      "\n",
      "\n",
      "\tcommunication:86.2\n",
      "\tessential_items:3.5\n",
      "\tfood:100.0\n",
      "\thealthcare:35.8\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 7-> intrested in donating used blankets\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.0\n",
      "\tfood:0.0\n",
      "\thealthcare:52.7\n",
      "\tothers:0.3\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 8-> intrested in used blankets\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tessential_items:0.2\n",
      "\tfood:0.0\n",
      "\thealthcare:1.3\n",
      "\tothers:0.1\n",
      "\ttravel:0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"brush toothpaste and soap for 2 people and 50 units of n95 mask\",\n",
    "            \"brush toothpaste and soap and 50 units of n95 mask\",\n",
    "           \"rice, wheat and daal for 2 people and 50 units of n95 mask and syrup\",\n",
    "           \"And the second is: Sri Venkateswara Layout, Chinappa Layout, Mahadevapura. There are 350 workers- construction, recycling, domestic help. WB, UP, Bihar. need urgent dry ration\",\n",
    "           \"There are 350 workers- construction, recycling, domestic help. WB, UP, Bihar. need urgent dry ration\",\n",
    "           \"et rations from a govt distribution in Sunkadkatte they didn't give him saying he is not from here. So request help here in this case too since they are not locals\",\n",
    "           '''Respected Ma'am,\n",
    "Help Required.\n",
    "No ration since yesterday who are in really need of food .\n",
    "Pa Shehgin & family including 2 children.\n",
    "1. Pa. Shehgin kipgen( worked in sales )\n",
    "2. Nu. Hoineng kipgen( worked beauty salon )\n",
    "3. Chingnu( daughter )\n",
    "4. Dedai( daughter )\n",
    "5. Gugun( son)\n",
    "6. Hekham\n",
    "7. Hoineo\n",
    "8. Chinkho\n",
    "Address:\n",
    "#12, 19 A cross Lakshmipuram, Halasuru, Bengaluru 560008.\n",
    "Contact number : 8884356927\n",
    "1.Mrs.hahat doungel ( working in beauty salon) 2.boichung doungel ( son,7 year old )\n",
    "3.jenny.doungel ( sister ).\n",
    "Contact no : 9108396170.\n",
    "Address: Kothanur, Anjinapalia, 3 cross''',\n",
    "           \"intrested in donating used blankets\",\n",
    "           \"intrested in used blankets\"\n",
    "]\n",
    "# new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "\n",
    "# predicts = model.predict(new_text)\n",
    "\n",
    "\n",
    "# categories = np.unique(df.label)\n",
    "# predict_logits = predicts.argmax(axis=1)\n",
    "# predict_labels = [categories[logit] for logit in predict_logits]\n",
    "predicts = run_prediction(new_text)\n",
    "\n",
    "dictt=trainset.target_names\n",
    "# ANS=[dict[s] for s in predict_labels]\n",
    "\n",
    "for j in range(len(new_text)):\n",
    "    print(\"QUERY \"+str(j) +'-> ' + new_text[j])\n",
    "    print('\\n')\n",
    "    for i in range(len(dictt)):\n",
    "        print('\\t'+dictt[i]+\":\"+str(np.around(predicts*100,decimals=1)[j][i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"We have a plea from Sunkadkatte for rations. Request your urgent help .They receive food sometimes but not regularly. They have children and would prefer ration.\",\n",
    "\"There is a Dalit village with 150 families in Kanakapura district who are not receiving any support. They received 10 kg rice and some wheat per family at the start of the lockdown.Anyone can help ?\",\n",
    "\"Dear Ma'am Suchitra here again with another request for help. About 10 people and two children, tribals from Javadhi hills, Tamil Nadu working in coffee n pepper plantation in Chikmagalur. 3 of them spoke to me. They say over 150+ such labourers are there in this belt. They were paid by the contractor in March n have no money now. They have not been given any ration either. They met the Tasildar yesterday about going back. But that cannot happen now.  Ma'am how do we help them out? What is the state decision on migrant workers moving back to place of origin? Thank you.\",\n",
    "\"Sir these wkrs r working as carpenters, helpers at Arabhikothanur Kolar,the builder and contractors r providing groceries and other food requirements to these workers.on enquiry the wkrs told there is no problem with resp to food sir\",\n",
    "\"250 Fishermen From Andhra Pradesh struck in Udupi, Karnataka.They didn't have access to food from last few days. They are in depression.And at last he says, \"\"agar Kuch ni mila toh zehar kha lenge isse aacha .Please help.\",\n",
    "\"Dear friends,  08 members from Uttar Pradesh are  in Mangalore near Kannanuru check post, they are in critical situation present they Requesting food and other help, any organizations working in Mangalore and border of Kerala request you pls attend this cae and help them, all are construction migrant workers,  their contact No: 6282662916, I hope some one will reach them.\",\n",
    "\"These are the contact details of a group of 50 plus migrant workers stuck in KR market with only intermittent access to food. They say they are a large group and all of them are unable to get food even at distribution points as food runs out. Request you to help\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts.shape\n",
    "preds_round = np.around(predicts*100,decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 92.9000015258789, 0.5, 0.0, 0.0, 0.0]\n",
      "[100.0, 6.800000190734863, 5.5, 0.20000000298023224, 0.0, 0.0]\n",
      "[99.9000015258789, 83.80000305175781, 56.900001525878906, 0.0, 0.0, 0.0]\n",
      "[94.80000305175781, 93.80000305175781, 35.099998474121094, 2.200000047683716, 0.8999999761581421, 0.0]\n",
      "[100.0, 70.9000015258789, 0.5, 0.0, 0.0, 0.0]\n",
      "[100.0, 71.9000015258789, 0.0, 0.0, 0.0, 0.0]\n",
      "[97.80000305175781, 41.79999923706055, 20.0, 10.0, 0.0, 0.0]\n",
      "[100.0, 99.9000015258789, 3.200000047683716, 0.30000001192092896, 0.10000000149011612, 0.0]\n",
      "[100.0, 4.199999809265137, 2.4000000953674316, 0.6000000238418579, 0.20000000298023224, 0.0]\n",
      "[100.0, 100.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 51.099998474121094, 2.299999952316284, 0.0, 0.0, 0.0]\n",
      "[100.0, 27.5, 0.20000000298023224, 0.0, 0.0, 0.0]\n",
      "[100.0, 2.200000047683716, 0.4000000059604645, 0.4000000059604645, 0.20000000298023224, 0.0]\n",
      "[99.9000015258789, 6.5, 3.4000000953674316, 0.5, 0.20000000298023224, 0.10000000149011612]\n",
      "[99.80000305175781, 99.4000015258789, 0.4000000059604645, 0.4000000059604645, 0.0, 0.0]\n",
      "[100.0, 1.0, 0.8999999761581421, 0.8999999761581421, 0.0, 0.0]\n",
      "[98.9000015258789, 80.0, 19.100000381469727, 9.699999809265137, 0.10000000149011612, 0.0]\n",
      "[100.0, 94.80000305175781, 0.0, 0.0, 0.0, 0.0]\n",
      "[99.0999984741211, 87.69999694824219, 85.0, 0.20000000298023224, 0.0, 0.0]\n",
      "[100.0, 23.799999237060547, 3.4000000953674316, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 72.4000015258789, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[100.0, 5.599999904632568, 0.5, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 5.300000190734863, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[100.0, 4.0, 2.4000000953674316, 0.30000001192092896, 0.0, 0.0]\n",
      "[100.0, 0.4000000059604645, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[99.80000305175781, 99.0, 0.800000011920929, 0.4000000059604645, 0.10000000149011612, 0.0]\n",
      "[100.0, 5.300000190734863, 0.699999988079071, 0.4000000059604645, 0.0, 0.0]\n",
      "[100.0, 40.400001525878906, 12.100000381469727, 0.10000000149011612, 0.0, 0.0]\n",
      "[99.4000015258789, 69.30000305175781, 65.0999984741211, 4.0, 0.10000000149011612, 0.0]\n",
      "[100.0, 80.9000015258789, 79.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 38.29999923706055, 15.899999618530273, 0.6000000238418579, 0.0, 0.0]\n",
      "[100.0, 13.199999809265137, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0]\n",
      "[98.80000305175781, 28.899999618530273, 14.0, 6.300000190734863, 0.10000000149011612, 0.0]\n",
      "[100.0, 2.299999952316284, 0.20000000298023224, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 46.400001525878906, 6.099999904632568, 0.0, 0.0, 0.0]\n",
      "[100.0, 11.5, 0.699999988079071, 0.20000000298023224, 0.10000000149011612, 0.0]\n",
      "[99.80000305175781, 99.4000015258789, 0.8999999761581421, 0.20000000298023224, 0.10000000149011612, 0.0]\n",
      "[100.0, 5.400000095367432, 0.20000000298023224, 0.0, 0.0, 0.0]\n",
      "[100.0, 31.100000381469727, 8.800000190734863, 7.900000095367432, 0.0, 0.0]\n",
      "[100.0, 50.70000076293945, 10.199999809265137, 1.100000023841858, 0.0, 0.0]\n",
      "[100.0, 24.5, 1.2999999523162842, 0.20000000298023224, 0.20000000298023224, 0.0]\n",
      "[100.0, 1.399999976158142, 1.2000000476837158, 0.0, 0.0, 0.0]\n",
      "[99.9000015258789, 99.9000015258789, 6.199999809265137, 0.4000000059604645, 0.0, 0.0]\n",
      "[100.0, 12.800000190734863, 0.8999999761581421, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 83.69999694824219, 3.799999952316284, 0.20000000298023224, 0.0, 0.0]\n",
      "[99.9000015258789, 98.5999984741211, 77.80000305175781, 0.0, 0.0, 0.0]\n",
      "[99.80000305175781, 84.19999694824219, 74.69999694824219, 11.600000381469727, 0.10000000149011612, 0.0]\n",
      "[61.099998474121094, 16.100000381469727, 6.199999809265137, 5.400000095367432, 1.0, 0.0]\n",
      "[99.0, 95.69999694824219, 72.5, 0.0, 0.0, 0.0]\n",
      "[100.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 2.700000047683716, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[91.4000015258789, 43.70000076293945, 13.0, 10.899999618530273, 0.30000001192092896, 0.0]\n",
      "[100.0, 99.19999694824219, 1.100000023841858, 0.0, 0.0, 0.0]\n",
      "[100.0, 1.100000023841858, 0.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 3.200000047683716, 0.800000011920929, 0.0, 0.0, 0.0]\n",
      "[100.0, 100.0, 0.20000000298023224, 0.0, 0.0, 0.0]\n",
      "[100.0, 75.5, 5.300000190734863, 3.5, 0.0, 0.0]\n",
      "[96.19999694824219, 95.5999984741211, 93.80000305175781, 0.10000000149011612, 0.0, 0.0]\n",
      "[99.9000015258789, 89.9000015258789, 33.599998474121094, 2.299999952316284, 0.0, 0.0]\n",
      "[98.0, 91.5999984741211, 6.800000190734863, 2.0, 0.10000000149011612, 0.0]\n",
      "[97.80000305175781, 83.80000305175781, 46.0, 1.2000000476837158, 0.10000000149011612, 0.0]\n",
      "[51.0, 45.599998474121094, 11.699999809265137, 7.099999904632568, 0.30000001192092896, 0.10000000149011612]\n",
      "[95.5, 73.30000305175781, 13.300000190734863, 1.2000000476837158, 0.5, 0.0]\n",
      "[100.0, 39.5, 6.199999809265137, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 5.699999809265137, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[100.0, 69.80000305175781, 38.29999923706055, 0.0, 0.0, 0.0]\n",
      "[100.0, 25.600000381469727, 5.0, 0.6000000238418579, 0.0, 0.0]\n",
      "[100.0, 2.5, 0.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 79.4000015258789, 14.199999809265137, 0.6000000238418579, 0.6000000238418579, 0.0]\n",
      "[100.0, 0.8999999761581421, 0.6000000238418579, 0.0, 0.0, 0.0]\n",
      "[100.0, 99.9000015258789, 3.200000047683716, 0.30000001192092896, 0.10000000149011612, 0.0]\n",
      "[100.0, 25.600000381469727, 0.20000000298023224, 0.10000000149011612, 0.0, 0.0]\n",
      "[97.80000305175781, 41.79999923706055, 20.0, 10.0, 0.0, 0.0]\n",
      "[100.0, 4.599999904632568, 2.5, 2.200000047683716, 0.0, 0.0]\n",
      "[100.0, 92.5999984741211, 1.0, 0.10000000149011612, 0.0, 0.0]\n",
      "[94.80000305175781, 93.80000305175781, 35.099998474121094, 2.200000047683716, 0.8999999761581421, 0.0]\n",
      "[99.9000015258789, 83.80000305175781, 56.900001525878906, 0.0, 0.0, 0.0]\n",
      "[100.0, 1.100000023841858, 0.699999988079071, 0.0, 0.0, 0.0]\n",
      "[100.0, 66.5, 1.100000023841858, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 48.70000076293945, 43.099998474121094, 0.0, 0.0, 0.0]\n",
      "[100.0, 11.899999618530273, 0.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 93.4000015258789, 55.099998474121094, 0.0, 0.0, 0.0]\n",
      "[100.0, 50.29999923706055, 1.5, 0.20000000298023224, 0.10000000149011612, 0.0]\n",
      "[100.0, 83.80000305175781, 24.299999237060547, 2.700000047683716, 0.10000000149011612, 0.0]\n",
      "[100.0, 15.800000190734863, 1.600000023841858, 1.0, 0.0, 0.0]\n",
      "[69.80000305175781, 63.5, 16.200000762939453, 7.0, 0.30000001192092896, 0.0]\n",
      "[87.9000015258789, 39.099998474121094, 21.0, 2.9000000953674316, 0.800000011920929, 0.0]\n",
      "[99.80000305175781, 99.0999984741211, 4.099999904632568, 3.0999999046325684, 0.0, 0.0]\n",
      "[100.0, 6.900000095367432, 0.5, 0.10000000149011612, 0.0, 0.0]\n",
      "[99.69999694824219, 97.4000015258789, 1.2999999523162842, 0.20000000298023224, 0.0, 0.0]\n",
      "[100.0, 94.80000305175781, 0.0, 0.0, 0.0, 0.0]\n",
      "[99.0999984741211, 87.69999694824219, 85.0, 0.20000000298023224, 0.0, 0.0]\n",
      "[61.099998474121094, 16.100000381469727, 6.199999809265137, 5.400000095367432, 1.0, 0.0]\n",
      "[99.0, 95.69999694824219, 72.5, 0.0, 0.0, 0.0]\n",
      "[100.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 20.799999237060547, 0.4000000059604645, 0.0, 0.0, 0.0]\n",
      "[100.0, 100.0, 0.20000000298023224, 0.0, 0.0, 0.0]\n",
      "[100.0, 75.5, 5.300000190734863, 3.5, 0.0, 0.0]\n",
      "[100.0, 5.699999809265137, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[100.0, 97.69999694824219, 6.800000190734863, 0.20000000298023224, 0.0, 0.0]\n",
      "[100.0, 99.9000015258789, 3.200000047683716, 0.30000001192092896, 0.10000000149011612, 0.0]\n",
      "[99.19999694824219, 71.4000015258789, 17.5, 0.5, 0.10000000149011612, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from statistics import stdev\n",
    "pred_results = []\n",
    "for i in range(predicts.shape[0]):\n",
    "    sorted_class_similariy = [float(x) for x in sorted(preds_round[i], reverse=True)]\n",
    "    print (sorted_class_similariy)\n",
    "    split_stdev = []\n",
    "    split_stdev.append(stdev(sorted_class_similariy[1:len(dictt)]))\n",
    "    for k in range(2, len(dictt) - 1):\n",
    "        split_stdev.append((stdev(sorted_class_similariy[:k]) + stdev(sorted_class_similariy[k:]))/2)\n",
    "    split_stdev.append(stdev(sorted_class_similariy[:len(dictt) - 1]))\n",
    "\n",
    "    split_ind = np.argmin(split_stdev)\n",
    "    thres = (sorted_class_similariy[split_ind] + sorted_class_similariy[split_ind + 1]) / 2\n",
    "    # print (thres)\n",
    "    pred_labels = [c for c in range(len(dictt)) if preds_round[i][c] >= np.around(thres, decimals=1)]\n",
    "    pred_classes = [dictt[r] for r in pred_labels]\n",
    "    # print (pred_labels)\n",
    "    pred_results.append(pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['food', 'health'],\n",
       " ['food'],\n",
       " ['food', 'fuel', 'health'],\n",
       " ['communication', 'travel'],\n",
       " ['food', 'health'],\n",
       " ['food', 'health'],\n",
       " ['travel'],\n",
       " ['food', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'health'],\n",
       " ['abuse', 'food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food'],\n",
       " ['communication', 'food'],\n",
       " ['food', 'travel'],\n",
       " ['food', 'health', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'health'],\n",
       " ['food'],\n",
       " ['travel'],\n",
       " ['food', 'health', 'travel'],\n",
       " ['food', 'fuel', 'travel'],\n",
       " ['health'],\n",
       " ['food'],\n",
       " ['travel'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'health'],\n",
       " ['food'],\n",
       " ['travel'],\n",
       " ['communication', 'travel'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food', 'fuel', 'health'],\n",
       " ['food', 'fuel', 'travel'],\n",
       " ['fuel'],\n",
       " ['food', 'fuel', 'travel'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['abuse'],\n",
       " ['food', 'fuel'],\n",
       " ['travel'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['abuse', 'food'],\n",
       " ['abuse', 'fuel', 'health'],\n",
       " ['abuse', 'fuel'],\n",
       " ['abuse', 'fuel'],\n",
       " ['abuse', 'food', 'health'],\n",
       " ['fuel', 'health'],\n",
       " ['abuse', 'food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'fuel', 'travel'],\n",
       " ['food'],\n",
       " ['health'],\n",
       " ['abuse', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food'],\n",
       " ['travel'],\n",
       " ['travel'],\n",
       " ['food', 'health'],\n",
       " ['communication', 'travel'],\n",
       " ['food', 'fuel', 'health'],\n",
       " ['health'],\n",
       " ['fuel', 'health'],\n",
       " ['food', 'health', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'fuel', 'health'],\n",
       " ['abuse', 'food'],\n",
       " ['health', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['health'],\n",
       " ['food', 'health'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food', 'travel'],\n",
       " ['food', 'health', 'travel'],\n",
       " ['fuel'],\n",
       " ['food', 'fuel', 'travel'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['abuse', 'food'],\n",
       " ['food'],\n",
       " ['food', 'health'],\n",
       " ['food', 'travel'],\n",
       " ['communication', 'travel']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OK### both tanh -84% split=0.3    split=o.2 good\n",
    "## both relu - 86% split=0.2\n",
    "## both tanh - 85.4% split=0.2\n",
    "## tanh relu 84.73\n",
    "### relu tanh 85.63 -----good 256,128\n",
    "### relu tanh  86.12-----ok ok 1024,256\n",
    "### relu tanh  86.12-----ok ok 1024,256\n",
    "## tanh tanh ---1024 128 \n",
    "## relu tanh tanh 256 128 64- 85.8%\n",
    "## tanh tanh 0.3 split acc= 84.55 can try\n",
    "\n",
    "\n",
    "OK###with categorical cross entropy tanh tanh 256 128 results are ok but accuracy showing is less\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 93.82%\n",
    "# dense1 = Dense(256, activation='relu')(embedding)\n",
    "# dense2 = Dense(128, activation='relu')(dense1)\n",
    "# pred = Dense(category_counts, activation='sigmoid')(dense2)\n",
    "# model = Model(inputs=[input_text], outputs=pred)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 94.41%\n",
    "# dense1 = Dense(1024, activation='relu')(embedding)\n",
    "# dense2 = Dense(256, activation='relu')(dense1)\n",
    "# pred = Dense(category_counts, activation='sigmoid')(dense2)\n",
    "# model = Model(inputs=[input_text], outputs=pred)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "## __94.78____%\n",
    "# dense1 = Dense(1024, activation='relu')(embedding)\n",
    "# dense2 = Dense(128, activation='relu')(dense1)\n",
    "# pred = Dense(category_counts, activation='sigmoid')(dense2)\n",
    "# model = Model(inputs=[input_text], outputs=pred)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "####### 94.48 % #########\n",
    "\n",
    "# input_text = Input(shape=(1,), dtype=tf.string)\n",
    "# embedding = Lambda(UniversalEmbedding,output_shape=(embed_size,))(input_text)\n",
    "# dense1 = Dense(1024, activation='relu')(embedding)\n",
    "# dense2 = Dense(128, activation='tanh')(dense1)\n",
    "# pred = Dense(category_counts, activation='sigmoid')(dense2)\n",
    "# model = Model(inputs=[input_text], outputs=pred)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import our dependencies\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "from keras import backend as K\n",
    "import keras.layers as layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.engine import Layer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable=True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
    "                               name=\"{}_module\".format(self.name))\n",
    "\n",
    "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                      as_dict=True,\n",
    "                      signature='default',\n",
    "                      )['default']\n",
    "        return result\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return K.not_equal(inputs, '--PAD--')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elmo = hub.Module('../elmo_2', trainable=True)\n",
    "# elmo(K.squeeze(K.cast([['food'],['']], tf.string), axis=1),\n",
    "#                         as_dict=True,\n",
    "#                         signature='default',\n",
    "#                         )['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-69438b62fda5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#                            signature=\"default\", output_key=\"default\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# hub_layer(train_examples[:3])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0melmo_emb_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElmoEmbeddingLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhub_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-138-f15e4abbb2bf>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimensions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mElmoEmbeddingLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "# model_url = \"https://tfhub.dev/google/elmo/3\"\n",
    "# # hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "# hub_layer = hub.KerasLayer(model_url, output_shape=[128], input_shape=[], \n",
    "#                            dtype=tf.string, trainable=False, \n",
    "#                            signature=\"default\", output_key=\"default\")\n",
    "# hub_layer(train_examples[:3])\n",
    "elmo_emb_layer = ElmoEmbeddingLayer().build((None,))\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(len(categories), activation='sigmoid'))\n",
    "model.build(input_shape=())\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# dense1 = Dense(1024, activation='relu')(embedding)\n",
    "# dense2 = Dense(128, activation='relu')(dense1)\n",
    "# out = Dense(len(categories), activation='sigmoid')(dense2)\n",
    "# # pred = []\n",
    "# # for c in categories:\n",
    "# #     pred.append(Dense(1, activation='sigmoid')(dense2))\n",
    "# # out = Concatenate()(pred)\n",
    "# model = Model(inputs=[input_text], outputs=out)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "optimizer = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "elmo_embedding_layer_19 (Elm (None, 1024)              4         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 263,946\n",
      "Trainable params: 263,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(): \n",
    "    input_text = layers.Input(shape=(1,), dtype=\"string\")\n",
    "    embedding = ElmoEmbeddingLayer()(input_text)\n",
    "    dense = layers.Dense(256, activation='relu')(embedding)\n",
    "    pred = layers.Dense(6, activation='sigmoid')(dense)\n",
    "\n",
    "    model = Model(inputs=[input_text], outputs=pred)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "# model.fit(train_text, \n",
    "#           train_label,\n",
    "#           validation_data=(test_text, test_label),\n",
    "#           epochs=10,\n",
    "#           batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2974 samples, validate on 744 samples\n",
      "Epoch 1/5\n",
      "2974/2974 [==============================] - 818s 275ms/step - loss: 0.5129 - acc: 0.7512 - val_loss: 0.3913 - val_acc: 0.8566\n",
      "Epoch 2/5\n",
      "2974/2974 [==============================] - 800s 269ms/step - loss: 0.3262 - acc: 0.8754 - val_loss: 0.2885 - val_acc: 0.8849\n",
      "Epoch 3/5\n",
      "2974/2974 [==============================] - 917s 308ms/step - loss: 0.2510 - acc: 0.9069 - val_loss: 0.2440 - val_acc: 0.9017\n",
      "Epoch 4/5\n",
      "2974/2974 [==============================] - 901s 303ms/step - loss: 0.2106 - acc: 0.9205 - val_loss: 0.2099 - val_acc: 0.9216\n",
      "Epoch 5/5\n",
      "2974/2974 [==============================] - 878s 295ms/step - loss: 0.1819 - acc: 0.9322 - val_loss: 0.1884 - val_acc: 0.9323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27daf552448>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_text, \n",
    "          train_label,\n",
    "          validation_data=(test_text, test_label),\n",
    "          epochs=5,\n",
    "          batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_elmo_256_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('text_processing': conda)",
   "language": "python",
   "name": "python37664bittextprocessingcondacdb2982750b1430d90ffe1db2903e3a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
