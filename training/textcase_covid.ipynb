{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## CLASSIFICATION OF SENTENCESS BASED ON Universal-sentence-encoder and keras modelling #########\n",
    "## https://www.dlology.com/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "# import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Lambda\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I need daily rations in Attur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Give rice  dal oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>people are hungary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>provide rations for 6 people for 10 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Need prepared food for 20 people in slum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                      text\n",
       "0     0             I need daily rations in Attur\n",
       "1     0                        Give rice  dal oil\n",
       "2     0                       people are hungary \n",
       "3     0  provide rations for 6 people for 10 days\n",
       "4     0  Need prepared food for 20 people in slum"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataframe(filename):\n",
    "    lines = open(filename, 'r').read().splitlines()\n",
    "    data = []\n",
    "    for i in range(0, len(lines)):\n",
    "        label = lines[i].split(' ')[0]\n",
    "        label = label.split(\",\")[0]\n",
    "        text = ' '.join(lines[i].split(',')[1:])\n",
    "        text = re.sub(',','', text)\n",
    "        data.append([label, text])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['label', 'text'])\n",
    "    df.label = df.label.astype('category')\n",
    "    return df\n",
    "\n",
    "df_train = get_dataframe('sentences.txt')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "### list of one-hot encoded labels\n",
    "train_text = df_train['text'].tolist()\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = len(df_train.label.cat.categories)\n",
    "module_url = \"tf_sent_encoder_2_MODEL_PRETRAINED\" \n",
    "embed = hub.Module(module_url)\n",
    "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)),signature=\"default\", as_dict=True)[\"default\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0504 14:34:07.140520 20892 deprecation_wrapper.py:119] From c:\\users\\i511977\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0504 14:34:07.143542 20892 deprecation_wrapper.py:119] From c:\\users\\i511977\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0504 14:34:09.596715 20892 deprecation_wrapper.py:119] From c:\\users\\i511977\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0504 14:34:09.793557 20892 deprecation_wrapper.py:119] From c:\\users\\i511977\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0504 14:34:09.841674 20892 deprecation_wrapper.py:119] From c:\\users\\i511977\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(UniversalEmbedding,output_shape=(embed_size,))(input_text)\n",
    "dense1 = Dense(256, activation='relu')(embedding)\n",
    "dense2 = Dense(128, activation='relu')(dense1)\n",
    "pred = Dense(category_counts, activation='softmax')(dense2)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 164,869\n",
      "Trainable params: 164,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_dataframe('test.txt')\n",
    "### list of one-hot encoded labels\n",
    "test_text = df_test['text'].tolist()\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Need food for diabeties patient'],\n",
       "       ['I want bread and rice for my home'],\n",
       "       ['arm broken need to go to hospital'],\n",
       "       ['food poisoning by eating old distributed food'],\n",
       "       ['network tower broken down in whitefield'],\n",
       "       ['calls are not connecting from airtel'],\n",
       "       ['I am a doctor  my car brokedown and want it to get repaired urgently.'],\n",
       "       ['My visa about to get expire. Want some travel arrangements to be done to fly back to Austia.'],\n",
       "       ['My neighbor attempted suicide .She is in hospital right now  urgent help needed'],\n",
       "       ['I saw bruises on my maid face. I think she is a victim of domestic violence.']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "20/40 [==============>...............] - ETA: 2s - loss: 1.6075 - acc: 0.2000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x000001BD7E89D828>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\i511977\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 88ms/step - loss: 1.6110 - acc: 0.1500 - val_loss: 1.5837 - val_acc: 0.4000\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5484 - acc: 0.7250 - val_loss: 1.5432 - val_acc: 0.6000\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4864 - acc: 0.9500 - val_loss: 1.4984 - val_acc: 0.7000\n",
      "Epoch 4/10\n",
      "20/40 [==============>...............] - ETA: 0s - loss: 1.4171 - acc: 0.9500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x000001BD7E89D828>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\i511977\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4202 - acc: 0.9750 - val_loss: 1.4440 - val_acc: 0.7000\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.3395 - acc: 0.9750 - val_loss: 1.3813 - val_acc: 0.7000\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.2457 - acc: 1.0000 - val_loss: 1.3108 - val_acc: 0.7000\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.1359 - acc: 1.0000 - val_loss: 1.2333 - val_acc: 0.7000\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0181 - acc: 1.0000 - val_loss: 1.1511 - val_acc: 0.7000\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.8930 - acc: 1.0000 - val_loss: 1.0709 - val_acc: 0.7000\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7621 - acc: 1.0000 - val_loss: 0.9899 - val_acc: 0.7000\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=10,batch_size=20)\n",
    "  model.save_weights('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x000001BD7E89D828>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\i511977\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '4']\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"wheat exhausted in hospital canteen\", \n",
    "            \"my neighbors house has crying voices. I think they need help\"]\n",
    "\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./model.h5')  \n",
    "  predicts = model.predict(new_text)\n",
    "\n",
    "categories = df_train.label.cat.categories.tolist()\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "print(predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4154314 , 0.2754173 , 0.07836786, 0.13586688, 0.09491654],\n",
       "       [0.16206545, 0.1603227 , 0.15349114, 0.09350415, 0.43061662]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## With LARGE augumented datasets -  Single Label - Universal Sentense Encoder - Keras modelling ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Lambda\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['label','text'])\n",
    "trainset = sklearn.datasets.load_files(container_path = 'datalarge',encoding = 'UTF-8')\n",
    "\n",
    "def get_dataframe(lines):\n",
    "#     lines = filename.splitlines()\n",
    "    data = []\n",
    "    for i in range(0, len(lines)):\n",
    "        label = lines[i][0]\n",
    "    #     label = label.split(\",\")[0]\n",
    "        text = ' '.join(lines[i][1:])\n",
    "        text = re.sub(',','', text)\n",
    "        data.append([label, text])\n",
    "    df = pd.DataFrame(data, columns=['label', 'text'])\n",
    "    df.label = df.label.astype('category')\n",
    "    return df\n",
    "\n",
    "for k in range(len(trainset.target)):\n",
    "    labelled_sent= trainset.data[k].strip().split('\\r\\n')\n",
    "    Label=[trainset.target[k]]*len(labelled_sent)\n",
    "    labelled_emb = list(zip([s for s in Label], [s for s in labelled_sent]))\n",
    "    df_train = get_dataframe(labelled_emb)\n",
    "    df=pd.concat([df,df_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df['label'], test_size=0.2,random_state=42)\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = np.array(X_train, dtype=object)[:,1][:,np.newaxis]\n",
    "train_label = np.asarray(pd.get_dummies(X_train.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = np.array(X_test, dtype=object)[:,1][:,np.newaxis]\n",
    "test_label = np.asarray(pd.get_dummies(X_test.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = len(np.unique(X_train.label))\n",
    "module_url = \"tf_sent_encoder_2_MODEL_PRETRAINED\" \n",
    "embed = hub.Module(module_url)\n",
    "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)),signature=\"default\", as_dict=True)[\"default\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(UniversalEmbedding,output_shape=(embed_size,))(input_text)\n",
    "dense1 = Dense(256, activation='relu')(embedding)\n",
    "dense2 = Dense(128, activation='relu')(dense1)\n",
    "pred = Dense(category_counts, activation='softmax')(dense2)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3540 samples, validate on 885 samples\n",
      "Epoch 1/5\n",
      "3540/3540 [==============================] - 264s 75ms/step - loss: 0.8755 - acc: 0.6969 - val_loss: 0.2986 - val_acc: 0.9051\n",
      "Epoch 2/5\n",
      "3540/3540 [==============================] - 15s 4ms/step - loss: 0.2148 - acc: 0.9325 - val_loss: 0.1674 - val_acc: 0.9401\n",
      "Epoch 3/5\n",
      "3540/3540 [==============================] - 15s 4ms/step - loss: 0.1162 - acc: 0.9664 - val_loss: 0.1158 - val_acc: 0.9616\n",
      "Epoch 4/5\n",
      "3540/3540 [==============================] - 15s 4ms/step - loss: 0.0733 - acc: 0.9828 - val_loss: 0.0951 - val_acc: 0.9661\n",
      "Epoch 5/5\n",
      "3540/3540 [==============================] - 14s 4ms/step - loss: 0.0484 - acc: 0.9898 - val_loss: 0.0868 - val_acc: 0.9661\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),epochs=5,batch_size=50)\n",
    "  model.save_weights('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = [\"wheat exhausted in hospital canteen\", \n",
    "            \"my neighbors house has crying voices. I think they need help\"]\n",
    "\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./model.h5')  \n",
    "  predicts = model.predict(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food', 'abuse']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categories = np.unique(X_train.label)\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "dict=['abuse','communication','food','fuel','health','travel']\n",
    "ANS=[dict[s] for s in predict_labels]\n",
    "print(ANS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. , 58.2,  0. , 41.8,  0. ],\n",
       "       [86.8, 11. ,  0. ,  0.2,  1.8,  0. ]], dtype=float32)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(predicts*100,decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict=['abuse','communication','food','fuel','health','travel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Combining both above cases ################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = [\"wheat exhausted in hospital canteen and my neighbors house has crying voices. I think they need help\",\n",
    "           \"GIVE ME OIL\"]\n",
    "\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./model.h5')  \n",
    "  predicts = model.predict(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abuse', 'fuel']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categories = np.unique(X_train.label)\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "dict=['abuse','communication','food','fuel','health','travel']\n",
    "ANS=[dict[s] for s in predict_labels]\n",
    "print(ANS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63. ,  1.2,  6.9,  8.5, 18.8,  1.6],\n",
       "       [ 0. ,  0. ,  0.4, 99.5,  0.1,  0. ]], dtype=float32)"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(predicts*100,decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Multilabel - Data Augumented - Universal sentense Encoder -  Keras Modelling ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Lambda\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "session  = tf.Session()\n",
    "K.set_session(session)\n",
    "# session.run(tf.global_variables_initializer())\n",
    "# session.run(tf.tables_initializer())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['label','text'])\n",
    "trainset = datasets.load_files(container_path = 'dataset_small_less_categories',encoding = 'UTF-8')\n",
    "\n",
    "def get_dataframe(lines):\n",
    "#     lines = filename.splitlines()\n",
    "    data = []\n",
    "    for i in range(0, len(lines)):\n",
    "        label = lines[i][0]\n",
    "    #     label = label.split(\",\")[0]\n",
    "        text = ' '.join(lines[i][1:])\n",
    "        text = re.sub(',','', text)\n",
    "        data.append([label, text])\n",
    "    df = pd.DataFrame(data, columns=['label', 'text'])\n",
    "    df.label = df.label.astype('category')\n",
    "    return df\n",
    "\n",
    "for k in range(len(trainset.target)):\n",
    "    labelled_sent= trainset.data[k].strip().split('\\r\\n')\n",
    "    Label=[trainset.target[k]]*len(labelled_sent)\n",
    "    labelled_emb = list(zip([s for s in Label], [s for s in labelled_sent]))\n",
    "    df_train = get_dataframe(labelled_emb)\n",
    "    df=pd.concat([df,df_train])\n",
    "    df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Two people suffering from fever and cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I need to take my father to hospital for dialy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Equipment required at hospital. patients need ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Need an ambulance urgently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>accident in the area and arm broken need to go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>4</td>\n",
       "      <td>Leave the future benefits and look at the pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>4</td>\n",
       "      <td>Lufthansa prepares to resume flights to Canada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>4</td>\n",
       "      <td>Mam I'm migrant worker of uttrakhand stuck in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>4</td>\n",
       "      <td>Many travelers are still waiting to get back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>4</td>\n",
       "      <td>me and my 4 colleagues are stranded in india d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                               text\n",
       "0       2           Two people suffering from fever and cold\n",
       "1       2  I need to take my father to hospital for dialy...\n",
       "2       2  Equipment required at hospital. patients need ...\n",
       "3       2                         Need an ambulance urgently\n",
       "4       2  accident in the area and arm broken need to go...\n",
       "..    ...                                                ...\n",
       "308     4  Leave the future benefits and look at the pres...\n",
       "309     4  Lufthansa prepares to resume flights to Canada...\n",
       "310     4  Mam I'm migrant worker of uttrakhand stuck in ...\n",
       "311     4  Many travelers are still waiting to get back t...\n",
       "312     4  me and my 4 colleagues are stranded in india d...\n",
       "\n",
       "[313 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset.data[0], trainset.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [\"Two people suffering from fever and cold\\r\\nI need to take my father to hospital for dialysis.\\r\\nEquipment required at hospital. patients need mask and sanitizers\\r\\nNeed an ambulance urgently\\r\\naccident in the area and arm broken, need to go to hospital\\r\\nThe delivery workers of essential items should always wear masks as they come in contact with hundreds of people. Government should provide masks for them.\\r\\nMy blood pressure is low.\\r\\nfood poisoning by eating old distributed food\\r\\nI am hungry from last three days. My glucose level is very low and bp is very high. Need help urgently.\\r\\nI was travelling from karnataka to tamil nadu and met with an accident. My bike is broken and I need medical assistance for my fractured leg.\\r\\nmy daughter ate expired medicine. I am unable to call any hospital.\\r\\nmy aunt is feeling uneasiness since morning. This can be a symptom of corona. Send check up team immediately.\\r\\nI read a news article and I suspect I have cancer. As a precautionary measure I want my body checkup\\r\\nThere was sparking in my electric generator due to fuel leakage and I got a third degree burn.\\r\\nDry ration provided is of bad quality. People are getting sick after consuming them.\\r\\nMy father is sick. \\r\\nMy son is ill due to bad weather.\\r\\nI have been coughing for several days now, but recently I am also feeling a blockage on my throat, weaknesss and fever. \\r\\nMy wife is a construction worker and since we don't have enough meals now due to shortage of money, she is weak and unable to get up\\r\\nneed medical assistance\\r\\nMy inhaler isnt working and I need a new one asap.\\r\\nI am running out of my insulin injections.\\r\\nMe and my parents are stuck alone in our house with severe health issues. My father has heart problems and my mother is bedridden. I need medical assistance.\\r\\nHello sir my father is very serious, he has to go to Patna for treatment and in Bihar during the covid19 it's very difficult to get any transportation to reach Patna, and I am in Delhi unfortunately I can't reach there so I request to Bihar police please help him.\\r\\n1,000,000 Nitrile gloves just arrived in stock. Severe worldwide shortage.\\r\\n17 people died in accident no medical help\\r\\n20,000 surgical masks in stock now.\\r\\nB737-700 Cargo operation stripping out passenger cabin seats to load cartons of medical supplies of personal protective equipment (PPE)\\r\\nChina's Ministry of Defense donated to Brunei medical supplies including masks, goggles, protective clothing, waterproof isolation suits, etc. Hoping the assistance would help fighting COVID19.\\r\\nCitySafe Durham is now operating delivery service where volunteers will deliver essential items, drop off prescriptions to vulnerable people.\\r\\nCountries were not being able to access medical supplies from suppliers because governments forbade the exports. Will there be shortages of other products in the coming months, due to government blocks?\\r\\nCovid - medical supplies ecommere shop website template is for selling first aid items, PPE or any other essential medical supplies. \\r\\nExxon Mobile Donates Ambulances, Vehicles, Medical Supplies for COVID-19\\r\\nfaye dsouza please see migrants and others staying in sant Nagar/ garhi/ prakash mohalla east of Kailash need help. There are many without food ration medicines in the area. Request you to please ask NGO/people to help them with basic. \\r\\nFor $50 you can sponsor 25 masks including shipping and materials for our sewists. Any amount will be greatly appreciated.\\r\\nFor anyone looking for PPE Supplies, my company has made it more accessible to the public.\\r\\nGovt sends medical supplies to various States\\r\\nHand Sanitizer, it don't need to wash with water and quick dry. \\r\\nI had the same issue with my medical aid at first but they need a written letter from your psychiatrist stating that your diagnosis is chronic. I don't know how it's determined, but mine was considered genetic.\\r\\nIf anyone is in need, call me okay! I'll use my first aid kit.\\r\\nIf YOU are worried about being exposed to Asymptomatic germs from me, then YOU wear a mask and stay germ free.If my mask will keep you safe, then your mask should also keep you safe if I choose not to wear one.Masks should be optional.\\r\\nIf you have some spare change, this group is buying groceries and medical supplies for New Yorkers in need.\\r\\nIf you need Ventilators,  Thermometer, Isolation STRETCHER.Call us\\r\\nIndianEmbRiyadh Sir, submitted online request to travel India on Medical Emergency, I am suffering from Severe Head abnormality and heart problems. In this lockdown did many tests &amp; MRI, CT Scan etc, unable to trace real cause of illness\\r\\nMy hometown WuxiCity not only dispatched medical workers to Hubei Province badly-hit by COVID19, but also donated medical supplies to its sister sities in 16 countries. Highly appreciated\\r\\nOur Biomedical team has an ongoing partnership with Project CURE, an organization that donates much needed medical supplies to hospitals.\\r\\nOur high school just sent out a request for help for our local hospital in the suburbs. They want us to make surgical caps! They are short supplied.\\r\\nPlace an order for our anti-bacterial hand-wipes!\\r\\nSanitizers 8 ounce available at Neptunes \\r\\nSir, i would like to inform you that, my mother admitted in Nehru Homoeopathic Medical College and Hospital defence colony due to covid 19, she is suffering from sleeping issues and she is crying frequently , i request you kindly help on this.\\r\\nThere have never been adequate stockpiles of necessary medical supplies for this type of contingency, even though it's been known for generations that these situations arise. Capitalism does not safeguard public health.\\r\\ntoday morning team of Doctors will come and take the testing sample. Its noon already and there is no one here to take sample. Also the Aarogya Setu app says I am safe.\\r\\nTrump mulls executive order that would limit any federal contracts for essential drugs and medical treatments to manufacturers in the U.S.\\r\\nWe are manufacturers of best quality ppe kits for health care workers and our doctors.\\r\\nWe are your trusted online medical store. We help you deliver all your essential medical needs at your doorstep.\\r\\nWhere's the medic car when you need one, or were these days when you would need your own first aid kit\\r\\nWHO  to condemn Houthis piracy on medical supplies, and to pressure the Houthi militia leaders to release medical materials and distribute them to hospitals to contribute to  the efficiency of health systems to counter the Coronavirus  outbreak\\r\\nZombieSquadHQ  has a fully stocked First Aid station and medics.\",\n",
       "  '5 people trapped with no internet in my locality\\r\\nrequesting mobile recharge for 2 phones\\r\\nnetwork coverage is weak in my house\\r\\nno connectivity in wifi router due to some wiring problem.\\r\\nI am not able to call helplines\\r\\nmy phone is damaged. Requesting spare\\r\\nis it possible to deliver a phone in kormangla as mine is not working\\r\\ndue to sim card issue I was not able to create hotspot\\r\\nthe network tower broken down in Whitefield\\r\\ncalls are not connecting from airtel\\r\\nI was trying to connect to my family. someone please guide me.\\r\\nDue to frequent power cuts, i am not able to watch tv or radio. \\r\\nWhy governement is not spending money to improve the communication services in India?\\r\\nWhy call center/customer care of COVID19-HelpCare do not respond on time.\\r\\nHelplines numbers are not working properly. Please update them.\\r\\nTower in my area has sparking issues.\\r\\nWhenever i try to reach some authorities from governement they just hang the call and don\\'t respond. I am really irritated by this behaviour.\\r\\nTelecom companies have raised the prices of net pack so much that they are not affordable.\\r\\nInternet facility provided at railway station is so bad that i am not even able to buy groceries online.\\r\\nThere has been transformer fault in our area and none of our devices are working and all our phones are discharged and we are not able to contact anyone to request for repair for many days now.\\r\\nAll electricity is down in my society due to which all electronic devices are off. Phone, wifi laptop all shut\\r\\nDue to poor network in remote area we are unable to attend class regularly\\r\\nAfrica races to fill telecoms \"not spots\": Resourceful medical services use 3G and 2G signals to overcome poor network coverage.\\r\\nam I the only one that has poor network ?\\r\\nAmazing bundles are good unfortunately the free WhatsApp part doesn\\'t work when the bundles is depleted. Secondly in my current place the Airtel network is very poor\\r\\nAtleast they should not set time limit as in remote cities , network connections are poor and all students cant afford latest  laptops smartphones and scanners andeven it is  not feasible to get it repaired during this covid 19 crisis,future of students  is at stake due to technology\\r\\nBecause of poor poor network speed we are not able consume even half of our daily limit. Nobody needs top-up.\\r\\nCan you up your game in network? Very slow and poor network. Don\\'t lure us yet when we buy the bundles, it takes decates to load\"\\r\\nCommunication is key, more so during this pandemic. If your charity needs help making sure your comms is up to scratch, head over to Media Trust\\'s Volunteer Platform and post an opportunity request to be matched with an expert comms volunteer.\\r\\ndd national and dd retro the network is very poor, regularly goes off. DDNational should upgrade the system while launching new channel\\r\\ndo we do this?  Communication.  People need to find information from the CDC or Fauci and make sure it is tweeted several times until it is picked up and retweeted several times.  Tweet to the news and request they help us get the info.\\r\\nfacing poor network and slow speed issue.\\r\\nGuys my net connection since morning isn\\'t working and all modes of communication to reach out to you aren\\'t working.\\r\\nHello team I am using airtel number but network is very poor. Kindly rectify as soon as possible. U give lot advertising from forest airtel give good network but u r not able to proved in city.\\r\\nHi I have Airtel Prepaid, since today morning there is  no  network showing on my mobile also tried with different handset still not showing seems there is an issue with my number only I am struggling to get support. Kindly help asap.\\r\\nHi my name is Rasmi Ranjan Sahoo  and my mob no is 7788914484 and I am a Airtel user. From last 2months I had face lots of network issue and I also try to connect with your customercare but unable to connect with them your team always say due to COVID-19 situation \\r\\nHope you consider this request, infact online delivery of these essential goods will also not create crowd and chaos and it will help efficient work from home as many are struggling with these items like charger, headphones, etc.\\r\\nHow much time do you cheat people like this. This is the screenshot of result which I got for data speed test in NetVelocity. Providing poor data speed and showing no speed in result. Better I will port my Network from reliancejio to idea_cares \\r\\nI am still experiencing a very poor connection! No one has contacted me. This network is pathetic! How are you still charging people when you can\\'t deliver on your service?\\r\\nI have placed request for new BHARAT Broadband connection, no any communication feom sangli office, even unable to contact them to know the status.\\r\\nI have tried to request help by all means of communication to airte lindia but all in vain.\\r\\nI thank for adding 3 more helpline numbers to ease communication of the stranded migrants with our state level help desk.\\r\\nI want to ask i have pending two month electricity bill..fir to covid and fund issue not able to pay bill... Please let me know if I do not make payment than will u disconnect line?.also request you to please wevied off inetrest charges....please help\"\\r\\nI was trying to Livestream it but Etisalat network is really poor.\\r\\nIdea very poor network. They said i will be getting 4g speed but in reality i am not even getting 2g . And in the app if we chat about the same with chat boot it says that the data limit is over. very bad n worst experience.\\r\\nInstead of telecasting more news about Corona pls start an initiative by conducting webinar sessions for 10th and PUC students ( any subject) This will help the ppl in greater way. Thanks\\r\\nIts been a week with no Vodacom network in Palma, Cabo Delgado, the ballons went dead\\r\\nIve called an average of 400+ times every day for over 3.5 weeks/have never spoken to a human being/Had issues with communication and missed my payment request date/over 3 weeks/what do I do? I need help/It won\\'t let me request payment for 1.5 months now.\\r\\nlast Sunday I paid for the renewal of my broadband. After receiving the service request, there no further communication! Personal not taking my calls / not responding to WhatsApp... Pls help\\r\\nlight off, network poor , mobile battery  low .see u again .follow me i will give u fb. Thank you every one.\\r\\nMy postpaid Airtel sim stopped working  this afternoon . No network coverage available as it says insert sim. Got a call from airtel rep saying Airtel stores are closed.what to do next? Pls help\\r\\nNetwork is very poor even not talk more than 8 sec in a single call. Every time we connect call disconnect within 5-8 sec. Location is Bihar, Dist- West Champaran, PS- Chanpatia, Vill-Pokharia Rai\\r\\nPhone communication may help clarify the request and whether or not we can \"designate\" an account in accordance with VA regulations.\\r\\nPlease do something about your network tower at Candolim Goa. The signal strength is so poor that the internet won\\'t work at all.\\r\\nPoor Network Airtel at Assam, Silchar, Nagatila. airtelindia I am recharged huge amount but doesn\\'t good network and I couldn\\'t open any apps, browser. I don\\'t like. please improve whatever I can.\\r\\npoor Network Airtel India. I couldn\\'t open any browse and apps. I didn\\'t play any game esily. only connection error.\\r\\nPoor network service from Airtel since last 1 years. Poor calling due to call drop issues and poor internet\\r\\nPossible to send email/txt confirmation on connection request ? In current situation, manpower shortage is understandable. But some communication on collected email+ph no. is fair ask. \\r\\nSo fed up with virginmedia Whenever I\\'m watching a movie on demand it suddenly stops with a network availability error. I pay so much for a service that is so poor. Am seriously considering giving up on them. Can\\'t stand the constant price increases with decreases in service.\\r\\nToo much bad network in my area a lot of tower available but the facility is very poor all network facility is very poor everyone getting speed in kb \\r\\ntoo much poor network in my area from past one week. a 3 mb file taking cou0le of minutes to download. cant surf youtube, insta\\r\\nVodacom SMS we do receive and can send but it\\'s not easy, it is difficult to make or receive phone calls, we always get voice mail notifications. We hardly surf the net due to poor network coverage. 1 minute you have access the other minute dololo.\\r\\nWhat kind of poor internet airtel provides now I understand why JIO is better network than Airtel.\\r\\nWhat we want is a constant and reliable network.not a network which disappoints you at the middle of a conversation.develop your network. it is so poor\\r\\nwhen will u call me?? who will compensate for my 1 day data loss? Moreover, your network is so poor that sometimes i feel like changing the network.\\r\\nWhy why poor connection network daily Airtel. I am recharge regularly but I couldn\\'t browse and open any apps, I don\\'t play pubg, any game\\r\\nwriting on behalf of my brother in Bengaluru. The Airtel network connection in his area ( Thala Kaveri layout) is poor and inconsistent. He has registered a complaint and no response yet. Can you please look into it and suggest solutions? Kindly help.',\n",
       "  'I need daily rations in Attur\\r\\nprovide rations for 6 people for 10 days\\r\\nNeed prepared food for 20 people in slum\\r\\nNeed groceries for a family in quarantine\\r\\nmy sugar, eggs and milk are over. I have small chidren. \\r\\nNeed food packets for 20 people\\r\\nI want bread and rice for my home\\r\\nFive construction workers started walking from kerela to bihar but are stranded in karnataka border. Get them food and help them go to their home.\\r\\nThe temporary bridge is broken due to heavy flow of river water, so we are not able to go to cities to buy groceries and medicines. Help us.\\r\\nI cannot cook food at my home as I do not have groceries and cooking oil.\\r\\nDry ration provided is of bad quality. People are getting sick after consuming them.\\r\\n5 kg Rice, 10 kg Wheat, 20 L Oil needed\\r\\nPeople are starving due to COVID19 crises.\\r\\nMy maid complaint that she has money but was unable to buy groceries as nearby shops are closed and police is not allowing them to go to far places. Please make sure essential services are working properly and Help my maid.Her No. is 7625472689\\r\\nNo one is taking care of roadside animals. They are starving.Plase do something to help them instantly\\r\\nAs my young daughter is still a toddler, I need some cereals or Cerelac and milk urgently.\\r\\nEven though the local auhtorities have arranged for raw vegetables for us to have, please provide us with oil and spices to cook them, which we have been asking for so long.\\r\\nI am unable to find fruits or vegetables\\r\\nWhere can I get bread and butter.\\r\\nEdible supplies are not available in my area, i need bread and groceries\\r\\nWe are 6 people in my family and we are out of food. Anything you can give, please do\\r\\nI need food supplies for my family. Require lunch, dinner, meals everyday. \\r\\nI am starving and hence require daily meals. please supply meals for me.\\r\\nInternet facility provided at railway station is so bad that i am not even able to buy groceries online.\\r\\n10lbs down in quarantine  No Food \\r\\nAlthough COVID-19 has highlighted fragility of our food systems, it is still an opportunity to change, both in production & consumption patterns and in private & public actions. Time 4 an ecological conversion\\r\\nchildren  stuck  lockdown hungry\\r\\nFor those of you that missed yesterday\\'s Food Drop, check out The City of Baltimore\\'s Grocery Boxes pick up locations and times.\\r\\nGovernments must work together to avert disruptions to food supply chains. Food protectionism must be avoided\\r\\nGovernments must work together to avert disruptions to food supply chains. Food protectionism must be avoided.\\r\\nHard to plan out a menu when you don\\'t know what the grocery situation will look like in a few months.\\r\\nhe has run out of all the savings and is dependent on NGO to get ration during this lockdown..Request you to Please help..Thanks \\r\\nHigh End Kosher Milk and Yougurt from upstate small farmers to Feed The Needy at Masbia during the current Food Crisis and Hunger Wave\\r\\nHow is your moms pizza??\\r\\nI hate when I go to the kitchen looking for food, and I find is ingredients.  food  no food  hungry\\r\\nI urge to help me in getting food to 20 migrant workers stuck in Regonda P/S Sundhrala Tehsil Husnabad District Siddipet . This is their contact: Asif Hussain 9541028380. Thank you for your kind cooperation!\\r\\nI was so hangry just now every little thing my kids and the dogs did threw me into a rage. I have no idea how people skip breakfast or fast for any length of time.\\r\\nI\\'m hungry and cant decided what I want.\\r\\nI\\'m raising money for Help me buy Urgent Food for People in Colombia. Click to Donate\\r\\nIn addition to food for people isolated at home during special periods, medical personnel in the frontline also need food supplies, and packaging of large amounts of food requires a large number of food boxes and ration kits\\r\\nLiterally all I\\'ve even today is some toast with Nutella and a protein shake.  needfood\\r\\nlockdown  no food  no shelter   \\r\\nMan Could Soon Be Eating Rice For Breakfast, Dinner And Tea.\\r\\nMany vulnerable families are struggling to manage daily meals, money to pay rent and access appropriate medical treatment during the lockdown \\r\\nNeed Food Hungry\\r\\nNew survey finds food waste on the rise as takeout and delivery increases.\\r\\nplease see migrants and others staying in sant Nagar/ garhi/ prakash mohalla east of Kailash need help. There are many without food ration medicines in the area. Request you to please ask NGO/people to help them with basic. \\r\\nProcessing and transportation breakdowns, panic buying threaten vulnerable nations; food crisis with lots of food.Soaring Prices, Rotting Crops: Coronavirus Triggers Global FoodCrisis.\\r\\nRequest to CM - people are dying with starvation who don\\'t have ration cards, kindly help us to get ration cards, MORE people DYING with starvation RATHER THAN COVID 19, Without transport going to AP GETTING Ration card is not Possible.\\r\\nso on top of  rent being late  no food and rationing \\r\\nSoaring Prices, Rotting Crops Coronavirus Triggers Global Food Crisis Processing and transportation breakdowns, panic buying threaten vulnerable nations; a food crisis with lots of food\\r\\nSomebody help me out with some food  HELP  COVID19\\r\\nSteersSA is really proving itself to be a substandard take away joint during this Lockdown.  I ordered  food at 11H30, more than Four and a half  hours later no delivery.  Still sitting hungry. \\r\\nStop Covid19 crisis morphing into a Food Crisis: Support to Africa rice sector. To avoid food crisis in Africa, urgent measures for sustained agricultural growth need to be in place now\\r\\nTackling Food Waste in the time of Food Insecurity and making progress .\\r\\nThe crisis has snarled supply chains, stoked fears of food shortages, and sparked warnings of a potential spike in global hunger\\r\\nThe current food crisis situation we are facing is not because we do not have food produced, but because there is a challenge in moving food across regions\\r\\nThe team have been out this week to our families in Bulacan delivery food packs.They were very happy to see them and receive this much needed essential supplies.\\r\\nThe WHO has warned of hunger famines and indications are for food shortages as governments push their bogus agenda.  THAT means start preparing! AND keep preparing!\\r\\nThere are many women lives in aarey colony (unit no 22) hve no option for food and dnt have money to buy essential items such as wheat, rice, oil, etc. They lost their jobs due to COVID-19. Request you to pls help them.\"\\r\\nThis startup is looking to empower people to grow more food for themselves.\\r\\nThose affected or at high risk of developing COVID19 must have access to food.\\r\\nToday we organized a virtual event on food security and nutrition looking at responses & early results to avert a global crisis.\\r\\nWay more global deaths from starvation than coronavirus.Loss in agriculture sector.\\r\\nwe got a request from weavers families total 55 families in need of groceries poor families please help\\r\\nZomatoIN done big mistake ordering food during lockdown since food packaging and handling was worst no hygiene and delivery guys looks in bad condition, now I am worrying why we ordered online food, packing were half open. Not sure how long I need to stay hungry.',\n",
       "  \"run out of gas. Unable to get gas cylinders\\r\\nrequesting supplies of kerosene\\r\\nthere are drums of flammable oil stored in our locality. Is it possible to store them elsewhere\\r\\nthere has ben a leakage in gas pipeline for the past few days. Cant find professionals to fix it.\\r\\nAmbulances are unable to function due to scarecitry of fuel.\\r\\nToo frequent power cuts in our locality. Need supply of kerosine oil to run the generator\\r\\nReduce oil prices immidiately\\r\\nAll the grocery shops near by do not have any kerosene oil or cooking oil. Government should provide it for people.\\r\\nPoor families cook food on the stove using wood. But they cannot go far to collect due to restrictions. Give them fuel for cooking food.\\r\\nFrequent power cut in the area and we do not have candles or oil for lighting. \\r\\nThe constant burning diya lamp in the temple needs oil to continue otherwise it will bring havoc on humanity.\\r\\nIf you fuel your journey on the opinion of others, you are going to run out of gas.\\r\\nFuel is precious. Please use it wisely.\\r\\nIn upcoming days CNG usage will rise to more than petrol and diesel.\\r\\nPlease provide coal for burning of stove.\\r\\nWe have been eating raw vegetables and fruits for the last 3 days as we do not have cooking gas in our cylinder and no one has delivered our new cylinder which we have requested a long time back.\\r\\nI haven't received the big 19 kg gas cannister which I applied for almost 20 days ago.\\r\\nNeed gas for car so that I can reach home.\\r\\nThere was sparking in my electric generator due to fuel leakage and I got a third degree burn.\\r\\nI can hear voices of crying children from my neighbor. I think they are being abused.\\r\\nYesterday i saw few people bullying a person from my locality.\\r\\nWas passing by the vathur bus stop and a group of boys teased me.\\r\\nI feel that someone is going to break in and kill me.\\r\\nThe only shop in my area is charging very high prices for items.\\r\\nAn old man is getting abused by his family\\r\\nSomeone is continusly following me. Feeling scared.\\r\\nI am not able to contact my friend from past few days. I think his life is in danger.\\r\\nI saw bruises on my maid face. I think she is a victim of domestic violence.\\r\\nDue to lack in any means of transport horse cart owner is charging very high prices.\\r\\nMy father is ill treated.\\r\\nI recently came to know that my brother is adopted and that's why he is ill treated by my parents.\\r\\nNearby shops are charging way beyond the MRP prices.\\r\\nDevesh was beating Aabhas with rod stick.\\r\\nThese days students are learning to bully from school itself.\\r\\nI think i am in depression due to mental stress i am facing from my family regarding my marriage.\\r\\nPolice assaulted senior citizen for not having proper ration cards.\\r\\nMedia houses have to much of liberty and they harass people a lot.\\r\\nMy neighbor, Mr. Rao is a salesman who is frustrated due to no income and he fights with his wife, shouts horribly and breaks things almost everyday\\r\\nAn elderly man in our locality was tested positive for coronavirus long back, has recovered and since then everybody is hateful of the entire family and even the shopkeepers harass them by refusing to sell items to them. \\r\\n3 people have crashed in my neighbors house for some money matter.\\r\\nSoon, the local social media fills with xenophobia and hate, along with demands that the foreigners go back to where they came from.\\r\\nAll of you are missing the point. One wrong does not justify another wrong. If you say that  Muslims are spreading  hate , so are you by citing selected verses from  Quran. How can you condemn something while doing exactly the same yourselves. It is  hypocrisy \\r\\nCrazy white woman terrorizing brown people  racism\\r\\nIn this webinar,  ryanmauro speaks to former jihadist  JesseMorton and former neo-nazi  SchoepJeff to discuss how extremists are using the current  pandemic to justify  Antisemitism and how they find a common focus of their  hate-filled ideologies.\\r\\nRape case of a minor Dalit Girl at Chaderghat,Hyd. Team of SIPAHE NGO headed by Gen.Sec Fazil Mohammed Khan visited victim's house collected information,assured necessary helpand provided RationKit.\\r\\nAbusive Relationships: Need get out safely\\r\\nlove  selfcare  selflove  trauma  single4life  confused  depression  anxiety  reactive abuse\\r\\nOur children are traumatized on so many levels by this quarantine from Covid-19.  No Food  Sexual Abuse\\r\\nrape by parents and relatives is now common; where then will the generation of  girls find refuge. One who is supposed to be protecting you from  sexual  physical and  emotional  abuse victimizes you; where is  socialprotection Who then shall we trust? \\r\\nShe is an absolute  arrogant  disgrace -  shameful and no respect for the gentleman she was interviewing. She planned to gang up on him and hit him hard - lack of  rational sense was from her. Pure  hate from her.  she is a disgrace.\\r\\nStop this. Stop all of this.queer phobia  forcible Institutionalisation  forcible Medication  suicide  abuse  sexism\\r\\nThink there's a minority who have an issue with  NHS staff as I got verbally abused in a store - a woman shouted in my face as she pushed me to go in a queue. When I brought my ID out to get discount she shouted oh clap for the NHS hero amongst other things\\r\\nTook me years to realise. It isn't ok! If the Warning signs show, get out from abuse!\",\n",
       "  'I want to travel back to my native place.\\r\\nWant curfew pass for case of emergency travel.\\r\\nFirstline workers facing issues as no cabs are available\\r\\nWant to go back to my family place. Currently staying in the hotel.\\r\\nWant to travel from bangalore to delhi. Any means of transport available?\\r\\nResiding in green zone but not able to get travel permssion even for getting essential household items.\\r\\nFew days back my vehicle was seized by police, now don\\'t have any means of transport.\\r\\nMy visa about to get expire. Want some travel arrangements to be done to fly back to Austria.\\r\\nFive construction workers started walking from kerela to bihar but are stranded in karnataka border.\\r\\nI live in pg where its difficult to get food. When are flights and trains getting started.\\r\\nYou are giving permission to celebrities like Rishi kapoors daughter to travel while normal people are not getting passes within the city. \\r\\nI cancelled my advance booking on irctc website but refund is not initiated yet.\\r\\nDue to lack in any means of transport horse cart owner is charging very high prices. Please give update when daily buses will resume.\\r\\nThe temporary bridge is broken due to heavy flow of river water, so we are not able to go to cities.\\r\\nDaily a truck of refugees breaks into the city via the south highway road. Travel ban should be imposed on the trucks too.\\r\\nI want to drive to my home town to attend a funeral and need paas. send me back.\\r\\nI came to Bangalore to work and have been stuck here for so long due to the lockdown, I need to get to my elderly parents who are in a small town in Maharashtra which is declared a red zone. \\r\\nMy son went to Delhi to prepare for competitive exams and now he is stuck there with some friends as their institution has closed down and he is unable to return. \\r\\nMe and family stranded on roadside on the way to mysore. Car is not working.\\r\\n I am a Canadian resident.. I am in Panama and the airport continue closed here and there aren\\'t humanitarian flights to Canada neither. Please I need back to see my family, return to get my job!.  I\\'ve been waiting for a humanitarian flight since early April\\r\\n I appeal to central govt, please  take care of laboure\\'s , provide transport facilities with proper safety.\\r\\n If they start to walk by themselves it\\'s very dif to find them and migrate them. Nd Center gov have already passed notice to all states to make sure they dont need to walk. Now states can arrange transport.\\r\\n U need to stop all this arrange means of transport for them n give them tickets at station as most of them have no email id n no means of sending information via mail\\r\\n10 migrant labour from Bihar near my locality are stuck here they  want to go back to their native place by road. I have been trying to register them on below site but it is not working\\r\\n100,000 Crew Members Stranded on Cruise Ships as Cruise Lines Refuse to Agree to Pay for Repatriation Expenses\"\\r\\n203 COVID19 patients in Uganda. I request you stop these trucks. Save us,  it\\'s suicidal to lock us inside and allow Corona Virus enter Uganda freely like this\\r\\n24 stranded migrant worker stuck at Venkateswara engineering collage\"\\r\\n3 lockdown ends tomorrow and Railway Minister wakes up to see that migrant labour is stuck. After 54 days of lockdown he is asking to prepare list\\r\\n70 workmen stuck in Tidong HE Project near Recongpeo to go back to their homes in Bihar. No help from any nodal officer for migrant workers yet. Please take needful action at the earliest.\\r\\nAdd more world class international outbound flights so stranded that NRIs can reunite with their families .Prove you are world class by being human first. \\r\\nAir Asia Support Since yesterday I already DM my booking code for some help. My flight to Thai cancelled due to covid-19, already request credit account thru AVA. However I can not request credit account for my flight back from Thailand a week later. Until now no response.\\r\\nall the migrant workers who are stuck on the way roads and  going to they home  MAKE THEM to come on police station\\r\\nAll those who wish to travel from gujarat to jk by train have to register on gujarat govt portal. Anyone from jk who is stranded in Gujarat may do so immediately. Its only train scheduled from Gujarat.\\r\\nAnyone any idea when atleast domastic flights will resume?\\r\\nAs Phase 2 of Vande Bharat Mission to carry Indians from other countries is slated to commence from May 19. NRIs have urged the Ministry of Civil Aviation to resume connecting flights to New Delhi, from south India.\\r\\nBut, what about those STUDENTS  and WORKERS who stuck in WESTBENGAL and want to go back to their home.\\r\\nCan anybody advice how to bring my wife and 4month son from alipurduar to delhi \\r\\nCan we go home with private 4 wheeler vehicles? Actually mother is stuck with me since Holi.\"\\r\\nCan you please tell us when will the flights resume for domestic sector.\\r\\nDear sir request you please arrange Flights from Chennai to ahmedabad as I am here with family and kids want to travel back to ahmedabad. I am here since lockdown started .You have started many flights all over India . But no flights is there from chennai to Ahmedabad\\r\\ndear sir we are lot of Kashmir stranded in Delhi mostly patients and aged who can\\'t travel by road pls resume some domestic flights\\r\\nDear Sir, My sister in law has applied for e pass to travel from Mumbai to Beed district in Maharashtra. It\\'s been a long time and still not received any update.Request you to please help.\\r\\nEffort from Congress to mobilize all local units to arrange transport. But if done, the goodwill will be tremendous.\\r\\nEMPLOYERS use public transport because they live miles away and have no alternative. noone is using public transport\\r\\nHello kind people, plz help @Deeksha01535151 in raising funds for migrant workers stuck in Delhi. Contribute whatever you can, no amount is small.\\r\\nHello sir my father is very serious, he has to go to Patna for treatment and in Bihar during the covid19 it\\'s very difficult to get any transportation to reach Patna , and I am in Delhi unfortunately I can\\'t reach there so I request to Bihar police please help him.\\r\\nHi, unfortunately we have no update on when normal international flights will resume due to the unpredictability of COVID-19 and other countries immigration changes.\\r\\nHow can i get the e-pass to travel back from New Delhi to Prayagraj. My Brother\\'s is Stuck in New Delhi. Since lockdown and veryuch in trouble. I request to New Delhi and UP government to help us in this situation.\\r\\nI am a travel registered nurse who was supposed to come to your county to work but I was cancelled by the hospital before starting. Help, I am stuck here\\r\\nI can\\'t able to understand that Why they are not resuming the domestic flights. If they can resume train why not flights.Every one wants to go to their families. \\r\\nI had been stuck in Kolkata because of lockdown.I want to travel back to my hometown Hyderabad address: More Market Lane, Girija,khardah, kolkata 700 115.\\r\\nI had filed a refund request with cbdt. Till today I have not received the amount nor have I received any communication from the department. I am a small entrepreneur. Could you please help me\\r\\nI have applied for migrant pass for up before 20 days on jansunvai app.I have alone and  stuck in Mumbai. I am facing too much problem. My registration no is 500. Please do needful so that I can reach my home. Please sir help me to reach my home.\\r\\nI have been issued travel pass but no further communication regarding travel options. I had opted for govt assistance in traveling back to Bengaluru from Ahmedabad.My father received no response in DC office too \\r\\nI m stuck in India with my 8month old infant. I can\\'t take the repartition flights as my visa isn\\'t stamped .\\r\\nIf domestic and international flights were to resume in June, would you?\"\\r\\nIf domestic flights don\\'t resume in your Lockdown 4.0 there are gonna be problems. People will pushback hard because hunger and trauma will get the people on road. The clock is ticking sir, please act now before it\\'s late.\\r\\nIf The border can be reopened why not international flight arrivals? Why should Pakistanis be left stranded in other countries? Resume international flights.\\r\\nIf the lockdown gets extended beyond may 17, I kindly request you to consider air services within Tamilnadu for inter district travel. Thanks.\\r\\nIf you are not going to resume international flights soon, then why did you have to give us false hopes? We are people stranded away from home and all alone in PHC, Nigeria.\\r\\nInternational travel need to be allowed, subject to testing before boarding. This\\'ll enable people to move to homes and jobs. It\\'ll also help trace infected people plus revive the airline industry and save jobs. emirates , British_Airways and others could resume flights under new rules.\\r\\nInterstate movement by Stranded Labours stuck in Narela, Delhi are continuously asked to fill info on different portal of delhi government without any action to move by shramik express\\r\\nis therE anY actioN takeN bY jharkhanD govT.foR migranT workeR tO brinG bacK tO hiS homE? iF yeS thaN whY mY eldeR brotheR iS stilL stucK iN mehsanA,gujraT? registatioN waS donE nearlY 20 dayS agO buT stilL nO responsE. pleasE trY tO brinG hiM bacK immedietelY.\"\\r\\nJust another day to go before this phase of the lockdown is to end. No clarity yet on what lockdown 4.0 has in store for us in Delhi.  Citizens need time to plan....If offices have to open we need to know if any public or commercial transport will be available.\\r\\nLeave the future benefits and look at the present situation.Nothing is benefiting air travellers for now.People are stranded in different places and requesting you everyday to resume domestic flights.\\r\\nLufthansa prepares to resume flights to Canada in June .We can\\'t even travel province to province.\\r\\nMam I\\'m migrant worker of uttrakhand stuck in WB. I\\'m trying several times to communicate with nodal officer or local police but failed. Kndly plz help how can i reach you from salanpur, WB Local police said bring your personal vehicle only that pass we can issue.\\r\\nMany travelers are still waiting to get back to their homes, jobs and daily routine.\\r\\nme and my 4 colleagues are stranded in india due to lockdown and want to travel to uganda as our company needs us urgently. We all have valid work permit and other required documents. So please consider our request urgently. Awaiting for your response'],\n",
       " 'filenames': array(['dataset_small_less_categories\\\\healthcare\\\\healthcare.txt',\n",
       "        'dataset_small_less_categories\\\\communication\\\\communication.txt',\n",
       "        'dataset_small_less_categories\\\\food\\\\food.txt',\n",
       "        'dataset_small_less_categories\\\\others\\\\others.txt',\n",
       "        'dataset_small_less_categories\\\\travel\\\\travel.txt'], dtype='<U61'),\n",
       " 'target_names': ['communication', 'food', 'healthcare', 'others', 'travel'],\n",
       " 'target': array([2, 0, 1, 3, 4]),\n",
       " 'DESCR': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Two people suffering from fever and cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I need to take my father to hospital for dialysis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Equipment required at hospital. patients need mask and sanitizers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Need an ambulance urgently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>accident in the area and arm broken need to go to hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>4</td>\n",
       "      <td>Leave the future benefits and look at the present situation.Nothing is benefiting air travellers for now.People are stranded in different places and requesting you everyday to resume domestic flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>4</td>\n",
       "      <td>Lufthansa prepares to resume flights to Canada in June .We can't even travel province to province.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>4</td>\n",
       "      <td>Mam I'm migrant worker of uttrakhand stuck in WB. I'm trying several times to communicate with nodal officer or local police but failed. Kndly plz help how can i reach you from salanpur WB Local p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>4</td>\n",
       "      <td>Many travelers are still waiting to get back to their homes jobs and daily routine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>4</td>\n",
       "      <td>me and my 4 colleagues are stranded in india due to lockdown and want to travel to uganda as our company needs us urgently. We all have valid work permit and other required documents. So please co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  \\\n",
       "0       2   \n",
       "1       2   \n",
       "2       2   \n",
       "3       2   \n",
       "4       2   \n",
       "..    ...   \n",
       "308     4   \n",
       "309     4   \n",
       "310     4   \n",
       "311     4   \n",
       "312     4   \n",
       "\n",
       "                                                                                                                                                                                                        text  \n",
       "0                                                                                                                                                                   Two people suffering from fever and cold  \n",
       "1                                                                                                                                                         I need to take my father to hospital for dialysis.  \n",
       "2                                                                                                                                          Equipment required at hospital. patients need mask and sanitizers  \n",
       "3                                                                                                                                                                                 Need an ambulance urgently  \n",
       "4                                                                                                                                                 accident in the area and arm broken need to go to hospital  \n",
       "..                                                                                                                                                                                                       ...  \n",
       "308  Leave the future benefits and look at the present situation.Nothing is benefiting air travellers for now.People are stranded in different places and requesting you everyday to resume domestic flig...  \n",
       "309                                                                                                       Lufthansa prepares to resume flights to Canada in June .We can't even travel province to province.  \n",
       "310  Mam I'm migrant worker of uttrakhand stuck in WB. I'm trying several times to communicate with nodal officer or local police but failed. Kndly plz help how can i reach you from salanpur WB Local p...  \n",
       "311                                                                                                                      Many travelers are still waiting to get back to their homes jobs and daily routine.  \n",
       "312  me and my 4 colleagues are stranded in india due to lockdown and want to travel to uganda as our company needs us urgently. We all have valid work permit and other required documents. So please co...  \n",
       "\n",
       "[313 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "data=[]\n",
    "length=len(df)\n",
    "for i in range(length * 10):\n",
    "    num1 = i % length\n",
    "    num2 = num1\n",
    "    while (num1 == num2):\n",
    "        num2=random.randrange(length)\n",
    "    data.append([df.label[num1],df.label[num2],df.text[num1] + ' ' + df.text[num2]])\n",
    "    \n",
    "df2 = pd.DataFrame(data, columns=['label1','label2', 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    693\n",
       "4    678\n",
       "0    653\n",
       "2    588\n",
       "3    518\n",
       "Name: label2, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['label2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train[X_train[\"label1\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_csv('dataset_multi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "filter_POS = set(['NOUN', 'NUM', 'ADJ', 'VERB', 'PART'])\n",
    "# ADV, NOUN, ADP, PRON, SCONJ, PROPN, DET, SYM, INTJ\n",
    "# PUNCT, NUM, AUX, X, CONJ, ADJ, VERB, PART, SPACE, CCONJ\n",
    "# def filter_query(query):\n",
    "#     query = query.lower()\n",
    "#     doc = nlp(query)\n",
    "#     tokens = [t.text for t in doc if t.pos_ in filter_POS]\n",
    "#     return ' '.join(tokens)\n",
    "\n",
    "def filter_query(query):\n",
    "    query = query.lower()\n",
    "    # trans = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    # query = query.translate(trans)\n",
    "    # query = re.sub(r'\\.', '. ', query)\n",
    "    query = re.sub(r'[\\t\\n\\r\\f ]+', ' ', re.sub(r'\\.', '. ', query))\n",
    "    # print (query)\n",
    "    doc = nlp(query)\n",
    "    print ([(t.text,t.pos_) for t in doc])\n",
    "    tokens = [t.text for t in doc if t.pos_ in filter_POS]\n",
    "    tokens = [nlp(t)[0].lemma_ for t in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ventilator', 'simcard', 'unavialable']\n"
     ]
    }
   ],
   "source": [
    "query = 'ventilators and simcards. are unavialable'\n",
    "query = query.lower()\n",
    "query = re.sub(r'[\\t\\n\\r\\f ]+', ' ', re.sub(r'\\.', '. ', query))\n",
    "doc = nlp(query)\n",
    "tokens = [t.text for t in doc if t.pos_ in filter_POS]\n",
    "tokens = [nlp(t)[0].lemma_ for t in tokens]\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rice. wheat, masks, sim cards all are available as essential items'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\\.', '. ', 'rice.wheat, masks, sim cards all are available as essential items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gun . is crap'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[\\t\\n\\r\\f ]+', ' ', re.sub(r'\\.', '. ', 'gun    .is crap'))\n",
    "# re.sub(r'\\.', '. ', 'hi. hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rice', 'NOUN'), (',', 'PUNCT'), ('wheat', 'NOUN'), (',', 'PUNCT'), ('masks', 'NOUN'), (',', 'PUNCT'), ('sim', 'NOUN'), ('cards', 'NOUN'), ('all', 'DET'), ('are', 'AUX'), ('available', 'ADJ'), ('as', 'SCONJ'), ('essential', 'ADJ'), ('items', 'NOUN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rice wheat mask sim card available essential item'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_query('rice, wheat, masks, sim cards all are available as essential items')\n",
    "#filter_query('gun.is crap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text_'] = df2['text']\n",
    "df2['text'] = df2['text'].apply(filter_query)\n",
    "\n",
    "# df['text_'] = df['text']\n",
    "# df['text'] = df['text'].apply(filter_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>two people suffering fever cold want to go family place staying hotel</td>\n",
       "      <td>Two people suffering from fever and cold Want to go back to my family place. Currently staying in the hotel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>need to take father hospital dialysis love selfcare selflove trauma confused depression anxiety reactive abuse</td>\n",
       "      <td>I need to take my father to hospital for dialysis. love  selfcare  selflove  trauma  single4life  confused  depression  anxiety  reactive abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>equipment required hospital patients need mask sanitizers media houses to much liberty harass people lot</td>\n",
       "      <td>Equipment required at hospital. patients need mask and sanitizers Media houses have to much of liberty and they harass people a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>need ambulance need prepared food 20 people slum</td>\n",
       "      <td>Need an ambulance urgently Need prepared food for 20 people in slum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>accident area arm broken need to go hospital sparking electric generator fuel leakage got third degree burn</td>\n",
       "      <td>accident in the area and arm broken need to go to hospital There was sparking in my electric generator due to fuel leakage and I got a third degree burn.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>leave future benefits look present situation benefiting air travellers people stranded different places requesting to resume domestic flights week vodacom network ballons went dead</td>\n",
       "      <td>Leave the future benefits and look at the present situation.Nothing is benefiting air travellers for now.People are stranded in different places and requesting you everyday to resume domestic flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>prepares to resume flights can t travel province to province can e pass to travel prayagraj brother stuck lockdown veryuch trouble request government to help situation</td>\n",
       "      <td>Lufthansa prepares to resume flights to Canada in June .We can't even travel province to province. How can i get the e-pass to travel back from New Delhi to Prayagraj. My Brother's is Stuck in New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>migrant worker stuck trying several times to communicate nodal officer local police failed help can reach local police said bring personal vehicle pass can issue requesting supplies</td>\n",
       "      <td>Mam I'm migrant worker of uttrakhand stuck in WB. I'm trying several times to communicate with nodal officer or local police but failed. Kndly plz help how can i reach you from salanpur WB Local p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>many travelers waiting to homes jobs daily routine man could eating rice breakfast dinner tea</td>\n",
       "      <td>Many travelers are still waiting to get back to their homes jobs and daily routine. Man Could Soon Be Eating Rice For Breakfast Dinner And Tea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4 colleagues stranded lockdown want to travel company needs valid work permit other required documents consider request awaiting response starving require daily meals supply meals</td>\n",
       "      <td>me and my 4 colleagues are stranded in india due to lockdown and want to travel to uganda as our company needs us urgently. We all have valid work permit and other required documents. So please co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label1  label2  \\\n",
       "0          2       4   \n",
       "1          2       3   \n",
       "2          2       3   \n",
       "3          2       1   \n",
       "4          2       2   \n",
       "...      ...     ...   \n",
       "3125       4       0   \n",
       "3126       4       4   \n",
       "3127       4       3   \n",
       "3128       4       1   \n",
       "3129       4       1   \n",
       "\n",
       "                                                                                                                                                                                       text  \\\n",
       "0                                                                                                                     two people suffering fever cold want to go family place staying hotel   \n",
       "1                                                                            need to take father hospital dialysis love selfcare selflove trauma confused depression anxiety reactive abuse   \n",
       "2                                                                                  equipment required hospital patients need mask sanitizers media houses to much liberty harass people lot   \n",
       "3                                                                                                                                          need ambulance need prepared food 20 people slum   \n",
       "4                                                                               accident area arm broken need to go hospital sparking electric generator fuel leakage got third degree burn   \n",
       "...                                                                                                                                                                                     ...   \n",
       "3125   leave future benefits look present situation benefiting air travellers people stranded different places requesting to resume domestic flights week vodacom network ballons went dead   \n",
       "3126                prepares to resume flights can t travel province to province can e pass to travel prayagraj brother stuck lockdown veryuch trouble request government to help situation   \n",
       "3127  migrant worker stuck trying several times to communicate nodal officer local police failed help can reach local police said bring personal vehicle pass can issue requesting supplies   \n",
       "3128                                                                                          many travelers waiting to homes jobs daily routine man could eating rice breakfast dinner tea   \n",
       "3129    4 colleagues stranded lockdown want to travel company needs valid work permit other required documents consider request awaiting response starving require daily meals supply meals   \n",
       "\n",
       "                                                                                                                                                                                                        text_  \n",
       "0                                                                                                Two people suffering from fever and cold Want to go back to my family place. Currently staying in the hotel.  \n",
       "1                                                             I need to take my father to hospital for dialysis. love  selfcare  selflove  trauma  single4life  confused  depression  anxiety  reactive abuse  \n",
       "2                                                                        Equipment required at hospital. patients need mask and sanitizers Media houses have to much of liberty and they harass people a lot.  \n",
       "3                                                                                                                                         Need an ambulance urgently Need prepared food for 20 people in slum  \n",
       "4                                                   accident in the area and arm broken need to go to hospital There was sparking in my electric generator due to fuel leakage and I got a third degree burn.  \n",
       "...                                                                                                                                                                                                       ...  \n",
       "3125  Leave the future benefits and look at the present situation.Nothing is benefiting air travellers for now.People are stranded in different places and requesting you everyday to resume domestic flig...  \n",
       "3126  Lufthansa prepares to resume flights to Canada in June .We can't even travel province to province. How can i get the e-pass to travel back from New Delhi to Prayagraj. My Brother's is Stuck in New...  \n",
       "3127  Mam I'm migrant worker of uttrakhand stuck in WB. I'm trying several times to communicate with nodal officer or local police but failed. Kndly plz help how can i reach you from salanpur WB Local p...  \n",
       "3128                                                          Many travelers are still waiting to get back to their homes jobs and daily routine. Man Could Soon Be Eating Rice For Breakfast Dinner And Tea.  \n",
       "3129  me and my 4 colleagues are stranded in india due to lockdown and want to travel to uganda as our company needs us urgently. We all have valid work permit and other required documents. So please co...  \n",
       "\n",
       "[3130 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2, df2['label2'], test_size=0.2)\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# X_train.reset_index(drop=True)\n",
    "# X_test.reset_index(drop=True)\n",
    "# y_train.reset_index(drop=True)\n",
    "# y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "main=[]\n",
    "for i in range(len(X_train)):\n",
    "    arr=np.array([X_train['label1'][i],X_train['label2'][i]])\n",
    "    main.append(arr)\n",
    "    \n",
    "# main=[]\n",
    "# for i in range(len(X_train)):\n",
    "#     arr=np.array([X_train['label'][i]])\n",
    "#     main.append(arr)\n",
    "    \n",
    "# # Create MultiLabelBinarizer object\n",
    "# one_hot = MultiLabelBinarizer()\n",
    "\n",
    "# One-hot encode data\n",
    "train_text = np.array(X_train, dtype=object)[:,2][:,np.newaxis]\n",
    "# train_label =np.asarray(one_hot.fit_transform(main), dtype = np.int8)\n",
    "\n",
    "train_label = np.zeros((X_train.shape[0], len(trainset.target)))\n",
    "for i in range(X_train.shape[0]):\n",
    "    train_label[i][main[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 0., 0., 1.]),\n",
       " label1                                                                                                                                                                                                          1\n",
       " label2                                                                                                                                                                                                          4\n",
       " text                                                                                        need food hungry 70 workmen stuck project to go homes help nodal officer migrant workers take needful action earliest\n",
       " text_     Need Food Hungry 70 workmen stuck in Tidong HE Project near Recongpeo to go back to their homes in Bihar. No help from any nodal officer for migrant workers yet. Please take needful action at the ...\n",
       " Name: 9, dtype: object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[9], X_train.loc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 4], dtype=int64),\n",
       " array([0., 0., 1., 0., 1.]),\n",
       " array(['hometown wuxicity not dispatched medical workers province hit covid19 donated medical supplies sister sities 16 countries appreciated travel registered nurse supposed to come county to work cancelled hospital starting help stuck'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main[10],train_label[10], train_text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "main=[]\n",
    "for i in range(len(X_test)):\n",
    "    arr=np.array([X_test['label1'][i],X_test['label2'][i]])\n",
    "    main.append(arr)\n",
    "    \n",
    "# main=[]\n",
    "# for i in range(len(X_test)):\n",
    "#     arr=np.array([X_test['label'][i]])\n",
    "#     main.append(arr)\n",
    "    \n",
    "# # Create MultiLabelBinarizer object\n",
    "# one_hot = MultiLabelBinarizer()\n",
    "\n",
    "test_text = np.array(X_test, dtype=object)[:,2][:,np.newaxis]\n",
    "# test_label = np.asarray(one_hot.fit_transform(main), dtype = np.int8)\n",
    "\n",
    "test_label = np.zeros((X_test.shape[0], len(trainset.target)))\n",
    "for i in range(X_test.shape[0]):\n",
    "    test_label[i][main[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = len(np.unique(df.label))\n",
    "module_url = \"../tf_sent_encoder_2\" \n",
    "embed = hub.Module(module_url)\n",
    "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)),signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "# def sentence_encoder(input_text):\n",
    "#     return embed(tf.squeeze(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Local\\Continuum\\anaconda3\\envs\\text_processing\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(UniversalEmbedding,output_shape=(embed_size,))(input_text)\n",
    "dense1 = Dense(1024, activation='relu')(embedding)\n",
    "dense2 = Dense(512, activation='relu')(dense1)\n",
    "dense3 = Dense(128, activation='relu')(dense2)\n",
    "pred = Dense(category_counts, activation='sigmoid')(dense3)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "optimizer = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 2504 samples, validate on 626 samples\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\i509787\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2504/2504 [==============================] - 9s 4ms/step - loss: 0.6071 - acc: 0.6657 - val_loss: 0.4687 - val_acc: 0.7760\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 2/1000\n",
      "2504/2504 [==============================] - 2s 696us/step - loss: 0.3696 - acc: 0.8498 - val_loss: 0.2741 - val_acc: 0.8923\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 3/1000\n",
      "2504/2504 [==============================] - 2s 690us/step - loss: 0.2572 - acc: 0.8982 - val_loss: 0.2513 - val_acc: 0.8994\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 4/1000\n",
      "2504/2504 [==============================] - 1s 571us/step - loss: 0.2223 - acc: 0.9126 - val_loss: 0.2152 - val_acc: 0.9121\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 5/1000\n",
      "2504/2504 [==============================] - 1s 573us/step - loss: 0.2007 - acc: 0.9219 - val_loss: 0.2034 - val_acc: 0.9208\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 6/1000\n",
      "2504/2504 [==============================] - 1s 492us/step - loss: 0.1777 - acc: 0.9326 - val_loss: 0.1947 - val_acc: 0.9265\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 7/1000\n",
      "2504/2504 [==============================] - 1s 495us/step - loss: 0.1608 - acc: 0.9378 - val_loss: 0.1906 - val_acc: 0.9265\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 8/1000\n",
      "2504/2504 [==============================] - 1s 529us/step - loss: 0.1521 - acc: 0.9411 - val_loss: 0.1901 - val_acc: 0.9236\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 9/1000\n",
      "2504/2504 [==============================] - 1s 503us/step - loss: 0.1364 - acc: 0.9480 - val_loss: 0.1723 - val_acc: 0.9323\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 10/1000\n",
      "2504/2504 [==============================] - 1s 528us/step - loss: 0.1250 - acc: 0.9541 - val_loss: 0.1752 - val_acc: 0.9319\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 11/1000\n",
      "2504/2504 [==============================] - 1s 500us/step - loss: 0.1140 - acc: 0.9581 - val_loss: 0.1576 - val_acc: 0.9403\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 12/1000\n",
      "2504/2504 [==============================] - 2s 743us/step - loss: 0.0969 - acc: 0.9653 - val_loss: 0.1596 - val_acc: 0.9367\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 13/1000\n",
      "2504/2504 [==============================] - 2s 653us/step - loss: 0.0869 - acc: 0.9688 - val_loss: 0.1525 - val_acc: 0.9406\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 14/1000\n",
      "2504/2504 [==============================] - 1s 526us/step - loss: 0.0765 - acc: 0.9736 - val_loss: 0.1430 - val_acc: 0.9441\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 15/1000\n",
      "2504/2504 [==============================] - 1s 574us/step - loss: 0.0658 - acc: 0.9774 - val_loss: 0.1429 - val_acc: 0.9460\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 16/1000\n",
      "2504/2504 [==============================] - 1s 508us/step - loss: 0.0599 - acc: 0.9808 - val_loss: 0.1400 - val_acc: 0.9473\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 17/1000\n",
      "2504/2504 [==============================] - 1s 508us/step - loss: 0.0522 - acc: 0.9831 - val_loss: 0.1484 - val_acc: 0.9454\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 18/1000\n",
      "2504/2504 [==============================] - 1s 526us/step - loss: 0.0453 - acc: 0.9870 - val_loss: 0.1425 - val_acc: 0.9466\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 19/1000\n",
      "2504/2504 [==============================] - 1s 572us/step - loss: 0.0408 - acc: 0.9885 - val_loss: 0.1425 - val_acc: 0.9482\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 20/1000\n",
      "2504/2504 [==============================] - 1s 481us/step - loss: 0.0355 - acc: 0.9897 - val_loss: 0.1406 - val_acc: 0.9486\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 21/1000\n",
      "2504/2504 [==============================] - 1s 491us/step - loss: 0.0300 - acc: 0.9925 - val_loss: 0.1343 - val_acc: 0.9527\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 22/1000\n",
      "2504/2504 [==============================] - 1s 522us/step - loss: 0.0243 - acc: 0.9950 - val_loss: 0.1347 - val_acc: 0.9511\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 23/1000\n",
      "2504/2504 [==============================] - 2s 607us/step - loss: 0.0186 - acc: 0.9964 - val_loss: 0.1371 - val_acc: 0.9534\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 24/1000\n",
      "2504/2504 [==============================] - 1s 539us/step - loss: 0.0158 - acc: 0.9981 - val_loss: 0.1384 - val_acc: 0.9514\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 25/1000\n",
      "2504/2504 [==============================] - 1s 557us/step - loss: 0.0138 - acc: 0.9986 - val_loss: 0.1404 - val_acc: 0.9527\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 26/1000\n",
      "2504/2504 [==============================] - 2s 633us/step - loss: 0.0132 - acc: 0.9986 - val_loss: 0.1411 - val_acc: 0.9524\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 27/1000\n",
      "2504/2504 [==============================] - 2s 599us/step - loss: 0.0103 - acc: 0.9988 - val_loss: 0.1492 - val_acc: 0.9518\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 28/1000\n",
      "2504/2504 [==============================] - 1s 529us/step - loss: 0.0099 - acc: 0.9990 - val_loss: 0.1425 - val_acc: 0.9537\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 29/1000\n",
      "2504/2504 [==============================] - 1s 582us/step - loss: 0.0083 - acc: 0.9994 - val_loss: 0.1480 - val_acc: 0.9524\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 30/1000\n",
      "2504/2504 [==============================] - 1s 559us/step - loss: 0.0073 - acc: 0.9994 - val_loss: 0.1513 - val_acc: 0.9527\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 31/1000\n",
      "2504/2504 [==============================] - 1s 539us/step - loss: 0.0063 - acc: 0.9998 - val_loss: 0.1586 - val_acc: 0.9495\n",
      " - lr: 0.0010000000474974513\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 32/1000\n",
      "2504/2504 [==============================] - 1s 543us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 0.1545 - val_acc: 0.9534\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 33/1000\n",
      "2504/2504 [==============================] - 1s 534us/step - loss: 0.0050 - acc: 0.9998 - val_loss: 0.1538 - val_acc: 0.9534\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 34/1000\n",
      "2504/2504 [==============================] - 1s 540us/step - loss: 0.0045 - acc: 0.9998 - val_loss: 0.1528 - val_acc: 0.9556\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 35/1000\n",
      "2504/2504 [==============================] - 1s 509us/step - loss: 0.0042 - acc: 0.9998 - val_loss: 0.1564 - val_acc: 0.9524\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 36/1000\n",
      "2504/2504 [==============================] - 1s 579us/step - loss: 0.0040 - acc: 0.9998 - val_loss: 0.1556 - val_acc: 0.9537\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 37/1000\n",
      "2504/2504 [==============================] - 1s 506us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 0.1557 - val_acc: 0.9540\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 38/1000\n",
      "2504/2504 [==============================] - 1s 540us/step - loss: 0.0036 - acc: 0.9999 - val_loss: 0.1577 - val_acc: 0.9534\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 39/1000\n",
      "2504/2504 [==============================] - 1s 540us/step - loss: 0.0034 - acc: 0.9999 - val_loss: 0.1581 - val_acc: 0.9530\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 40/1000\n",
      "2504/2504 [==============================] - 1s 559us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.1583 - val_acc: 0.9550\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 41/1000\n",
      "2504/2504 [==============================] - 1s 532us/step - loss: 0.0031 - acc: 0.9998 - val_loss: 0.1585 - val_acc: 0.9550\n",
      " - lr: 0.0005000000237487257\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/1000\n",
      "2504/2504 [==============================] - 1s 541us/step - loss: 0.0030 - acc: 0.9998 - val_loss: 0.1602 - val_acc: 0.9546\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 43/1000\n",
      "2504/2504 [==============================] - 1s 537us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1598 - val_acc: 0.9556\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 44/1000\n",
      "2504/2504 [==============================] - 1s 537us/step - loss: 0.0028 - acc: 0.9999 - val_loss: 0.1613 - val_acc: 0.9543\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 45/1000\n",
      "2504/2504 [==============================] - 1s 549us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.1610 - val_acc: 0.9553\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 46/1000\n",
      "2504/2504 [==============================] - 1s 573us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.1606 - val_acc: 0.9543\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 47/1000\n",
      "2504/2504 [==============================] - 1s 552us/step - loss: 0.0026 - acc: 0.9999 - val_loss: 0.1621 - val_acc: 0.9553\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 48/1000\n",
      "2504/2504 [==============================] - 1s 524us/step - loss: 0.0026 - acc: 0.9998 - val_loss: 0.1623 - val_acc: 0.9546\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 49/1000\n",
      "2504/2504 [==============================] - 1s 542us/step - loss: 0.0025 - acc: 0.9998 - val_loss: 0.1627 - val_acc: 0.9543\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 50/1000\n",
      "2504/2504 [==============================] - 1s 512us/step - loss: 0.0024 - acc: 0.9999 - val_loss: 0.1627 - val_acc: 0.9553\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 51/1000\n",
      "2504/2504 [==============================] - 1s 563us/step - loss: 0.0024 - acc: 0.9999 - val_loss: 0.1633 - val_acc: 0.9550\n",
      " - lr: 0.0002500000118743628\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 52/1000\n",
      "2504/2504 [==============================] - 1s 542us/step - loss: 0.0023 - acc: 0.9999 - val_loss: 0.1635 - val_acc: 0.9550\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 53/1000\n",
      "2504/2504 [==============================] - 1s 510us/step - loss: 0.0023 - acc: 0.9999 - val_loss: 0.1635 - val_acc: 0.9553\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 54/1000\n",
      "2504/2504 [==============================] - 1s 535us/step - loss: 0.0023 - acc: 0.9998 - val_loss: 0.1640 - val_acc: 0.9553\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 55/1000\n",
      "2504/2504 [==============================] - 1s 561us/step - loss: 0.0022 - acc: 0.9998 - val_loss: 0.1640 - val_acc: 0.9550\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 56/1000\n",
      "2504/2504 [==============================] - 1s 533us/step - loss: 0.0022 - acc: 0.9999 - val_loss: 0.1641 - val_acc: 0.9550\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 57/1000\n",
      "2504/2504 [==============================] - 1s 518us/step - loss: 0.0022 - acc: 0.9998 - val_loss: 0.1648 - val_acc: 0.9553\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 58/1000\n",
      "2504/2504 [==============================] - 1s 556us/step - loss: 0.0022 - acc: 0.9999 - val_loss: 0.1645 - val_acc: 0.9556\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 59/1000\n",
      "2504/2504 [==============================] - 1s 561us/step - loss: 0.0021 - acc: 0.9999 - val_loss: 0.1652 - val_acc: 0.9550\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 60/1000\n",
      "2504/2504 [==============================] - 1s 564us/step - loss: 0.0021 - acc: 0.9999 - val_loss: 0.1650 - val_acc: 0.9550\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 61/1000\n",
      "2504/2504 [==============================] - 1s 551us/step - loss: 0.0021 - acc: 0.9999 - val_loss: 0.1653 - val_acc: 0.9553\n",
      " - lr: 0.0001250000059371814\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 62/1000\n",
      "2504/2504 [==============================] - 1s 591us/step - loss: 0.0021 - acc: 0.9999 - val_loss: 0.1657 - val_acc: 0.9550\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 63/1000\n",
      "2504/2504 [==============================] - 1s 537us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.1657 - val_acc: 0.9553\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 64/1000\n",
      "2504/2504 [==============================] - 1s 504us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.1657 - val_acc: 0.9550\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 65/1000\n",
      "2504/2504 [==============================] - 1s 524us/step - loss: 0.0020 - acc: 0.9998 - val_loss: 0.1659 - val_acc: 0.9550\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 66/1000\n",
      "2504/2504 [==============================] - 1s 533us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.1658 - val_acc: 0.9550\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 67/1000\n",
      "2504/2504 [==============================] - 1s 536us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.1660 - val_acc: 0.9550\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 68/1000\n",
      "2504/2504 [==============================] - 1s 567us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.1663 - val_acc: 0.9546\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 69/1000\n",
      "2504/2504 [==============================] - 1s 596us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.1663 - val_acc: 0.9550\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 70/1000\n",
      "2504/2504 [==============================] - 2s 619us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.1665 - val_acc: 0.9543\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 71/1000\n",
      "2504/2504 [==============================] - 1s 562us/step - loss: 0.0020 - acc: 0.9998 - val_loss: 0.1664 - val_acc: 0.9550\n",
      " - lr: 6.25000029685907e-05\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 00071: early stopping\n"
     ]
    }
   ],
   "source": [
    "# session.run(tf.global_variables_initializer())\n",
    "# session.run(tf.tables_initializer())\n",
    "\n",
    "# history = model.fit(train_text, \n",
    "#         train_label,\n",
    "#         validation_data=(test_text, test_label),epochs=100,batch_size=256)\n",
    "# model.save_weights('./model4.h5')\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "class LearningRateTracker(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\" - lr: {}\".format(K.eval(self.model.optimizer.lr))) \n",
    "# session.run(tf.global_variables_initializer())\n",
    "# session.run(tf.tables_initializer())\n",
    "\n",
    "LR_PATIENCE = 10\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=LR_PATIENCE, min_lr=1e-8, verbose=1, mode=\"min\")\n",
    "es_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "lr_tracker = LearningRateTracker()\n",
    "\n",
    "history = model.fit(train_text, \n",
    "          train_label,\n",
    "          validation_data=(test_text, test_label),\n",
    "          epochs=1000,\n",
    "          batch_size=256,\n",
    "          callbacks=[es_callback, lr_tracker, reduce_lr])\n",
    "model.save_weights('./model5.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model5.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "queries_list = []\n",
    "with open('COVID-TEXT.csv', 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        queries_list.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Labourers without food',\n",
       " 'Migrant Workers from UP and BIHAR',\n",
       " 'People need cooked food',\n",
       " 'people stuck in bangalore',\n",
       " 'People Stuck without Food',\n",
       " 'People without ration',\n",
       " 'Residence of rama swamy palya facing water scarcity',\n",
       " 'Stranded migrants from various states',\n",
       " '5o Migrant workers from West Bengal',\n",
       " 'Alemari samudaya with food and ration',\n",
       " 'Elder people need urgent ration',\n",
       " 'Familiy without ration',\n",
       " '10 members need Ration , Daily Wage workers',\n",
       " '10 people Need information on how to go back to bihar ',\n",
       " '10 person from Bihar are struck in Dharwad. They need Ration , Kindly deliver, they have no money and food to survive .\\nThanks',\n",
       " '14 Workers need ration',\n",
       " '150 people Wants to go home from mangalore to Giridih Jarkhand',\n",
       " '17 families are not having ration card not received any ration from anywhere. They need to be helped for the basic food and sanitaries',\n",
       " '25 people who are living in Venkateshwar Nagar, (Vaddargalli) not ration card and not benefiting from PDS. These people need to be helped provision kit',\n",
       " '3 members Need ration and GAS ',\n",
       " '3 Migrants labourers from Bihar need ration \\n',\n",
       " '300 family in poor people please help them',\n",
       " '300 Migrants labourers from Bihar need ration ',\n",
       " '310 families need families',\n",
       " '32 family need ration, daily wage workers',\n",
       " '6 members need ration (garment workers)',\n",
       " '6 members need ration wage workers\\nDaily wage workers\\n ',\n",
       " 'Enquiry about travelling from Bangalore to Dakshina kannada.\\n ',\n",
       " 'Glycomety GP - 1 ( 2 strips)\\nDolowin Plus (2 strips)',\n",
       " \"I've got request for ration to be delivered for 70-75 labour class people in OPH road, shivaginagar. \\nThese people are from different states (UP, Bihar, Assam) \\nEssentials were provided to them by their owners and now itâ€™s become hard for the owners also to provide further. \\nRequesting you to revert at the earliest.\",\n",
       " 'karmikarige 112 resan kit',\n",
       " 'Lakshmi Yadav and 7 migrant workers need ration urgently.',\n",
       " 'Need information on how to go back to bihar ',\n",
       " 'Need ration for 12 dialy wage workers',\n",
       " 'Need ration for 13 migrant laborers from Kolkata.',\n",
       " 'Need ration for 3 members Daily wage workers\\nRecieved through phone by Manohar\\n',\n",
       " 'Need ration for 5 members ,person working in garments ',\n",
       " 'Need Ration for 6 members Daily wage workers ',\n",
       " 'Need to go to Agra ',\n",
       " 'Need to travel from Bangalore to Bihar \\n ',\n",
       " 'Panchanan and 9 migrant workers need ration and gas immediately.',\n",
       " 'Phagu Ram Mahato and 2 migrants need dry ration immediately',\n",
       " 'Pradip and 8 workers need dry ration and gas refill immediately. They are painters from North Indian states.',\n",
       " 'Prakash and 4 migrant workers need ration urgently.',\n",
       " 'Ranjith and fifty workers from North Indian states need dry ration urgently. \\n',\n",
       " 'Ration kits for slum',\n",
       " 'Request for ration kits and packed food for underprivileged families in and around JC nagar. \\nWe have been active in this area and have been providing both ration and packed food to the needy and are running out of resources and funds to meet the list of people here. \\n\\nPlease get in touch with us and help us deliver essential food and ration for the needy here. \\nThank you',\n",
       " 'Request for ration kits to be provided in agalkote village, after magadi town. \\n36 families all from labour class are expecting aid.\\nTransport will be provided by our volunteers if necessary. Please reach out to them at the earliest.',\n",
       " 'Request Ration Kits for Daily Wage and Migrant labourers near Kannur Village Quarry, Near Nelamanagal, Sagarhalli and Mariampet-Muthakapalli Panchayat, in Srinivaspur, Kolar',\n",
       " 'Required ration for poor and needy for 30 plus families',\n",
       " 'Santosh Kumar and 4 migrants need ration urgently.',\n",
       " \"Sir/Madam,My name is Lakshminarayana BN,I am requesting fr ration supply behalf of distress lady named sharadamma,aged 80yrs,she is almost blind,She's helpless,As of now I am taking care of her,Hence I request u to kindly help her by providing ration supplies,Thanking you,yours faithfully,,,\",\n",
       " 'Sonaram Munda and 5 migrants need ration and gas refilling immediately',\n",
       " 'Stuck in Bangalore. From WEst Bengal. No jobs. Shop owner left them without paying. Need ration, gas and house rent. Want to return back to West Bengal.',\n",
       " 'Sukhram Kumar and 15 migrant workers need ration urgently.',\n",
       " 'There are 17 families without the Ration Card and they are not able to access the Ration shop for the basic necessities. they need to be helped for food and sanitary ietems',\n",
       " 'There are 45 families at the slum near Aland Naka, Kalaburagi. These people are requesting for the basic necessities.',\n",
       " 'They are in need of ration and gas. \\nThe secondary contact name: Pravat Bardhan contact number is 7991098775',\n",
       " 'They are in need of Ration and Gas. There are 5 peoples in group. The secondary contact person is Santosh Sethy, contact number : 7992993324.',\n",
       " 'They are in need of Ration and Gas. They are 5 members living together in one room.\\nThe secondary contact person name :Pravat Bardhan and the contact no: 7991098775',\n",
       " 'They are in need of Ration. There are 16 peoples in group. The secondary contact person is Baskar Mahato, contact number : 6362301525',\n",
       " 'They are in need of Ration. There are 20 peoples.\\nThe secondary contact person name: Pankaj Kumar, contact no: 9611001767.',\n",
       " 'They are in need of Ration. There are 5 peoples in group. The secondary contact person is Ranjeet Kumar Sharma, contact no. 6203404995.',\n",
       " 'They are in need of Ration. There are 7 peoples in group.',\n",
       " 'Thirteen families are not having ration card and they are struggling for food.',\n",
       " 'We are around 5 migrant workers stranded in Kolar, we require help Iâ€™m going back to Tripura. We did not have groceries this till yesterday. We received relief today (2 May 2020) from localities. Kindly let us know how we can use the transport facility provided by the Government to go back home.',\n",
       " 'We have helping to alemari people and beggers senior citizens families issued vegetables fruits and water bottle needfully issued and then future help to single oldage families forest hills poorest people s',\n",
       " 'Women in need of medical assistance',\n",
       " 'Tribals from Tamil Nadu wants to travel back',\n",
       " 'To Provide Ration for people',\n",
       " 'Stranded migrants from various states',\n",
       " 'Stranded labourers without food or ration',\n",
       " 'Residence of rama swamy palya facing water scarcity',\n",
       " \"Require pass to travel from bangalore to Tirchy due to father's death\",\n",
       " 'people without food and need assistance to travel',\n",
       " 'people stuck in bangalore',\n",
       " 'People need cooked food',\n",
       " 'People in need of medical assistance',\n",
       " 'Patient in request of urgent medicine',\n",
       " 'Need pass to travel from Assam to Karnataka due to daughters health condition',\n",
       " 'need food for 50 people',\n",
       " 'need dry ration',\n",
       " 'Migrant Family from Jharkhand need help',\n",
       " 'Migrant construction workers request for travel',\n",
       " 'Labourers without food who travelled to Chitradurga',\n",
       " 'Labourers (Jharkhand ) who worked for Gopalan group . Have not been paid since lockdown.',\n",
       " 'Familoes pressurized for rent',\n",
       " '8 adults 2 child stuck without food',\n",
       " '73 families surveyed by a volunteer - most dont have ration card.',\n",
       " '10 person from Bihar are struck in Dharwad. They need Ration , Kindly deliver, they have no money and food to survive .',\n",
       " '17 families are not having ration card not received any ration from anywhere. They need to be helped for the basic food and sanitaries',\n",
       " '25 people who are living in Venkateshwar Nagar, (Vaddargalli) not ration card and not benefiting from PDS. These people need to be helped provision kit',\n",
       " 'Request for ration kits to be provided in agalkote village, after magadi town. \\n36 families all from labour class are expecting aid.\\nTransport will be provided by our volunteers if necessary. Please reach out to them at the earliest.',\n",
       " 'Request Ration Kits for Daily Wage and Migrant labourers near Kannur Village Quarry, Near Nelamanagal, Sagarhalli and Mariampet-Muthakapalli Panchayat, in Srinivaspur, Kolar',\n",
       " 'Required ration for poor and needy for 30 plus families',\n",
       " 'Settled population needing help with ration, money',\n",
       " 'There are 17 families without the Ration Card and they are not able to access the Ration shop for the basic necessities. they need to be helped for food and sanitary ietems',\n",
       " 'There are 45 families at the slum near Aland Naka, Kalaburagi. These people are requesting for the basic necessities.',\n",
       " 'Thirteen families are not having ration card and they are struggling for food.',\n",
       " 'food need for construction workers from Raichur',\n",
       " 'Stranded migrants from various states',\n",
       " 'There is a request for ration for above address. Since it is a Red zone, we are not able to reach.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(query_list):\n",
    "    filt_query = [filter_query(q) for q in query_list]\n",
    "    print (filt_query)\n",
    "    # filt_query = query_list\n",
    "    query_arr = np.array(filt_query, dtype=object)[:, np.newaxis]\n",
    "    predicts = model.predict(query_arr)\n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labourers food', 'migrant workers bihar', 'people need cooked food', 'people stuck', 'people stuck food', 'people ration', 'facing water scarcity', 'stranded migrants various states', '5o migrant workers', 'food ration', 'elder people need urgent ration', 'familiy ration', '10 members need ration daily wage workers', '10 people need information to go', '10 person struck need ration deliver money food to survive thanks', '14 workers need ration', '150 people wants to go mangalore to', '17 families not having ration card not received ration need to helped basic food sanitaries', '25 people living not ration card not benefiting people need to helped provision kit', '3 members need ration gas', '3 migrants labourers need ration', '300 family poor people help', '300 migrants labourers need ration', '310 families need families', '32 family need ration daily wage workers', '6 members need ration garment workers', '6 members need ration wage workers daily wage workers', 'enquiry travelling', '1 2 2 strips', 'got request ration to delivered 70 75 labour class people shivaginagar people different states essentials provided owners become hard owners to provide requesting to revert earliest', '112 kit', '7 migrant workers need ration', 'need information to go', 'need ration 12 dialy wage workers', 'need ration 13 migrant laborers', 'need ration 3 members daily wage workers recieved phone manohar', 'need ration 5 members person working garments', 'need ration 6 members daily wage workers', 'need to go agra', 'need to travel', '9 migrant workers need ration gas', '2 migrants need dry ration', '8 workers need dry ration gas refill painters indian states', '4 migrant workers need ration', 'ranjith fifty workers indian states need dry ration', 'ration kits slum', 'request ration kits packed food underprivileged families active area providing ration packed food needy running resources funds to meet list people touch help deliver essential food ration needy thank', 'request ration kits to provided village town 36 families labour class expecting aid transport will provided volunteers necessary reach earliest', 'ration kits daily wage migrant labourers', 'required ration poor needy 30 families', '4 migrants need ration', 'name requesting ration supply behalf distress lady named aged 80yrs blind s helpless taking care request to help providing ration supplies thanking', '5 migrants need ration gas refilling', 'stuck jobs shop owner left paying need ration gas house rent want to return', '15 migrant workers need ration', '17 families ration card not able to access ration shop basic necessities need to helped food sanitary ietems', '45 families slum people requesting basic necessities', 'need ration gas secondary contact name pravat contact number 7991098775', 'need ration gas 5 peoples group secondary contact person sethy contact number 7992993324', 'need ration gas 5 members living one room secondary contact person name pravat contact 7991098775', 'need ration 16 peoples group secondary contact person contact number 6362301525', 'need ration 20 peoples secondary contact person name 9611001767', 'need ration 5 peoples group secondary contact person 6203404995', 'need ration 7 peoples group', 'thirteen families not having ration card struggling food', '5 migrant workers stranded kolar require help going tripura not groceries yesterday received relief today 2 may 2020 localities let know can use transport facility provided government to go', 'helping to alemari people beggers senior citizens families issued vegetables fruits water bottle issued future help single oldage families forest hills poorest people', 'women need medical assistance', 'tribals wants to travel', 'to provide ration people', 'stranded migrants various states', 'stranded labourers food ration', 'facing water scarcity', 'require pass to travel to tirchy s death', 'people food need assistance to travel', 'people stuck', 'people need cooked food', 'people need medical assistance', 'patient request urgent medicine', 'need pass to travel due daughters health condition', 'need food 50 people', 'need dry ration', 'migrant family need help', 'migrant construction workers request travel', 'labourers food travelled', 'worked not paid lockdown', 'familoes pressurized rent', '8 adults 2 child stuck food', '73 families surveyed volunteer most nt ration card', '10 person struck need ration deliver money food to survive', '17 families not having ration card not received ration need to helped basic food sanitaries', '25 people living not ration card not benefiting people need to helped provision kit', 'request ration kits to provided village town 36 families labour class expecting aid transport will provided volunteers necessary reach earliest', 'ration kits daily wage migrant labourers', 'required ration poor needy 30 families', 'settled population needing help ration money', '17 families ration card not able to access ration shop basic necessities need to helped food sanitary ietems', '45 families slum people requesting basic necessities', 'thirteen families not having ration card struggling food', 'food need construction workers', 'stranded migrants various states', 'request ration above address red zone not able to reach']\n",
      "QUERY 0-> No network connectivity in my area for ordering groceries. Need ration urgently\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tfood:100.0\n",
      "\thealthcare:0.3\n",
      "\tothers:35.9\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 1-> Need gas cylinder as my mobile broke down.\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tfood:7.5\n",
      "\thealthcare:95.5\n",
      "\tothers:7.5\n",
      "\ttravel:98.1\n",
      "\n",
      "\n",
      "QUERY 2-> My father is sick. i want daily ration\n",
      "\n",
      "\n",
      "\tcommunication:7.5\n",
      "\tfood:98.9\n",
      "\thealthcare:9.1\n",
      "\tothers:98.1\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 3-> Yesterday i saw few people bullying a person from my locality. I think he needs help.i need cab as my car broke down to go to hospital.\n",
      "\n",
      "\n",
      "\tcommunication:99.5\n",
      "\tfood:0.1\n",
      "\thealthcare:0.0\n",
      "\tothers:100.0\n",
      "\ttravel:0.1\n",
      "\n",
      "\n",
      "QUERY 4-> I am unable to find fruits and vegetables\n",
      "\n",
      "\n",
      "\tcommunication:57.2\n",
      "\tfood:91.3\n",
      "\thealthcare:3.1\n",
      "\tothers:99.7\n",
      "\ttravel:0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"No network connectivity in my area for ordering groceries. Need ration urgently\",\n",
    "\"Need gas cylinder as my mobile broke down.\",\n",
    "\"My father is sick. i want daily ration\",\n",
    "\"Yesterday i saw few people bullying a person from my locality. I think he needs help.i need cab as my car broke down to go to hospital.\",\n",
    "'I am unable to find fruits and vegetables']\n",
    "\n",
    "\n",
    "# new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "# #new_text = np.array(queries_list, dtype=object)[:, np.newaxis]\n",
    "\n",
    "# predicts = model.predict(new_text)\n",
    "predicts = run_prediction(queries_list)\n",
    "\n",
    "dictt=trainset.target_names\n",
    "\n",
    "for j in range(len(new_text)):\n",
    "    print(\"QUERY \"+str(j) +'-> ' + new_text[j])\n",
    "    print('\\n')\n",
    "    for i in range(len(dictt)):\n",
    "        print('\\t'+dictt[i]+\":\"+str(np.around(predicts*100,decimals=1)[j][i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame([[queries_list[i]] + list(np.around(predicts*100,decimals=1)[i]) for i in range(len(queries_list))], columns=['query'] + dictt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>communication</th>\n",
       "      <th>food</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>others</th>\n",
       "      <th>travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Labourers without food</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Migrant Workers from UP and BIHAR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>95.5</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>98.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People need cooked food</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>98.900002</td>\n",
       "      <td>9.1</td>\n",
       "      <td>98.099998</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people stuck in bangalore</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People Stuck without Food</td>\n",
       "      <td>57.200001</td>\n",
       "      <td>91.300003</td>\n",
       "      <td>3.1</td>\n",
       "      <td>99.699997</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               query  communication        food  healthcare  \\\n",
       "0             Labourers without food       0.000000  100.000000         0.3   \n",
       "1  Migrant Workers from UP and BIHAR       0.000000    7.500000        95.5   \n",
       "2            People need cooked food       7.500000   98.900002         9.1   \n",
       "3          people stuck in bangalore      99.500000    0.100000         0.0   \n",
       "4          People Stuck without Food      57.200001   91.300003         3.1   \n",
       "\n",
       "       others     travel  \n",
       "0   35.900002   0.000000  \n",
       "1    7.500000  98.099998  \n",
       "2   98.099998   0.000000  \n",
       "3  100.000000   0.100000  \n",
       "4   99.699997   0.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plea sunkadkatte rations request urgent help receive food not children would prefer ration', 'dalit village 150 families not receiving support received 10 kg rice wheat family start lockdown can help', 'request help 10 people two children tribals working coffee pepper plantation 3 spoke say 150 such labourers belt paid contractor money not given ration met tasildar yesterday going can not happen help state decision migrant workers moving place origin thank', 'working carpenters helpers builder contractors r providing groceries other food requirements workers enquiry wkrs told problem food sir', '250 fishermen struck didn access food last few days depression says help', 'dear friends 08 members mangalore near kannanuru check post critical situation present requesting food other help organizations working mangalore border request pls attend cae help construction migrant workers contact 6282662916 hope one will reach provide ration', 'contact details group 50 migrant workers stuck market only intermittent access food say large group unable to food distribution points food runs request to help', 'small village outskirts not good cell reception isolated news availability supplies', 'three construction workers hungry last two days jumped building provide ambulance', 'friend fell terrace searching network network problem area government mistake medical expenses should bourne', 'daily ration kit distributed not cooking oil supposed to cook', 'trying to start small kitchen to feed hungry poor kids locality unable to haven received big 19 kg gas cannister applied 20 days', 'doctor car brokedown want to repaired']\n",
      "QUERY 0-> We have a plea from Sunkadkatte for rations. Request your urgent help .They receive food sometimes but not regularly. They have children and would prefer ration.\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tfood:98.8\n",
      "\thealthcare:22.5\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 1-> There is a Dalit village with 150 families in Kanakapura district who are not receiving any support. They received 10 kg rice and some wheat per family at the start of the lockdown.Anyone can help ?\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tfood:61.2\n",
      "\thealthcare:0.2\n",
      "\tothers:20.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 2-> Dear Ma'am Suchitra here again with another request for help. About 10 people and two children, tribals from Javadhi hills, Tamil Nadu working in coffee n pepper plantation in Chikmagalur. 3 of them spoke to me. They say over 150+ such labourers are there in this belt. They were paid by the contractor in March n have no money now. They have not been given any ration either. They met the Tasildar yesterday about going back. But that cannot happen now.  Ma'am how do we help them out? What is the state decision on migrant workers moving back to place of origin? Thank you.\n",
      "\n",
      "\n",
      "\tcommunication:0.1\n",
      "\tfood:82.2\n",
      "\thealthcare:1.3\n",
      "\tothers:0.1\n",
      "\ttravel:9.0\n",
      "\n",
      "\n",
      "QUERY 3-> Sir these wkrs r working as carpenters, helpers at Arabhikothanur Kolar,the builder and contractors r providing groceries and other food requirements to these workers.on enquiry the wkrs told there is no problem with resp to food sir\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tfood:55.6\n",
      "\thealthcare:1.5\n",
      "\tothers:5.6\n",
      "\ttravel:0.1\n",
      "\n",
      "\n",
      "QUERY 4-> 250 Fishermen From Andhra Pradesh struck in Udupi, Karnataka.They didn't have access to food from last few days. They are in depression.And at last he says, agar Kuch ni mila toh zehar kha lenge isse aacha .Please help.\n",
      "\n",
      "\n",
      "\tcommunication:0.1\n",
      "\tfood:39.1\n",
      "\thealthcare:37.3\n",
      "\tothers:0.8\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 5-> Dear friends,  08 members from Uttar Pradesh are  in Mangalore near Kannanuru check post, they are in critical situation present they Requesting food and other help, any organizations working in Mangalore and border of Kerala request you pls attend this cae and help them, all are construction migrant workers,  their contact No: 6282662916, I hope some one will reach them. Please provide ration for all of us.\n",
      "\n",
      "\n",
      "\tcommunication:1.0\n",
      "\tfood:58.7\n",
      "\thealthcare:0.3\n",
      "\tothers:0.0\n",
      "\ttravel:5.1\n",
      "\n",
      "\n",
      "QUERY 6-> These are the contact details of a group of 50 plus migrant workers stuck in KR market with only intermittent access to food. They say they are a large group and all of them are unable to get food even at distribution points as food runs out. Request you to help\n",
      "\n",
      "\n",
      "\tcommunication:9.0\n",
      "\tfood:90.7\n",
      "\thealthcare:0.6\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 7-> We are a small village on the outskirts of Bangalore and we do not have good cell reception here and hence we are isolated here with no news about coronavirus or availability of supplies.\n",
      "\n",
      "\n",
      "\tcommunication:74.8\n",
      "\tfood:33.7\n",
      "\thealthcare:0.3\n",
      "\tothers:0.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 8-> Three construction workers from jharkhand are hungry from last two days and jumped off the building. Please provide ambulance\n",
      "\n",
      "\n",
      "\tcommunication:0.2\n",
      "\tfood:23.7\n",
      "\thealthcare:23.8\n",
      "\tothers:0.2\n",
      "\ttravel:1.1\n",
      "\n",
      "\n",
      "QUERY 9-> my friend fell from terrace while searching for network. There is network problem in this area. This is all government mistake and the medical expenses should be bourne by them.\n",
      "\n",
      "\n",
      "\tcommunication:96.8\n",
      "\tfood:0.0\n",
      "\thealthcare:0.7\n",
      "\tothers:0.0\n",
      "\ttravel:1.9\n",
      "\n",
      "\n",
      "QUERY 10-> The daily ration kit distributed to us do not have cooking oil in them. How are we supposed to cook.\n",
      "\n",
      "\n",
      "\tcommunication:0.0\n",
      "\tfood:43.8\n",
      "\thealthcare:1.0\n",
      "\tothers:76.6\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 11-> I am trying to start a small kitchen to feed the hungry poor kids in my locality but I am unable to do so as I haven't received the big 19 kg gas cannister which I applied for almost 20 days ago.\n",
      "\n",
      "\n",
      "\tcommunication:0.1\n",
      "\tfood:96.7\n",
      "\thealthcare:0.4\n",
      "\tothers:2.1\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 12-> I am a doctor, my car brokedown and want it to get repaired urgently.\n",
      "\n",
      "\n",
      "\tcommunication:0.1\n",
      "\tfood:0.0\n",
      "\thealthcare:92.8\n",
      "\tothers:7.3\n",
      "\ttravel:1.7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"We have a plea from Sunkadkatte for rations. Request your urgent help .They receive food sometimes but not regularly. They have children and would prefer ration.\",\n",
    "\"There is a Dalit village with 150 families in Kanakapura district who are not receiving any support. They received 10 kg rice and some wheat per family at the start of the lockdown.Anyone can help ?\",\n",
    "\"Dear Ma'am Suchitra here again with another request for help. About 10 people and two children, tribals from Javadhi hills, Tamil Nadu working in coffee n pepper plantation in Chikmagalur. 3 of them spoke to me. They say over 150+ such labourers are there in this belt. They were paid by the contractor in March n have no money now. They have not been given any ration either. They met the Tasildar yesterday about going back. But that cannot happen now.  Ma'am how do we help them out? What is the state decision on migrant workers moving back to place of origin? Thank you.\",\n",
    "\"Sir these wkrs r working as carpenters, helpers at Arabhikothanur Kolar,the builder and contractors r providing groceries and other food requirements to these workers.on enquiry the wkrs told there is no problem with resp to food sir\",\n",
    "\"250 Fishermen From Andhra Pradesh struck in Udupi, Karnataka.They didn't have access to food from last few days. They are in depression.And at last he says, \"\"agar Kuch ni mila toh zehar kha lenge isse aacha .Please help.\",\n",
    "\"Dear friends,  08 members from Uttar Pradesh are  in Mangalore near Kannanuru check post, they are in critical situation present they Requesting food and other help, any organizations working in Mangalore and border of Kerala request you pls attend this cae and help them, all are construction migrant workers,  their contact No: 6282662916, I hope some one will reach them. Please provide ration for all of us.\",\n",
    "\"These are the contact details of a group of 50 plus migrant workers stuck in KR market with only intermittent access to food. They say they are a large group and all of them are unable to get food even at distribution points as food runs out. Request you to help\",\n",
    "'We are a small village on the outskirts of Bangalore and we do not have good cell reception here and hence we are isolated here with no news about coronavirus or availability of supplies.',\n",
    "'Three construction workers from jharkhand are hungry from last two days and jumped off the building. Please provide ambulance',\n",
    "'my friend fell from terrace while searching for network. There is network problem in this area. This is all government mistake and the medical expenses should be bourne by them.',\n",
    "'The daily ration kit distributed to us do not have cooking oil in them. How are we supposed to cook.',\n",
    "\"I am trying to start a small kitchen to feed the hungry poor kids in my locality but I am unable to do so as I haven't received the big 19 kg gas cannister which I applied for almost 20 days ago.\",\n",
    "'I am a doctor, my car brokedown and want it to get repaired urgently.']\n",
    "# new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "\n",
    "# predicts = model.predict(new_text)\n",
    "\n",
    "\n",
    "# categories = np.unique(df.label)\n",
    "# predict_logits = predicts.argmax(axis=1)\n",
    "# predict_labels = [categories[logit] for logit in predict_logits]\n",
    "predicts = run_prediction(new_text)\n",
    "\n",
    "dictt=trainset.target_names\n",
    "# ANS=[dict[s] for s in predict_labels]\n",
    "\n",
    "for j in range(len(new_text)):\n",
    "    print(\"QUERY \"+str(j) +'-> ' + new_text[j])\n",
    "    print('\\n')\n",
    "    for i in range(len(dictt)):\n",
    "        print('\\t'+dictt[i]+\":\"+str(np.around(predicts*100,decimals=1)[j][i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As my young daughter is still a toddler, I need some cereals or Cerelac and milk urgently, as she is almost always crying due to hunger.', 'Even though the local auhtorities have arranged for raw vegetables for us to have, please provide us with oil and spices to cook them, which we have been asking for so long.', 'I have been coughing for several days now, but recently I am also feeling a blockage on my throat, weaknesss and fever. ', \"My wife is a construction worker and since we don't have enough meals now due to shortage of money, she is weak and unable to get up\", 'I came to Bangalore to work and have been stuck here for so long due to the lockdown, I need to get to my elderly parents who are in a small town in Maharashtra which is declared a red zone. ', 'My son went to Delhi to prepare for competitive exams and now he is stuck there with some friends as their institution has closed down and he is unable to return.', 'My neighbor, Mr. Rao is a salesman who is frustrated due to no income and he fights with his wife, shouts horribly and breaks things almost everyday', 'An elderly man in our locality was tested positive for coronavirus long back, has recovered and since then everybody is hateful of the entire family and even the shopkeepers harass them by refusing to sell items to them. ', 'We are a small village on the outskirts of Bangalore and we do not have good cell reception here and hence we are isolated here with no news about coronavirus or availability of supplies.', 'There has been transformer fault in our area and none of our devices are working and all our phones are discharged and we are not able to contact anyone to request for repair for many days now. ', 'We have been eating raw vegetables and fruits for the last 3 days as we do not have cooking gas in our cylinder and no one has delivered our new cylinder which we have requested a long time back.', \"I am trying to start a small kitchen to feed the hungry poor kids in my locality but I am unable to do so as I haven't received the big 19 kg gas cannister which I applied for almost 20 days ago. \"]\n",
      "['young daughter toddler need cereal milk cry hunger', 'local auhtoritie arrange raw vegetable to provide oil spice to cook ask', 'cough several day feel blockage throat weaknesss fever', 'wife construction worker not enough meal due shortage money weak unable to', 'come to work stick due lockdown need to elderly parent small town declare red zone', 'son go to prepare competitive exam stick friend institution close unable to return', 'neighbor salesman frustrate income fight wife shout break thing', 'elderly man locality test positive recover hateful entire family shopkeeper harass refuse to sell item', 'small village outskirt not good cell reception isolate news availability supply', 'transform fault area none device work phone discharge not able to contact to request repair many day', 'eat raw vegetable fruit last 3 day not cooking gas cylinder one deliver new cylinder request long time', 'try to start small kitchen to feed hungry poor kid locality unable to not receive big 19 kg gas cannister apply 20 day']\n",
      "QUERY 0-> As my young daughter is still a toddler, I need some cereals or Cerelac and milk urgently, as she is almost always crying due to hunger.\n",
      "\n",
      "\n",
      "\tabuse:30.5\n",
      "\tcommunication:0.0\n",
      "\tfood:100.0\n",
      "\tfuel:7.8\n",
      "\thealth:0.1\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 1-> Even though the local auhtorities have arranged for raw vegetables for us to have, please provide us with oil and spices to cook them, which we have been asking for so long.\n",
      "\n",
      "\n",
      "\tabuse:1.4\n",
      "\tcommunication:0.4\n",
      "\tfood:100.0\n",
      "\tfuel:0.0\n",
      "\thealth:6.4\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 2-> I have been coughing for several days now, but recently I am also feeling a blockage on my throat, weaknesss and fever. \n",
      "\n",
      "\n",
      "\tabuse:0.3\n",
      "\tcommunication:0.7\n",
      "\tfood:0.0\n",
      "\tfuel:5.9\n",
      "\thealth:100.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 3-> My wife is a construction worker and since we don't have enough meals now due to shortage of money, she is weak and unable to get up\n",
      "\n",
      "\n",
      "\tabuse:5.8\n",
      "\tcommunication:0.5\n",
      "\tfood:26.1\n",
      "\tfuel:0.0\n",
      "\thealth:100.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 4-> I came to Bangalore to work and have been stuck here for so long due to the lockdown, I need to get to my elderly parents who are in a small town in Maharashtra which is declared a red zone. \n",
      "\n",
      "\n",
      "\tabuse:0.1\n",
      "\tcommunication:1.4\n",
      "\tfood:0.0\n",
      "\tfuel:1.7\n",
      "\thealth:0.0\n",
      "\ttravel:100.0\n",
      "\n",
      "\n",
      "QUERY 5-> My son went to Delhi to prepare for competitive exams and now he is stuck there with some friends as their institution has closed down and he is unable to return.\n",
      "\n",
      "\n",
      "\tabuse:4.4\n",
      "\tcommunication:3.6\n",
      "\tfood:0.0\n",
      "\tfuel:0.0\n",
      "\thealth:17.9\n",
      "\ttravel:100.0\n",
      "\n",
      "\n",
      "QUERY 6-> My neighbor, Mr. Rao is a salesman who is frustrated due to no income and he fights with his wife, shouts horribly and breaks things almost everyday\n",
      "\n",
      "\n",
      "\tabuse:100.0\n",
      "\tcommunication:0.3\n",
      "\tfood:0.1\n",
      "\tfuel:0.0\n",
      "\thealth:0.0\n",
      "\ttravel:0.1\n",
      "\n",
      "\n",
      "QUERY 7-> An elderly man in our locality was tested positive for coronavirus long back, has recovered and since then everybody is hateful of the entire family and even the shopkeepers harass them by refusing to sell items to them. \n",
      "\n",
      "\n",
      "\tabuse:100.0\n",
      "\tcommunication:0.0\n",
      "\tfood:7.9\n",
      "\tfuel:0.0\n",
      "\thealth:2.7\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 8-> We are a small village on the outskirts of Bangalore and we do not have good cell reception here and hence we are isolated here with no news about coronavirus or availability of supplies.\n",
      "\n",
      "\n",
      "\tabuse:0.0\n",
      "\tcommunication:100.0\n",
      "\tfood:40.0\n",
      "\tfuel:0.0\n",
      "\thealth:0.2\n",
      "\ttravel:0.1\n",
      "\n",
      "\n",
      "QUERY 9-> There has been transformer fault in our area and none of our devices are working and all our phones are discharged and we are not able to contact anyone to request for repair for many days now. \n",
      "\n",
      "\n",
      "\tabuse:0.3\n",
      "\tcommunication:100.0\n",
      "\tfood:0.1\n",
      "\tfuel:0.1\n",
      "\thealth:9.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 10-> We have been eating raw vegetables and fruits for the last 3 days as we do not have cooking gas in our cylinder and no one has delivered our new cylinder which we have requested a long time back.\n",
      "\n",
      "\n",
      "\tabuse:0.0\n",
      "\tcommunication:0.6\n",
      "\tfood:1.9\n",
      "\tfuel:100.0\n",
      "\thealth:40.6\n",
      "\ttravel:0.0\n",
      "\n",
      "\n",
      "QUERY 11-> I am trying to start a small kitchen to feed the hungry poor kids in my locality but I am unable to do so as I haven't received the big 19 kg gas cannister which I applied for almost 20 days ago. \n",
      "\n",
      "\n",
      "\tabuse:1.0\n",
      "\tcommunication:0.0\n",
      "\tfood:57.3\n",
      "\tfuel:92.2\n",
      "\thealth:49.0\n",
      "\ttravel:0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_text = ['I am unable to find fruits or vegetables',\n",
    "'Where can I get bread',\n",
    "'Edible supplies are not available in my area, i need bread and groceries',\n",
    "'We are 6 people in my family and we are out of food. Anything you can give, please do',\n",
    "'My inhaler isnt working and I need a new one asap, but i am unable to find it anywhere',\n",
    "'I am running out of my insulin injections. I need to stock up',\n",
    "'Me and my parents are stuck alone in our house with severe health issues. My father has heart problems and my mother is bedridden. I need urgent medical assistance',\n",
    "'All electricity is down in my society due to which all electronic devices are off.Phone, wifi laptop all shut',\n",
    "'I crashed in the divider on the way to medical and now bike wont start. Need help urgently.',\n",
    "'Me and family stranded on roadside on the way to mysore. Car is not working',\n",
    "'I hit the brakes very hard and now my car is shut down. Need help to get home',\n",
    "'Need gas for car so that I can reach home.',\n",
    "'Cooking oil is over and it is not available in any store',\n",
    "'3 people have crashed in my neighbors house for some money matter. Need urgent assistance']\n",
    "text = \\\n",
    "'''As my young daughter is still a toddler, I need some cereals or Cerelac and milk urgently, as she is almost always crying due to hunger.\n",
    "Even though the local auhtorities have arranged for raw vegetables for us to have, please provide us with oil and spices to cook them, which we have been asking for so long.\n",
    "I have been coughing for several days now, but recently I am also feeling a blockage on my throat, weaknesss and fever. \n",
    "My wife is a construction worker and since we don't have enough meals now due to shortage of money, she is weak and unable to get up\n",
    "I came to Bangalore to work and have been stuck here for so long due to the lockdown, I need to get to my elderly parents who are in a small town in Maharashtra which is declared a red zone. \n",
    "My son went to Delhi to prepare for competitive exams and now he is stuck there with some friends as their institution has closed down and he is unable to return.\n",
    "My neighbor, Mr. Rao is a salesman who is frustrated due to no income and he fights with his wife, shouts horribly and breaks things almost everyday\n",
    "An elderly man in our locality was tested positive for coronavirus long back, has recovered and since then everybody is hateful of the entire family and even the shopkeepers harass them by refusing to sell items to them. \n",
    "We are a small village on the outskirts of Bangalore and we do not have good cell reception here and hence we are isolated here with no news about coronavirus or availability of supplies.\n",
    "There has been transformer fault in our area and none of our devices are working and all our phones are discharged and we are not able to contact anyone to request for repair for many days now. \n",
    "We have been eating raw vegetables and fruits for the last 3 days as we do not have cooking gas in our cylinder and no one has delivered our new cylinder which we have requested a long time back.\n",
    "I am trying to start a small kitchen to feed the hungry poor kids in my locality but I am unable to do so as I haven't received the big 19 kg gas cannister which I applied for almost 20 days ago. '''\n",
    "new_text = text.split('\\n')\n",
    "print (new_text)\n",
    "\n",
    "predicts = run_prediction(new_text)\n",
    "\n",
    "dictt=['abuse','communication','food','fuel','health','travel']\n",
    "# ANS=[dict[s] for s in predict_labels]\n",
    "\n",
    "for j in range(len(new_text)):\n",
    "    print(\"QUERY \"+str(j) +'-> ' + new_text[j])\n",
    "    print('\\n')\n",
    "    for i in range(len(dictt)):\n",
    "        print('\\t'+dictt[i]+\":\"+str(np.around(predicts*100,decimals=1)[j][i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"We have a plea from Sunkadkatte for rations. Request your urgent help .They receive food sometimes but not regularly. They have children and would prefer ration.\",\n",
    "\"There is a Dalit village with 150 families in Kanakapura district who are not receiving any support. They received 10 kg rice and some wheat per family at the start of the lockdown.Anyone can help ?\",\n",
    "\"Dear Ma'am Suchitra here again with another request for help. About 10 people and two children, tribals from Javadhi hills, Tamil Nadu working in coffee n pepper plantation in Chikmagalur. 3 of them spoke to me. They say over 150+ such labourers are there in this belt. They were paid by the contractor in March n have no money now. They have not been given any ration either. They met the Tasildar yesterday about going back. But that cannot happen now.  Ma'am how do we help them out? What is the state decision on migrant workers moving back to place of origin? Thank you.\",\n",
    "\"Sir these wkrs r working as carpenters, helpers at Arabhikothanur Kolar,the builder and contractors r providing groceries and other food requirements to these workers.on enquiry the wkrs told there is no problem with resp to food sir\",\n",
    "\"250 Fishermen From Andhra Pradesh struck in Udupi, Karnataka.They didn't have access to food from last few days. They are in depression.And at last he says, \"\"agar Kuch ni mila toh zehar kha lenge isse aacha .Please help.\",\n",
    "\"Dear friends,  08 members from Uttar Pradesh are  in Mangalore near Kannanuru check post, they are in critical situation present they Requesting food and other help, any organizations working in Mangalore and border of Kerala request you pls attend this cae and help them, all are construction migrant workers,  their contact No: 6282662916, I hope some one will reach them.\",\n",
    "\"These are the contact details of a group of 50 plus migrant workers stuck in KR market with only intermittent access to food. They say they are a large group and all of them are unable to get food even at distribution points as food runs out. Request you to help\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts.shape\n",
    "preds_round = np.around(predicts*100,decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 92.9000015258789, 0.5, 0.0, 0.0, 0.0]\n",
      "[100.0, 6.800000190734863, 5.5, 0.20000000298023224, 0.0, 0.0]\n",
      "[99.9000015258789, 83.80000305175781, 56.900001525878906, 0.0, 0.0, 0.0]\n",
      "[94.80000305175781, 93.80000305175781, 35.099998474121094, 2.200000047683716, 0.8999999761581421, 0.0]\n",
      "[100.0, 70.9000015258789, 0.5, 0.0, 0.0, 0.0]\n",
      "[100.0, 71.9000015258789, 0.0, 0.0, 0.0, 0.0]\n",
      "[97.80000305175781, 41.79999923706055, 20.0, 10.0, 0.0, 0.0]\n",
      "[100.0, 99.9000015258789, 3.200000047683716, 0.30000001192092896, 0.10000000149011612, 0.0]\n",
      "[100.0, 4.199999809265137, 2.4000000953674316, 0.6000000238418579, 0.20000000298023224, 0.0]\n",
      "[100.0, 100.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 51.099998474121094, 2.299999952316284, 0.0, 0.0, 0.0]\n",
      "[100.0, 27.5, 0.20000000298023224, 0.0, 0.0, 0.0]\n",
      "[100.0, 2.200000047683716, 0.4000000059604645, 0.4000000059604645, 0.20000000298023224, 0.0]\n",
      "[99.9000015258789, 6.5, 3.4000000953674316, 0.5, 0.20000000298023224, 0.10000000149011612]\n",
      "[99.80000305175781, 99.4000015258789, 0.4000000059604645, 0.4000000059604645, 0.0, 0.0]\n",
      "[100.0, 1.0, 0.8999999761581421, 0.8999999761581421, 0.0, 0.0]\n",
      "[98.9000015258789, 80.0, 19.100000381469727, 9.699999809265137, 0.10000000149011612, 0.0]\n",
      "[100.0, 94.80000305175781, 0.0, 0.0, 0.0, 0.0]\n",
      "[99.0999984741211, 87.69999694824219, 85.0, 0.20000000298023224, 0.0, 0.0]\n",
      "[100.0, 23.799999237060547, 3.4000000953674316, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 72.4000015258789, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[100.0, 5.599999904632568, 0.5, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 5.300000190734863, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[100.0, 4.0, 2.4000000953674316, 0.30000001192092896, 0.0, 0.0]\n",
      "[100.0, 0.4000000059604645, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[99.80000305175781, 99.0, 0.800000011920929, 0.4000000059604645, 0.10000000149011612, 0.0]\n",
      "[100.0, 5.300000190734863, 0.699999988079071, 0.4000000059604645, 0.0, 0.0]\n",
      "[100.0, 40.400001525878906, 12.100000381469727, 0.10000000149011612, 0.0, 0.0]\n",
      "[99.4000015258789, 69.30000305175781, 65.0999984741211, 4.0, 0.10000000149011612, 0.0]\n",
      "[100.0, 80.9000015258789, 79.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 38.29999923706055, 15.899999618530273, 0.6000000238418579, 0.0, 0.0]\n",
      "[100.0, 13.199999809265137, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0]\n",
      "[98.80000305175781, 28.899999618530273, 14.0, 6.300000190734863, 0.10000000149011612, 0.0]\n",
      "[100.0, 2.299999952316284, 0.20000000298023224, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 46.400001525878906, 6.099999904632568, 0.0, 0.0, 0.0]\n",
      "[100.0, 11.5, 0.699999988079071, 0.20000000298023224, 0.10000000149011612, 0.0]\n",
      "[99.80000305175781, 99.4000015258789, 0.8999999761581421, 0.20000000298023224, 0.10000000149011612, 0.0]\n",
      "[100.0, 5.400000095367432, 0.20000000298023224, 0.0, 0.0, 0.0]\n",
      "[100.0, 31.100000381469727, 8.800000190734863, 7.900000095367432, 0.0, 0.0]\n",
      "[100.0, 50.70000076293945, 10.199999809265137, 1.100000023841858, 0.0, 0.0]\n",
      "[100.0, 24.5, 1.2999999523162842, 0.20000000298023224, 0.20000000298023224, 0.0]\n",
      "[100.0, 1.399999976158142, 1.2000000476837158, 0.0, 0.0, 0.0]\n",
      "[99.9000015258789, 99.9000015258789, 6.199999809265137, 0.4000000059604645, 0.0, 0.0]\n",
      "[100.0, 12.800000190734863, 0.8999999761581421, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 83.69999694824219, 3.799999952316284, 0.20000000298023224, 0.0, 0.0]\n",
      "[99.9000015258789, 98.5999984741211, 77.80000305175781, 0.0, 0.0, 0.0]\n",
      "[99.80000305175781, 84.19999694824219, 74.69999694824219, 11.600000381469727, 0.10000000149011612, 0.0]\n",
      "[61.099998474121094, 16.100000381469727, 6.199999809265137, 5.400000095367432, 1.0, 0.0]\n",
      "[99.0, 95.69999694824219, 72.5, 0.0, 0.0, 0.0]\n",
      "[100.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 2.700000047683716, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[91.4000015258789, 43.70000076293945, 13.0, 10.899999618530273, 0.30000001192092896, 0.0]\n",
      "[100.0, 99.19999694824219, 1.100000023841858, 0.0, 0.0, 0.0]\n",
      "[100.0, 1.100000023841858, 0.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 3.200000047683716, 0.800000011920929, 0.0, 0.0, 0.0]\n",
      "[100.0, 100.0, 0.20000000298023224, 0.0, 0.0, 0.0]\n",
      "[100.0, 75.5, 5.300000190734863, 3.5, 0.0, 0.0]\n",
      "[96.19999694824219, 95.5999984741211, 93.80000305175781, 0.10000000149011612, 0.0, 0.0]\n",
      "[99.9000015258789, 89.9000015258789, 33.599998474121094, 2.299999952316284, 0.0, 0.0]\n",
      "[98.0, 91.5999984741211, 6.800000190734863, 2.0, 0.10000000149011612, 0.0]\n",
      "[97.80000305175781, 83.80000305175781, 46.0, 1.2000000476837158, 0.10000000149011612, 0.0]\n",
      "[51.0, 45.599998474121094, 11.699999809265137, 7.099999904632568, 0.30000001192092896, 0.10000000149011612]\n",
      "[95.5, 73.30000305175781, 13.300000190734863, 1.2000000476837158, 0.5, 0.0]\n",
      "[100.0, 39.5, 6.199999809265137, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 5.699999809265137, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[100.0, 69.80000305175781, 38.29999923706055, 0.0, 0.0, 0.0]\n",
      "[100.0, 25.600000381469727, 5.0, 0.6000000238418579, 0.0, 0.0]\n",
      "[100.0, 2.5, 0.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 79.4000015258789, 14.199999809265137, 0.6000000238418579, 0.6000000238418579, 0.0]\n",
      "[100.0, 0.8999999761581421, 0.6000000238418579, 0.0, 0.0, 0.0]\n",
      "[100.0, 99.9000015258789, 3.200000047683716, 0.30000001192092896, 0.10000000149011612, 0.0]\n",
      "[100.0, 25.600000381469727, 0.20000000298023224, 0.10000000149011612, 0.0, 0.0]\n",
      "[97.80000305175781, 41.79999923706055, 20.0, 10.0, 0.0, 0.0]\n",
      "[100.0, 4.599999904632568, 2.5, 2.200000047683716, 0.0, 0.0]\n",
      "[100.0, 92.5999984741211, 1.0, 0.10000000149011612, 0.0, 0.0]\n",
      "[94.80000305175781, 93.80000305175781, 35.099998474121094, 2.200000047683716, 0.8999999761581421, 0.0]\n",
      "[99.9000015258789, 83.80000305175781, 56.900001525878906, 0.0, 0.0, 0.0]\n",
      "[100.0, 1.100000023841858, 0.699999988079071, 0.0, 0.0, 0.0]\n",
      "[100.0, 66.5, 1.100000023841858, 0.10000000149011612, 0.0, 0.0]\n",
      "[100.0, 48.70000076293945, 43.099998474121094, 0.0, 0.0, 0.0]\n",
      "[100.0, 11.899999618530273, 0.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 93.4000015258789, 55.099998474121094, 0.0, 0.0, 0.0]\n",
      "[100.0, 50.29999923706055, 1.5, 0.20000000298023224, 0.10000000149011612, 0.0]\n",
      "[100.0, 83.80000305175781, 24.299999237060547, 2.700000047683716, 0.10000000149011612, 0.0]\n",
      "[100.0, 15.800000190734863, 1.600000023841858, 1.0, 0.0, 0.0]\n",
      "[69.80000305175781, 63.5, 16.200000762939453, 7.0, 0.30000001192092896, 0.0]\n",
      "[87.9000015258789, 39.099998474121094, 21.0, 2.9000000953674316, 0.800000011920929, 0.0]\n",
      "[99.80000305175781, 99.0999984741211, 4.099999904632568, 3.0999999046325684, 0.0, 0.0]\n",
      "[100.0, 6.900000095367432, 0.5, 0.10000000149011612, 0.0, 0.0]\n",
      "[99.69999694824219, 97.4000015258789, 1.2999999523162842, 0.20000000298023224, 0.0, 0.0]\n",
      "[100.0, 94.80000305175781, 0.0, 0.0, 0.0, 0.0]\n",
      "[99.0999984741211, 87.69999694824219, 85.0, 0.20000000298023224, 0.0, 0.0]\n",
      "[61.099998474121094, 16.100000381469727, 6.199999809265137, 5.400000095367432, 1.0, 0.0]\n",
      "[99.0, 95.69999694824219, 72.5, 0.0, 0.0, 0.0]\n",
      "[100.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0]\n",
      "[100.0, 20.799999237060547, 0.4000000059604645, 0.0, 0.0, 0.0]\n",
      "[100.0, 100.0, 0.20000000298023224, 0.0, 0.0, 0.0]\n",
      "[100.0, 75.5, 5.300000190734863, 3.5, 0.0, 0.0]\n",
      "[100.0, 5.699999809265137, 0.10000000149011612, 0.0, 0.0, 0.0]\n",
      "[100.0, 97.69999694824219, 6.800000190734863, 0.20000000298023224, 0.0, 0.0]\n",
      "[100.0, 99.9000015258789, 3.200000047683716, 0.30000001192092896, 0.10000000149011612, 0.0]\n",
      "[99.19999694824219, 71.4000015258789, 17.5, 0.5, 0.10000000149011612, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from statistics import stdev\n",
    "pred_results = []\n",
    "for i in range(predicts.shape[0]):\n",
    "    sorted_class_similariy = [float(x) for x in sorted(preds_round[i], reverse=True)]\n",
    "    print (sorted_class_similariy)\n",
    "    split_stdev = []\n",
    "    split_stdev.append(stdev(sorted_class_similariy[1:len(dictt)]))\n",
    "    for k in range(2, len(dictt) - 1):\n",
    "        split_stdev.append((stdev(sorted_class_similariy[:k]) + stdev(sorted_class_similariy[k:]))/2)\n",
    "    split_stdev.append(stdev(sorted_class_similariy[:len(dictt) - 1]))\n",
    "\n",
    "    split_ind = np.argmin(split_stdev)\n",
    "    thres = (sorted_class_similariy[split_ind] + sorted_class_similariy[split_ind + 1]) / 2\n",
    "    # print (thres)\n",
    "    pred_labels = [c for c in range(len(dictt)) if preds_round[i][c] >= np.around(thres, decimals=1)]\n",
    "    pred_classes = [dictt[r] for r in pred_labels]\n",
    "    # print (pred_labels)\n",
    "    pred_results.append(pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['food', 'health'],\n",
       " ['food'],\n",
       " ['food', 'fuel', 'health'],\n",
       " ['communication', 'travel'],\n",
       " ['food', 'health'],\n",
       " ['food', 'health'],\n",
       " ['travel'],\n",
       " ['food', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'health'],\n",
       " ['abuse', 'food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food'],\n",
       " ['communication', 'food'],\n",
       " ['food', 'travel'],\n",
       " ['food', 'health', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'health'],\n",
       " ['food'],\n",
       " ['travel'],\n",
       " ['food', 'health', 'travel'],\n",
       " ['food', 'fuel', 'travel'],\n",
       " ['health'],\n",
       " ['food'],\n",
       " ['travel'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'health'],\n",
       " ['food'],\n",
       " ['travel'],\n",
       " ['communication', 'travel'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food', 'fuel', 'health'],\n",
       " ['food', 'fuel', 'travel'],\n",
       " ['fuel'],\n",
       " ['food', 'fuel', 'travel'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['abuse'],\n",
       " ['food', 'fuel'],\n",
       " ['travel'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['abuse', 'food'],\n",
       " ['abuse', 'fuel', 'health'],\n",
       " ['abuse', 'fuel'],\n",
       " ['abuse', 'fuel'],\n",
       " ['abuse', 'food', 'health'],\n",
       " ['fuel', 'health'],\n",
       " ['abuse', 'food'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'fuel', 'travel'],\n",
       " ['food'],\n",
       " ['health'],\n",
       " ['abuse', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food'],\n",
       " ['travel'],\n",
       " ['travel'],\n",
       " ['food', 'health'],\n",
       " ['communication', 'travel'],\n",
       " ['food', 'fuel', 'health'],\n",
       " ['health'],\n",
       " ['fuel', 'health'],\n",
       " ['food', 'health', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'fuel', 'health'],\n",
       " ['abuse', 'food'],\n",
       " ['health', 'travel'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['health'],\n",
       " ['food', 'health'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['food', 'travel'],\n",
       " ['food', 'health', 'travel'],\n",
       " ['fuel'],\n",
       " ['food', 'fuel', 'travel'],\n",
       " ['food'],\n",
       " ['food'],\n",
       " ['food', 'travel'],\n",
       " ['abuse', 'food'],\n",
       " ['food'],\n",
       " ['food', 'health'],\n",
       " ['food', 'travel'],\n",
       " ['communication', 'travel']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OK### both tanh -84% split=0.3    split=o.2 good\n",
    "## both relu - 86% split=0.2\n",
    "## both tanh - 85.4% split=0.2\n",
    "## tanh relu 84.73\n",
    "### relu tanh 85.63 -----good 256,128\n",
    "### relu tanh  86.12-----ok ok 1024,256\n",
    "### relu tanh  86.12-----ok ok 1024,256\n",
    "## tanh tanh ---1024 128 \n",
    "## relu tanh tanh 256 128 64- 85.8%\n",
    "## tanh tanh 0.3 split acc= 84.55 can try\n",
    "\n",
    "\n",
    "OK###with categorical cross entropy tanh tanh 256 128 results are ok but accuracy showing is less\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 93.82%\n",
    "# dense1 = Dense(256, activation='relu')(embedding)\n",
    "# dense2 = Dense(128, activation='relu')(dense1)\n",
    "# pred = Dense(category_counts, activation='sigmoid')(dense2)\n",
    "# model = Model(inputs=[input_text], outputs=pred)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 94.41%\n",
    "# dense1 = Dense(1024, activation='relu')(embedding)\n",
    "# dense2 = Dense(256, activation='relu')(dense1)\n",
    "# pred = Dense(category_counts, activation='sigmoid')(dense2)\n",
    "# model = Model(inputs=[input_text], outputs=pred)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "## __94.78____%\n",
    "# dense1 = Dense(1024, activation='relu')(embedding)\n",
    "# dense2 = Dense(128, activation='relu')(dense1)\n",
    "# pred = Dense(category_counts, activation='sigmoid')(dense2)\n",
    "# model = Model(inputs=[input_text], outputs=pred)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "####### 94.48 % #########\n",
    "\n",
    "# input_text = Input(shape=(1,), dtype=tf.string)\n",
    "# embedding = Lambda(UniversalEmbedding,output_shape=(embed_size,))(input_text)\n",
    "# dense1 = Dense(1024, activation='relu')(embedding)\n",
    "# dense2 = Dense(128, activation='tanh')(dense1)\n",
    "# pred = Dense(category_counts, activation='sigmoid')(dense2)\n",
    "# model = Model(inputs=[input_text], outputs=pred)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['communication', 'food', 'healthcare', 'others', 'travel']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = trainset.target_names\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Concatenate\n",
    "\n",
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)),signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "# def sentence_encoder(input_text):\n",
    "#     return embed(tf.squeeze(input_text))\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(UniversalEmbedding,output_shape=(embed_size,))(input_text)\n",
    "dense1 = Dense(1024, activation='relu')(embedding)\n",
    "dense2 = Dense(128, activation='relu')(dense1)\n",
    "pred = []\n",
    "for c in categories:\n",
    "    pred.append(Dense(1, activation='sigmoid')(dense2))\n",
    "out = Concatenate()(pred)\n",
    "model = Model(inputs=[input_text], outputs=out)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "optimizer = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 512)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1024)         525312      lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          131200      dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            129         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            129         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            129         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            129         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            129         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5)            0           dense_17[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "                                                                 dense_19[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "                                                                 dense_21[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 657,157\n",
      "Trainable params: 657,157\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2504 samples, validate on 626 samples\n",
      "Epoch 1/1000\n",
      "2504/2504 [==============================] - 26s 10ms/step - loss: 0.6200 - acc: 0.6868 - val_loss: 0.5276 - val_acc: 0.7329\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 2/1000\n",
      "2504/2504 [==============================] - 2s 659us/step - loss: 0.4316 - acc: 0.8216 - val_loss: 0.3591 - val_acc: 0.8677\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 3/1000\n",
      "2504/2504 [==============================] - 2s 750us/step - loss: 0.3007 - acc: 0.8831 - val_loss: 0.2829 - val_acc: 0.8856\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 4/1000\n",
      "2504/2504 [==============================] - 2s 624us/step - loss: 0.2456 - acc: 0.9020 - val_loss: 0.2569 - val_acc: 0.8949\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 5/1000\n",
      "2504/2504 [==============================] - 1s 586us/step - loss: 0.2222 - acc: 0.9093 - val_loss: 0.2485 - val_acc: 0.8952\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 6/1000\n",
      "2504/2504 [==============================] - 2s 642us/step - loss: 0.2065 - acc: 0.9172 - val_loss: 0.2312 - val_acc: 0.9080\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 7/1000\n",
      "2504/2504 [==============================] - 2s 617us/step - loss: 0.1896 - acc: 0.9244 - val_loss: 0.2211 - val_acc: 0.9115\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 8/1000\n",
      "2504/2504 [==============================] - 2s 658us/step - loss: 0.1792 - acc: 0.9295 - val_loss: 0.2146 - val_acc: 0.9131\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 9/1000\n",
      "2504/2504 [==============================] - 2s 619us/step - loss: 0.1710 - acc: 0.9331 - val_loss: 0.2135 - val_acc: 0.9144\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 10/1000\n",
      "2504/2504 [==============================] - 1s 557us/step - loss: 0.1631 - acc: 0.9372 - val_loss: 0.2075 - val_acc: 0.9185\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 11/1000\n",
      "2504/2504 [==============================] - 1s 586us/step - loss: 0.1558 - acc: 0.9413 - val_loss: 0.2081 - val_acc: 0.9150\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 12/1000\n",
      "2504/2504 [==============================] - 1s 598us/step - loss: 0.1498 - acc: 0.9438 - val_loss: 0.2003 - val_acc: 0.9188\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 13/1000\n",
      "2504/2504 [==============================] - 2s 640us/step - loss: 0.1423 - acc: 0.9475 - val_loss: 0.1964 - val_acc: 0.9214\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 14/1000\n",
      "2504/2504 [==============================] - 2s 678us/step - loss: 0.1365 - acc: 0.9482 - val_loss: 0.1874 - val_acc: 0.9265\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 15/1000\n",
      "2504/2504 [==============================] - 2s 669us/step - loss: 0.1302 - acc: 0.9511 - val_loss: 0.1843 - val_acc: 0.9246\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 16/1000\n",
      "2504/2504 [==============================] - 2s 683us/step - loss: 0.1245 - acc: 0.9533 - val_loss: 0.1868 - val_acc: 0.9230\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 17/1000\n",
      "2504/2504 [==============================] - 2s 657us/step - loss: 0.1171 - acc: 0.9577 - val_loss: 0.1818 - val_acc: 0.9288\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 18/1000\n",
      "2504/2504 [==============================] - 2s 702us/step - loss: 0.1116 - acc: 0.9593 - val_loss: 0.1725 - val_acc: 0.9310\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 19/1000\n",
      "2504/2504 [==============================] - 2s 621us/step - loss: 0.1046 - acc: 0.9624 - val_loss: 0.1684 - val_acc: 0.9348\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 20/1000\n",
      "2504/2504 [==============================] - 2s 614us/step - loss: 0.1001 - acc: 0.9649 - val_loss: 0.1665 - val_acc: 0.9329\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 21/1000\n",
      "2504/2504 [==============================] - 2s 640us/step - loss: 0.0948 - acc: 0.9671 - val_loss: 0.1671 - val_acc: 0.9348\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 22/1000\n",
      "2504/2504 [==============================] - 2s 606us/step - loss: 0.0900 - acc: 0.9683 - val_loss: 0.1659 - val_acc: 0.9361\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 23/1000\n",
      "2504/2504 [==============================] - 2s 615us/step - loss: 0.0846 - acc: 0.9718 - val_loss: 0.1611 - val_acc: 0.9383\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 24/1000\n",
      "2504/2504 [==============================] - 1s 591us/step - loss: 0.0801 - acc: 0.9738 - val_loss: 0.1589 - val_acc: 0.9380\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 25/1000\n",
      "2504/2504 [==============================] - 1s 595us/step - loss: 0.0769 - acc: 0.9756 - val_loss: 0.1669 - val_acc: 0.9335\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 26/1000\n",
      "2504/2504 [==============================] - 1s 581us/step - loss: 0.0728 - acc: 0.9762 - val_loss: 0.1562 - val_acc: 0.9387\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 27/1000\n",
      "2504/2504 [==============================] - 2s 648us/step - loss: 0.0690 - acc: 0.9788 - val_loss: 0.1506 - val_acc: 0.9435\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 28/1000\n",
      "2504/2504 [==============================] - 2s 668us/step - loss: 0.0644 - acc: 0.9789 - val_loss: 0.1507 - val_acc: 0.9441\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 29/1000\n",
      "2504/2504 [==============================] - 2s 606us/step - loss: 0.0623 - acc: 0.9812 - val_loss: 0.1447 - val_acc: 0.9419\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 30/1000\n",
      "2504/2504 [==============================] - 2s 616us/step - loss: 0.0571 - acc: 0.9835 - val_loss: 0.1480 - val_acc: 0.9415\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 31/1000\n",
      "2504/2504 [==============================] - 2s 617us/step - loss: 0.0536 - acc: 0.9848 - val_loss: 0.1505 - val_acc: 0.9399\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 32/1000\n",
      "2504/2504 [==============================] - 2s 624us/step - loss: 0.0516 - acc: 0.9858 - val_loss: 0.1456 - val_acc: 0.9447\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 33/1000\n",
      "2504/2504 [==============================] - 2s 616us/step - loss: 0.0480 - acc: 0.9879 - val_loss: 0.1411 - val_acc: 0.9460\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 34/1000\n",
      "2504/2504 [==============================] - 2s 622us/step - loss: 0.0448 - acc: 0.9887 - val_loss: 0.1413 - val_acc: 0.9435\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 35/1000\n",
      "2504/2504 [==============================] - 2s 665us/step - loss: 0.0428 - acc: 0.9890 - val_loss: 0.1395 - val_acc: 0.9470\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 36/1000\n",
      "2504/2504 [==============================] - 2s 660us/step - loss: 0.0402 - acc: 0.9909 - val_loss: 0.1418 - val_acc: 0.9505\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 37/1000\n",
      "2504/2504 [==============================] - 2s 629us/step - loss: 0.0380 - acc: 0.9918 - val_loss: 0.1423 - val_acc: 0.9457\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 38/1000\n",
      "2504/2504 [==============================] - 2s 637us/step - loss: 0.0366 - acc: 0.9911 - val_loss: 0.1394 - val_acc: 0.9466\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 39/1000\n",
      "2504/2504 [==============================] - 2s 609us/step - loss: 0.0342 - acc: 0.9927 - val_loss: 0.1403 - val_acc: 0.9502\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 40/1000\n",
      "2504/2504 [==============================] - 1s 582us/step - loss: 0.0322 - acc: 0.9932 - val_loss: 0.1410 - val_acc: 0.9489\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 41/1000\n",
      "2504/2504 [==============================] - 2s 646us/step - loss: 0.0311 - acc: 0.9935 - val_loss: 0.1437 - val_acc: 0.9447\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 42/1000\n",
      "2504/2504 [==============================] - 2s 639us/step - loss: 0.0300 - acc: 0.9935 - val_loss: 0.1386 - val_acc: 0.9486\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 43/1000\n",
      "2504/2504 [==============================] - 1s 595us/step - loss: 0.0282 - acc: 0.9952 - val_loss: 0.1393 - val_acc: 0.9470\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 44/1000\n",
      "2504/2504 [==============================] - 2s 619us/step - loss: 0.0263 - acc: 0.9950 - val_loss: 0.1390 - val_acc: 0.9521\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 45/1000\n",
      "2504/2504 [==============================] - 1s 585us/step - loss: 0.0247 - acc: 0.9962 - val_loss: 0.1389 - val_acc: 0.9511\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 46/1000\n",
      "2504/2504 [==============================] - 2s 604us/step - loss: 0.0232 - acc: 0.9963 - val_loss: 0.1399 - val_acc: 0.9511\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 47/1000\n",
      "2504/2504 [==============================] - 1s 589us/step - loss: 0.0214 - acc: 0.9968 - val_loss: 0.1395 - val_acc: 0.9473\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 48/1000\n",
      "2504/2504 [==============================] - 2s 630us/step - loss: 0.0205 - acc: 0.9970 - val_loss: 0.1402 - val_acc: 0.9498\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 49/1000\n",
      "2504/2504 [==============================] - 1s 586us/step - loss: 0.0190 - acc: 0.9977 - val_loss: 0.1416 - val_acc: 0.9508\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 50/1000\n",
      "2504/2504 [==============================] - 1s 597us/step - loss: 0.0180 - acc: 0.9977 - val_loss: 0.1420 - val_acc: 0.9511\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 51/1000\n",
      "2504/2504 [==============================] - 2s 608us/step - loss: 0.0171 - acc: 0.9979 - val_loss: 0.1425 - val_acc: 0.9508\n",
      " - lr: 0.0010000000474974513\n",
      "Epoch 52/1000\n",
      "2504/2504 [==============================] - 2s 603us/step - loss: 0.0164 - acc: 0.9982 - val_loss: 0.1418 - val_acc: 0.9518\n",
      " - lr: 0.0010000000474974513\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 53/1000\n",
      "2504/2504 [==============================] - 2s 666us/step - loss: 0.0149 - acc: 0.9987 - val_loss: 0.1433 - val_acc: 0.9537\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 54/1000\n",
      "2504/2504 [==============================] - 2s 687us/step - loss: 0.0145 - acc: 0.9986 - val_loss: 0.1414 - val_acc: 0.9502\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 55/1000\n",
      "2504/2504 [==============================] - 2s 655us/step - loss: 0.0142 - acc: 0.9987 - val_loss: 0.1444 - val_acc: 0.9530\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 56/1000\n",
      "2504/2504 [==============================] - 1s 551us/step - loss: 0.0137 - acc: 0.9989 - val_loss: 0.1414 - val_acc: 0.9524\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 57/1000\n",
      "2504/2504 [==============================] - 1s 578us/step - loss: 0.0136 - acc: 0.9987 - val_loss: 0.1432 - val_acc: 0.9505\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 58/1000\n",
      "2504/2504 [==============================] - 2s 640us/step - loss: 0.0131 - acc: 0.9988 - val_loss: 0.1427 - val_acc: 0.9540\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 59/1000\n",
      "2504/2504 [==============================] - 2s 658us/step - loss: 0.0127 - acc: 0.9987 - val_loss: 0.1436 - val_acc: 0.9537\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 60/1000\n",
      "2504/2504 [==============================] - 2s 651us/step - loss: 0.0127 - acc: 0.9989 - val_loss: 0.1442 - val_acc: 0.9524\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 61/1000\n",
      "2504/2504 [==============================] - 2s 647us/step - loss: 0.0125 - acc: 0.9990 - val_loss: 0.1450 - val_acc: 0.9524\n",
      " - lr: 0.0005000000237487257\n",
      "Epoch 62/1000\n",
      "2504/2504 [==============================] - 1s 573us/step - loss: 0.0120 - acc: 0.9992 - val_loss: 0.1452 - val_acc: 0.9524\n",
      " - lr: 0.0005000000237487257\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 63/1000\n",
      "2504/2504 [==============================] - 2s 605us/step - loss: 0.0117 - acc: 0.9991 - val_loss: 0.1443 - val_acc: 0.9524\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 64/1000\n",
      "2504/2504 [==============================] - 1s 594us/step - loss: 0.0112 - acc: 0.9992 - val_loss: 0.1457 - val_acc: 0.9524\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 65/1000\n",
      "2504/2504 [==============================] - 2s 636us/step - loss: 0.0110 - acc: 0.9991 - val_loss: 0.1442 - val_acc: 0.9534\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 66/1000\n",
      "2504/2504 [==============================] - 2s 663us/step - loss: 0.0109 - acc: 0.9990 - val_loss: 0.1456 - val_acc: 0.9524\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 67/1000\n",
      "2504/2504 [==============================] - 2s 694us/step - loss: 0.0108 - acc: 0.9993 - val_loss: 0.1449 - val_acc: 0.9534\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 68/1000\n",
      "2504/2504 [==============================] - 2s 624us/step - loss: 0.0107 - acc: 0.9993 - val_loss: 0.1459 - val_acc: 0.9521\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 69/1000\n",
      "2504/2504 [==============================] - 2s 607us/step - loss: 0.0104 - acc: 0.9993 - val_loss: 0.1458 - val_acc: 0.9540\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 70/1000\n",
      "2504/2504 [==============================] - 2s 623us/step - loss: 0.0103 - acc: 0.9990 - val_loss: 0.1454 - val_acc: 0.9530\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 71/1000\n",
      "2504/2504 [==============================] - 1s 583us/step - loss: 0.0102 - acc: 0.9991 - val_loss: 0.1460 - val_acc: 0.9543\n",
      " - lr: 0.0002500000118743628\n",
      "Epoch 72/1000\n",
      "2504/2504 [==============================] - 1s 552us/step - loss: 0.0101 - acc: 0.9992 - val_loss: 0.1451 - val_acc: 0.9540\n",
      " - lr: 0.0002500000118743628\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 73/1000\n",
      "2504/2504 [==============================] - 1s 553us/step - loss: 0.0100 - acc: 0.9993 - val_loss: 0.1460 - val_acc: 0.9537\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 74/1000\n",
      "2504/2504 [==============================] - 1s 550us/step - loss: 0.0098 - acc: 0.9993 - val_loss: 0.1465 - val_acc: 0.9534\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 75/1000\n",
      "2504/2504 [==============================] - 1s 549us/step - loss: 0.0097 - acc: 0.9991 - val_loss: 0.1457 - val_acc: 0.9530\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 76/1000\n",
      "2504/2504 [==============================] - 1s 553us/step - loss: 0.0097 - acc: 0.9992 - val_loss: 0.1461 - val_acc: 0.9540\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 77/1000\n",
      "2504/2504 [==============================] - 1s 556us/step - loss: 0.0096 - acc: 0.9993 - val_loss: 0.1466 - val_acc: 0.9534\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 78/1000\n",
      "2504/2504 [==============================] - 2s 653us/step - loss: 0.0096 - acc: 0.9992 - val_loss: 0.1464 - val_acc: 0.9534\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 79/1000\n",
      "2504/2504 [==============================] - 1s 544us/step - loss: 0.0095 - acc: 0.9992 - val_loss: 0.1463 - val_acc: 0.9537\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 80/1000\n",
      "2504/2504 [==============================] - 1s 559us/step - loss: 0.0095 - acc: 0.9992 - val_loss: 0.1467 - val_acc: 0.9540\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 81/1000\n",
      "2504/2504 [==============================] - 1s 543us/step - loss: 0.0094 - acc: 0.9993 - val_loss: 0.1465 - val_acc: 0.9530\n",
      " - lr: 0.0001250000059371814\n",
      "Epoch 82/1000\n",
      "2504/2504 [==============================] - 1s 576us/step - loss: 0.0093 - acc: 0.9993 - val_loss: 0.1466 - val_acc: 0.9534\n",
      " - lr: 0.0001250000059371814\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 83/1000\n",
      "2504/2504 [==============================] - 1s 586us/step - loss: 0.0093 - acc: 0.9993 - val_loss: 0.1474 - val_acc: 0.9537\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 84/1000\n",
      "2504/2504 [==============================] - 1s 581us/step - loss: 0.0092 - acc: 0.9993 - val_loss: 0.1469 - val_acc: 0.9540\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 85/1000\n",
      "2504/2504 [==============================] - 1s 549us/step - loss: 0.0092 - acc: 0.9992 - val_loss: 0.1469 - val_acc: 0.9537\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 86/1000\n",
      "2504/2504 [==============================] - 1s 566us/step - loss: 0.0091 - acc: 0.9992 - val_loss: 0.1472 - val_acc: 0.9537\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 87/1000\n",
      "2504/2504 [==============================] - 1s 577us/step - loss: 0.0091 - acc: 0.9991 - val_loss: 0.1470 - val_acc: 0.9540\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 88/1000\n",
      "2504/2504 [==============================] - 1s 539us/step - loss: 0.0091 - acc: 0.9992 - val_loss: 0.1472 - val_acc: 0.9537\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 89/1000\n",
      "2504/2504 [==============================] - 1s 543us/step - loss: 0.0090 - acc: 0.9993 - val_loss: 0.1469 - val_acc: 0.9540\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 90/1000\n",
      "2504/2504 [==============================] - 1s 559us/step - loss: 0.0090 - acc: 0.9993 - val_loss: 0.1475 - val_acc: 0.9537\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 91/1000\n",
      "2504/2504 [==============================] - 1s 556us/step - loss: 0.0090 - acc: 0.9993 - val_loss: 0.1470 - val_acc: 0.9530\n",
      " - lr: 6.25000029685907e-05\n",
      "Epoch 92/1000\n",
      "2504/2504 [==============================] - 1s 565us/step - loss: 0.0089 - acc: 0.9993 - val_loss: 0.1473 - val_acc: 0.9530\n",
      " - lr: 6.25000029685907e-05\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 00092: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "class LearningRateTracker(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\" - lr: {}\".format(K.eval(self.model.optimizer.lr))) \n",
    "# session.run(tf.global_variables_initializer())\n",
    "# session.run(tf.tables_initializer())\n",
    "\n",
    "LR_PATIENCE = 10\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=LR_PATIENCE, min_lr=1e-8, verbose=1, mode=\"min\")\n",
    "es_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "lr_tracker = LearningRateTracker()\n",
    "\n",
    "history = model.fit(train_text, \n",
    "          train_label,\n",
    "          validation_data=(test_text, test_label),\n",
    "          epochs=1000,\n",
    "          batch_size=256,\n",
    "          callbacks=[es_callback, lr_tracker, reduce_lr])\n",
    "model.save_weights('./model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = trainset.target_names\n",
    "categories\n",
    "\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)),signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "# def sentence_encoder(input_text):\n",
    "#     return embed(tf.squeeze(input_text))\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(UniversalEmbedding,output_shape=(embed_size,))(input_text)\n",
    "dense1 = Dense(1024, activation='relu')(embedding)\n",
    "dense2 = Dense(128, activation='relu')(dense1)\n",
    "pred = []\n",
    "for c in categories:\n",
    "    pred.append(Dense(1, activation='sigmoid')(dense2))\n",
    "out = Concatenate()(pred)\n",
    "model = Model(inputs=[input_text], outputs=out)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "optimizer = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "new_text = ['I am unable to find fruits or vegetables',\n",
    "'Where can I get bread',\n",
    "'Edible supplies are not available in my area, i need bread and groceries',\n",
    "'We are 6 people in my family and we are out of food. Anything you can give, please do',\n",
    "'My inhaler isnt working and I need a new one asap, but i am unable to find it anywhere',\n",
    "'I am running out of my insulin injections. I need to stock up',\n",
    "'Me and my parents are stuck alone in our house with severe health issues. My father has heart problems and my mother is bedridden. I need urgent medical assistance',\n",
    "'All electricity is down in my society due to which all electronic devices are off.Phone, wifi laptop all shut',\n",
    "'I crashed in the divider on the way to medical and now bike wont start. Need help urgently.',\n",
    "'Me and family stranded on roadside on the way to mysore. Car is not working',\n",
    "'I hit the brakes very hard and now my car is shut down. Need help to get home',\n",
    "'Need gas for car so that I can reach home.',\n",
    "'Cooking oil is over and it is not available in any store',\n",
    "'3 people have crashed in my neighbors house for some money matter. Need urgent assistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'NN'), ('want', 'VBP'), ('to', 'TO'), ('go', 'VB'), ('back', 'RB')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 1\n",
    "nltk.pos_tag(nltk.word_tokenize('i want to go back'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('where', 'ADV'), ('can', 'VERB'), ('i', 'PRON'), ('get', 'AUX'), ('bread', 'NOUN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'can bread'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_query(new_text[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program  :  program\n",
      "programs  :  program\n",
      "computer  :  comput\n",
      "programing  :  program\n",
      "programers  :  program\n"
     ]
    }
   ],
   "source": [
    "words = [\"program\", \"programs\", \"computer\", \"programing\", \"programers\"] \n",
    "for w in words: \n",
    "    print(w, \" : \", ps.stem(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "card\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "print(lemmatizer.lemmatize(\"cards\")) \n",
    "\n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('text_processing': conda)",
   "language": "python",
   "name": "python37664bittextprocessingcondacdb2982750b1430d90ffe1db2903e3a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
